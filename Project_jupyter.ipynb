{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Dense, Input, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.callbacks import EarlyStopping\n",
    "import keras as keras\n",
    "import datetime\n",
    "import xgboost as xgb\n",
    "import joblib\n",
    "from xgboost import plot_tree\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing files and joining them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gene_0</th>\n",
       "      <th>gene_1</th>\n",
       "      <th>gene_2</th>\n",
       "      <th>gene_3</th>\n",
       "      <th>gene_4</th>\n",
       "      <th>gene_5</th>\n",
       "      <th>gene_6</th>\n",
       "      <th>gene_7</th>\n",
       "      <th>gene_8</th>\n",
       "      <th>gene_9</th>\n",
       "      <th>...</th>\n",
       "      <th>gene_20521</th>\n",
       "      <th>gene_20522</th>\n",
       "      <th>gene_20523</th>\n",
       "      <th>gene_20524</th>\n",
       "      <th>gene_20525</th>\n",
       "      <th>gene_20526</th>\n",
       "      <th>gene_20527</th>\n",
       "      <th>gene_20528</th>\n",
       "      <th>gene_20529</th>\n",
       "      <th>gene_20530</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sample_0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.017209</td>\n",
       "      <td>3.265527</td>\n",
       "      <td>5.478487</td>\n",
       "      <td>10.431999</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.175175</td>\n",
       "      <td>0.591871</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.926711</td>\n",
       "      <td>8.210257</td>\n",
       "      <td>9.723516</td>\n",
       "      <td>7.220030</td>\n",
       "      <td>9.119813</td>\n",
       "      <td>12.003135</td>\n",
       "      <td>9.650743</td>\n",
       "      <td>8.921326</td>\n",
       "      <td>5.286759</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample_1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.592732</td>\n",
       "      <td>1.588421</td>\n",
       "      <td>7.586157</td>\n",
       "      <td>9.623011</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.816049</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.593372</td>\n",
       "      <td>7.323865</td>\n",
       "      <td>9.740931</td>\n",
       "      <td>6.256586</td>\n",
       "      <td>8.381612</td>\n",
       "      <td>12.674552</td>\n",
       "      <td>10.517059</td>\n",
       "      <td>9.397854</td>\n",
       "      <td>2.094168</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample_2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.511759</td>\n",
       "      <td>4.327199</td>\n",
       "      <td>6.881787</td>\n",
       "      <td>9.870730</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.972130</td>\n",
       "      <td>0.452595</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.125213</td>\n",
       "      <td>8.127123</td>\n",
       "      <td>10.908640</td>\n",
       "      <td>5.401607</td>\n",
       "      <td>9.911597</td>\n",
       "      <td>9.045255</td>\n",
       "      <td>9.788359</td>\n",
       "      <td>10.090470</td>\n",
       "      <td>1.683023</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample_3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.663618</td>\n",
       "      <td>4.507649</td>\n",
       "      <td>6.659068</td>\n",
       "      <td>10.196184</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.843375</td>\n",
       "      <td>0.434882</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.076566</td>\n",
       "      <td>8.792959</td>\n",
       "      <td>10.141520</td>\n",
       "      <td>8.942805</td>\n",
       "      <td>9.601208</td>\n",
       "      <td>11.392682</td>\n",
       "      <td>9.694814</td>\n",
       "      <td>9.684365</td>\n",
       "      <td>3.292001</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample_4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.655741</td>\n",
       "      <td>2.821547</td>\n",
       "      <td>6.539454</td>\n",
       "      <td>9.738265</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.566967</td>\n",
       "      <td>0.360982</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.996032</td>\n",
       "      <td>8.891425</td>\n",
       "      <td>10.373790</td>\n",
       "      <td>7.181162</td>\n",
       "      <td>9.846910</td>\n",
       "      <td>11.922439</td>\n",
       "      <td>9.217749</td>\n",
       "      <td>9.461191</td>\n",
       "      <td>5.110372</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample_796</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.865642</td>\n",
       "      <td>2.718197</td>\n",
       "      <td>7.350099</td>\n",
       "      <td>10.006003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.764792</td>\n",
       "      <td>0.496922</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.088133</td>\n",
       "      <td>9.118313</td>\n",
       "      <td>10.004852</td>\n",
       "      <td>4.484415</td>\n",
       "      <td>9.614701</td>\n",
       "      <td>12.031267</td>\n",
       "      <td>9.813063</td>\n",
       "      <td>10.092770</td>\n",
       "      <td>8.819269</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample_797</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.942955</td>\n",
       "      <td>4.453807</td>\n",
       "      <td>6.346597</td>\n",
       "      <td>10.056868</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.320331</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.371876</td>\n",
       "      <td>9.623335</td>\n",
       "      <td>9.823921</td>\n",
       "      <td>6.555327</td>\n",
       "      <td>9.064002</td>\n",
       "      <td>11.633422</td>\n",
       "      <td>10.317266</td>\n",
       "      <td>8.745983</td>\n",
       "      <td>9.659081</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample_798</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.249582</td>\n",
       "      <td>3.707492</td>\n",
       "      <td>8.185901</td>\n",
       "      <td>9.504082</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.536589</td>\n",
       "      <td>1.811101</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.719386</td>\n",
       "      <td>8.610704</td>\n",
       "      <td>10.485517</td>\n",
       "      <td>3.589763</td>\n",
       "      <td>9.350636</td>\n",
       "      <td>12.180944</td>\n",
       "      <td>10.681194</td>\n",
       "      <td>9.466711</td>\n",
       "      <td>4.677458</td>\n",
       "      <td>0.586693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample_799</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.590339</td>\n",
       "      <td>2.787976</td>\n",
       "      <td>7.318624</td>\n",
       "      <td>9.987136</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.213464</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.785237</td>\n",
       "      <td>8.605387</td>\n",
       "      <td>11.004677</td>\n",
       "      <td>4.745888</td>\n",
       "      <td>9.626383</td>\n",
       "      <td>11.198279</td>\n",
       "      <td>10.335513</td>\n",
       "      <td>10.400581</td>\n",
       "      <td>5.718751</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample_800</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.325242</td>\n",
       "      <td>3.805932</td>\n",
       "      <td>6.530246</td>\n",
       "      <td>9.560367</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.957027</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.403075</td>\n",
       "      <td>8.594354</td>\n",
       "      <td>10.243079</td>\n",
       "      <td>9.139459</td>\n",
       "      <td>10.102934</td>\n",
       "      <td>11.641081</td>\n",
       "      <td>10.607358</td>\n",
       "      <td>9.844794</td>\n",
       "      <td>4.550716</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>801 rows × 20531 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            gene_0    gene_1    gene_2    gene_3     gene_4  gene_5    gene_6  \\\n",
       "sample_0       0.0  2.017209  3.265527  5.478487  10.431999     0.0  7.175175   \n",
       "sample_1       0.0  0.592732  1.588421  7.586157   9.623011     0.0  6.816049   \n",
       "sample_2       0.0  3.511759  4.327199  6.881787   9.870730     0.0  6.972130   \n",
       "sample_3       0.0  3.663618  4.507649  6.659068  10.196184     0.0  7.843375   \n",
       "sample_4       0.0  2.655741  2.821547  6.539454   9.738265     0.0  6.566967   \n",
       "...            ...       ...       ...       ...        ...     ...       ...   \n",
       "sample_796     0.0  1.865642  2.718197  7.350099  10.006003     0.0  6.764792   \n",
       "sample_797     0.0  3.942955  4.453807  6.346597  10.056868     0.0  7.320331   \n",
       "sample_798     0.0  3.249582  3.707492  8.185901   9.504082     0.0  7.536589   \n",
       "sample_799     0.0  2.590339  2.787976  7.318624   9.987136     0.0  9.213464   \n",
       "sample_800     0.0  2.325242  3.805932  6.530246   9.560367     0.0  7.957027   \n",
       "\n",
       "              gene_7  gene_8  gene_9  ...  gene_20521  gene_20522  gene_20523  \\\n",
       "sample_0    0.591871     0.0     0.0  ...    4.926711    8.210257    9.723516   \n",
       "sample_1    0.000000     0.0     0.0  ...    4.593372    7.323865    9.740931   \n",
       "sample_2    0.452595     0.0     0.0  ...    5.125213    8.127123   10.908640   \n",
       "sample_3    0.434882     0.0     0.0  ...    6.076566    8.792959   10.141520   \n",
       "sample_4    0.360982     0.0     0.0  ...    5.996032    8.891425   10.373790   \n",
       "...              ...     ...     ...  ...         ...         ...         ...   \n",
       "sample_796  0.496922     0.0     0.0  ...    6.088133    9.118313   10.004852   \n",
       "sample_797  0.000000     0.0     0.0  ...    6.371876    9.623335    9.823921   \n",
       "sample_798  1.811101     0.0     0.0  ...    5.719386    8.610704   10.485517   \n",
       "sample_799  0.000000     0.0     0.0  ...    5.785237    8.605387   11.004677   \n",
       "sample_800  0.000000     0.0     0.0  ...    6.403075    8.594354   10.243079   \n",
       "\n",
       "            gene_20524  gene_20525  gene_20526  gene_20527  gene_20528  \\\n",
       "sample_0      7.220030    9.119813   12.003135    9.650743    8.921326   \n",
       "sample_1      6.256586    8.381612   12.674552   10.517059    9.397854   \n",
       "sample_2      5.401607    9.911597    9.045255    9.788359   10.090470   \n",
       "sample_3      8.942805    9.601208   11.392682    9.694814    9.684365   \n",
       "sample_4      7.181162    9.846910   11.922439    9.217749    9.461191   \n",
       "...                ...         ...         ...         ...         ...   \n",
       "sample_796    4.484415    9.614701   12.031267    9.813063   10.092770   \n",
       "sample_797    6.555327    9.064002   11.633422   10.317266    8.745983   \n",
       "sample_798    3.589763    9.350636   12.180944   10.681194    9.466711   \n",
       "sample_799    4.745888    9.626383   11.198279   10.335513   10.400581   \n",
       "sample_800    9.139459   10.102934   11.641081   10.607358    9.844794   \n",
       "\n",
       "            gene_20529  gene_20530  \n",
       "sample_0      5.286759    0.000000  \n",
       "sample_1      2.094168    0.000000  \n",
       "sample_2      1.683023    0.000000  \n",
       "sample_3      3.292001    0.000000  \n",
       "sample_4      5.110372    0.000000  \n",
       "...                ...         ...  \n",
       "sample_796    8.819269    0.000000  \n",
       "sample_797    9.659081    0.000000  \n",
       "sample_798    4.677458    0.586693  \n",
       "sample_799    5.718751    0.000000  \n",
       "sample_800    4.550716    0.000000  \n",
       "\n",
       "[801 rows x 20531 columns]"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/data.csv', index_col=0)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(801, 20531)"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gene_0</th>\n",
       "      <th>gene_1</th>\n",
       "      <th>gene_2</th>\n",
       "      <th>gene_3</th>\n",
       "      <th>gene_4</th>\n",
       "      <th>gene_5</th>\n",
       "      <th>gene_6</th>\n",
       "      <th>gene_7</th>\n",
       "      <th>gene_8</th>\n",
       "      <th>gene_9</th>\n",
       "      <th>...</th>\n",
       "      <th>gene_20521</th>\n",
       "      <th>gene_20522</th>\n",
       "      <th>gene_20523</th>\n",
       "      <th>gene_20524</th>\n",
       "      <th>gene_20525</th>\n",
       "      <th>gene_20526</th>\n",
       "      <th>gene_20527</th>\n",
       "      <th>gene_20528</th>\n",
       "      <th>gene_20529</th>\n",
       "      <th>gene_20530</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>801.000000</td>\n",
       "      <td>801.000000</td>\n",
       "      <td>801.000000</td>\n",
       "      <td>801.000000</td>\n",
       "      <td>801.000000</td>\n",
       "      <td>801.0</td>\n",
       "      <td>801.000000</td>\n",
       "      <td>801.000000</td>\n",
       "      <td>801.000000</td>\n",
       "      <td>801.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>801.000000</td>\n",
       "      <td>801.000000</td>\n",
       "      <td>801.000000</td>\n",
       "      <td>801.000000</td>\n",
       "      <td>801.000000</td>\n",
       "      <td>801.000000</td>\n",
       "      <td>801.000000</td>\n",
       "      <td>801.000000</td>\n",
       "      <td>801.000000</td>\n",
       "      <td>801.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.026642</td>\n",
       "      <td>3.010909</td>\n",
       "      <td>3.095350</td>\n",
       "      <td>6.722305</td>\n",
       "      <td>9.813612</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.405509</td>\n",
       "      <td>0.499882</td>\n",
       "      <td>0.016744</td>\n",
       "      <td>0.013428</td>\n",
       "      <td>...</td>\n",
       "      <td>5.896573</td>\n",
       "      <td>8.765891</td>\n",
       "      <td>10.056252</td>\n",
       "      <td>4.847727</td>\n",
       "      <td>9.741987</td>\n",
       "      <td>11.742228</td>\n",
       "      <td>10.155271</td>\n",
       "      <td>9.590726</td>\n",
       "      <td>5.528177</td>\n",
       "      <td>0.095411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.136850</td>\n",
       "      <td>1.200828</td>\n",
       "      <td>1.065601</td>\n",
       "      <td>0.638819</td>\n",
       "      <td>0.506537</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.108237</td>\n",
       "      <td>0.508799</td>\n",
       "      <td>0.133635</td>\n",
       "      <td>0.204722</td>\n",
       "      <td>...</td>\n",
       "      <td>0.746399</td>\n",
       "      <td>0.603176</td>\n",
       "      <td>0.379278</td>\n",
       "      <td>2.382728</td>\n",
       "      <td>0.533898</td>\n",
       "      <td>0.670371</td>\n",
       "      <td>0.580569</td>\n",
       "      <td>0.563849</td>\n",
       "      <td>2.073859</td>\n",
       "      <td>0.364529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.009284</td>\n",
       "      <td>8.435999</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.930747</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.853517</td>\n",
       "      <td>6.678368</td>\n",
       "      <td>8.669456</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.974942</td>\n",
       "      <td>9.045255</td>\n",
       "      <td>7.530141</td>\n",
       "      <td>7.864533</td>\n",
       "      <td>0.593975</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.299039</td>\n",
       "      <td>2.390365</td>\n",
       "      <td>6.303346</td>\n",
       "      <td>9.464466</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.676042</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>5.454926</td>\n",
       "      <td>8.383834</td>\n",
       "      <td>9.826027</td>\n",
       "      <td>3.130750</td>\n",
       "      <td>9.400747</td>\n",
       "      <td>11.315857</td>\n",
       "      <td>9.836525</td>\n",
       "      <td>9.244219</td>\n",
       "      <td>4.092385</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.143687</td>\n",
       "      <td>3.127006</td>\n",
       "      <td>6.655893</td>\n",
       "      <td>9.791599</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.450114</td>\n",
       "      <td>0.443076</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>5.972582</td>\n",
       "      <td>8.784144</td>\n",
       "      <td>10.066385</td>\n",
       "      <td>5.444935</td>\n",
       "      <td>9.784524</td>\n",
       "      <td>11.749802</td>\n",
       "      <td>10.191207</td>\n",
       "      <td>9.566511</td>\n",
       "      <td>5.218618</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.883484</td>\n",
       "      <td>3.802534</td>\n",
       "      <td>7.038447</td>\n",
       "      <td>10.142324</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.121984</td>\n",
       "      <td>0.789354</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>6.411292</td>\n",
       "      <td>9.147136</td>\n",
       "      <td>10.299025</td>\n",
       "      <td>6.637412</td>\n",
       "      <td>10.082269</td>\n",
       "      <td>12.177852</td>\n",
       "      <td>10.578561</td>\n",
       "      <td>9.917888</td>\n",
       "      <td>6.876382</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.482332</td>\n",
       "      <td>6.237034</td>\n",
       "      <td>6.063484</td>\n",
       "      <td>10.129528</td>\n",
       "      <td>11.355621</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.718190</td>\n",
       "      <td>2.779008</td>\n",
       "      <td>1.785592</td>\n",
       "      <td>4.067604</td>\n",
       "      <td>...</td>\n",
       "      <td>7.771054</td>\n",
       "      <td>11.105431</td>\n",
       "      <td>11.318243</td>\n",
       "      <td>9.207495</td>\n",
       "      <td>11.811632</td>\n",
       "      <td>13.715361</td>\n",
       "      <td>11.675653</td>\n",
       "      <td>12.813320</td>\n",
       "      <td>11.205836</td>\n",
       "      <td>5.254133</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 20531 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           gene_0      gene_1      gene_2      gene_3      gene_4  gene_5  \\\n",
       "count  801.000000  801.000000  801.000000  801.000000  801.000000   801.0   \n",
       "mean     0.026642    3.010909    3.095350    6.722305    9.813612     0.0   \n",
       "std      0.136850    1.200828    1.065601    0.638819    0.506537     0.0   \n",
       "min      0.000000    0.000000    0.000000    5.009284    8.435999     0.0   \n",
       "25%      0.000000    2.299039    2.390365    6.303346    9.464466     0.0   \n",
       "50%      0.000000    3.143687    3.127006    6.655893    9.791599     0.0   \n",
       "75%      0.000000    3.883484    3.802534    7.038447   10.142324     0.0   \n",
       "max      1.482332    6.237034    6.063484   10.129528   11.355621     0.0   \n",
       "\n",
       "           gene_6      gene_7      gene_8      gene_9  ...  gene_20521  \\\n",
       "count  801.000000  801.000000  801.000000  801.000000  ...  801.000000   \n",
       "mean     7.405509    0.499882    0.016744    0.013428  ...    5.896573   \n",
       "std      1.108237    0.508799    0.133635    0.204722  ...    0.746399   \n",
       "min      3.930747    0.000000    0.000000    0.000000  ...    2.853517   \n",
       "25%      6.676042    0.000000    0.000000    0.000000  ...    5.454926   \n",
       "50%      7.450114    0.443076    0.000000    0.000000  ...    5.972582   \n",
       "75%      8.121984    0.789354    0.000000    0.000000  ...    6.411292   \n",
       "max     10.718190    2.779008    1.785592    4.067604  ...    7.771054   \n",
       "\n",
       "       gene_20522  gene_20523  gene_20524  gene_20525  gene_20526  gene_20527  \\\n",
       "count  801.000000  801.000000  801.000000  801.000000  801.000000  801.000000   \n",
       "mean     8.765891   10.056252    4.847727    9.741987   11.742228   10.155271   \n",
       "std      0.603176    0.379278    2.382728    0.533898    0.670371    0.580569   \n",
       "min      6.678368    8.669456    0.000000    7.974942    9.045255    7.530141   \n",
       "25%      8.383834    9.826027    3.130750    9.400747   11.315857    9.836525   \n",
       "50%      8.784144   10.066385    5.444935    9.784524   11.749802   10.191207   \n",
       "75%      9.147136   10.299025    6.637412   10.082269   12.177852   10.578561   \n",
       "max     11.105431   11.318243    9.207495   11.811632   13.715361   11.675653   \n",
       "\n",
       "       gene_20528  gene_20529  gene_20530  \n",
       "count  801.000000  801.000000  801.000000  \n",
       "mean     9.590726    5.528177    0.095411  \n",
       "std      0.563849    2.073859    0.364529  \n",
       "min      7.864533    0.593975    0.000000  \n",
       "25%      9.244219    4.092385    0.000000  \n",
       "50%      9.566511    5.218618    0.000000  \n",
       "75%      9.917888    6.876382    0.000000  \n",
       "max     12.813320   11.205836    5.254133  \n",
       "\n",
       "[8 rows x 20531 columns]"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sample_0</th>\n",
       "      <td>PRAD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample_1</th>\n",
       "      <td>LUAD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample_2</th>\n",
       "      <td>PRAD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample_3</th>\n",
       "      <td>PRAD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample_4</th>\n",
       "      <td>BRCA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample_796</th>\n",
       "      <td>BRCA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample_797</th>\n",
       "      <td>LUAD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample_798</th>\n",
       "      <td>COAD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample_799</th>\n",
       "      <td>PRAD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample_800</th>\n",
       "      <td>PRAD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>801 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Class\n",
       "sample_0    PRAD\n",
       "sample_1    LUAD\n",
       "sample_2    PRAD\n",
       "sample_3    PRAD\n",
       "sample_4    BRCA\n",
       "...          ...\n",
       "sample_796  BRCA\n",
       "sample_797  LUAD\n",
       "sample_798  COAD\n",
       "sample_799  PRAD\n",
       "sample_800  PRAD\n",
       "\n",
       "[801 rows x 1 columns]"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_class = pd.read_csv('data/labels.csv', index_col=0)\n",
    "df_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gene_0</th>\n",
       "      <th>gene_1</th>\n",
       "      <th>gene_2</th>\n",
       "      <th>gene_3</th>\n",
       "      <th>gene_4</th>\n",
       "      <th>gene_5</th>\n",
       "      <th>gene_6</th>\n",
       "      <th>gene_7</th>\n",
       "      <th>gene_8</th>\n",
       "      <th>gene_9</th>\n",
       "      <th>...</th>\n",
       "      <th>gene_20522</th>\n",
       "      <th>gene_20523</th>\n",
       "      <th>gene_20524</th>\n",
       "      <th>gene_20525</th>\n",
       "      <th>gene_20526</th>\n",
       "      <th>gene_20527</th>\n",
       "      <th>gene_20528</th>\n",
       "      <th>gene_20529</th>\n",
       "      <th>gene_20530</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sample_0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.017209</td>\n",
       "      <td>3.265527</td>\n",
       "      <td>5.478487</td>\n",
       "      <td>10.431999</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.175175</td>\n",
       "      <td>0.591871</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.210257</td>\n",
       "      <td>9.723516</td>\n",
       "      <td>7.220030</td>\n",
       "      <td>9.119813</td>\n",
       "      <td>12.003135</td>\n",
       "      <td>9.650743</td>\n",
       "      <td>8.921326</td>\n",
       "      <td>5.286759</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>PRAD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample_1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.592732</td>\n",
       "      <td>1.588421</td>\n",
       "      <td>7.586157</td>\n",
       "      <td>9.623011</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.816049</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.323865</td>\n",
       "      <td>9.740931</td>\n",
       "      <td>6.256586</td>\n",
       "      <td>8.381612</td>\n",
       "      <td>12.674552</td>\n",
       "      <td>10.517059</td>\n",
       "      <td>9.397854</td>\n",
       "      <td>2.094168</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>LUAD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample_2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.511759</td>\n",
       "      <td>4.327199</td>\n",
       "      <td>6.881787</td>\n",
       "      <td>9.870730</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.972130</td>\n",
       "      <td>0.452595</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.127123</td>\n",
       "      <td>10.908640</td>\n",
       "      <td>5.401607</td>\n",
       "      <td>9.911597</td>\n",
       "      <td>9.045255</td>\n",
       "      <td>9.788359</td>\n",
       "      <td>10.090470</td>\n",
       "      <td>1.683023</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>PRAD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample_3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.663618</td>\n",
       "      <td>4.507649</td>\n",
       "      <td>6.659068</td>\n",
       "      <td>10.196184</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.843375</td>\n",
       "      <td>0.434882</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.792959</td>\n",
       "      <td>10.141520</td>\n",
       "      <td>8.942805</td>\n",
       "      <td>9.601208</td>\n",
       "      <td>11.392682</td>\n",
       "      <td>9.694814</td>\n",
       "      <td>9.684365</td>\n",
       "      <td>3.292001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>PRAD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample_4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.655741</td>\n",
       "      <td>2.821547</td>\n",
       "      <td>6.539454</td>\n",
       "      <td>9.738265</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.566967</td>\n",
       "      <td>0.360982</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.891425</td>\n",
       "      <td>10.373790</td>\n",
       "      <td>7.181162</td>\n",
       "      <td>9.846910</td>\n",
       "      <td>11.922439</td>\n",
       "      <td>9.217749</td>\n",
       "      <td>9.461191</td>\n",
       "      <td>5.110372</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>BRCA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample_796</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.865642</td>\n",
       "      <td>2.718197</td>\n",
       "      <td>7.350099</td>\n",
       "      <td>10.006003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.764792</td>\n",
       "      <td>0.496922</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.118313</td>\n",
       "      <td>10.004852</td>\n",
       "      <td>4.484415</td>\n",
       "      <td>9.614701</td>\n",
       "      <td>12.031267</td>\n",
       "      <td>9.813063</td>\n",
       "      <td>10.092770</td>\n",
       "      <td>8.819269</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>BRCA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample_797</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.942955</td>\n",
       "      <td>4.453807</td>\n",
       "      <td>6.346597</td>\n",
       "      <td>10.056868</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.320331</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.623335</td>\n",
       "      <td>9.823921</td>\n",
       "      <td>6.555327</td>\n",
       "      <td>9.064002</td>\n",
       "      <td>11.633422</td>\n",
       "      <td>10.317266</td>\n",
       "      <td>8.745983</td>\n",
       "      <td>9.659081</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>LUAD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample_798</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.249582</td>\n",
       "      <td>3.707492</td>\n",
       "      <td>8.185901</td>\n",
       "      <td>9.504082</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.536589</td>\n",
       "      <td>1.811101</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.610704</td>\n",
       "      <td>10.485517</td>\n",
       "      <td>3.589763</td>\n",
       "      <td>9.350636</td>\n",
       "      <td>12.180944</td>\n",
       "      <td>10.681194</td>\n",
       "      <td>9.466711</td>\n",
       "      <td>4.677458</td>\n",
       "      <td>0.586693</td>\n",
       "      <td>COAD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample_799</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.590339</td>\n",
       "      <td>2.787976</td>\n",
       "      <td>7.318624</td>\n",
       "      <td>9.987136</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.213464</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.605387</td>\n",
       "      <td>11.004677</td>\n",
       "      <td>4.745888</td>\n",
       "      <td>9.626383</td>\n",
       "      <td>11.198279</td>\n",
       "      <td>10.335513</td>\n",
       "      <td>10.400581</td>\n",
       "      <td>5.718751</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>PRAD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample_800</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.325242</td>\n",
       "      <td>3.805932</td>\n",
       "      <td>6.530246</td>\n",
       "      <td>9.560367</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.957027</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.594354</td>\n",
       "      <td>10.243079</td>\n",
       "      <td>9.139459</td>\n",
       "      <td>10.102934</td>\n",
       "      <td>11.641081</td>\n",
       "      <td>10.607358</td>\n",
       "      <td>9.844794</td>\n",
       "      <td>4.550716</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>PRAD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>801 rows × 20532 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            gene_0    gene_1    gene_2    gene_3     gene_4  gene_5    gene_6  \\\n",
       "sample_0       0.0  2.017209  3.265527  5.478487  10.431999     0.0  7.175175   \n",
       "sample_1       0.0  0.592732  1.588421  7.586157   9.623011     0.0  6.816049   \n",
       "sample_2       0.0  3.511759  4.327199  6.881787   9.870730     0.0  6.972130   \n",
       "sample_3       0.0  3.663618  4.507649  6.659068  10.196184     0.0  7.843375   \n",
       "sample_4       0.0  2.655741  2.821547  6.539454   9.738265     0.0  6.566967   \n",
       "...            ...       ...       ...       ...        ...     ...       ...   \n",
       "sample_796     0.0  1.865642  2.718197  7.350099  10.006003     0.0  6.764792   \n",
       "sample_797     0.0  3.942955  4.453807  6.346597  10.056868     0.0  7.320331   \n",
       "sample_798     0.0  3.249582  3.707492  8.185901   9.504082     0.0  7.536589   \n",
       "sample_799     0.0  2.590339  2.787976  7.318624   9.987136     0.0  9.213464   \n",
       "sample_800     0.0  2.325242  3.805932  6.530246   9.560367     0.0  7.957027   \n",
       "\n",
       "              gene_7  gene_8  gene_9  ...  gene_20522  gene_20523  gene_20524  \\\n",
       "sample_0    0.591871     0.0     0.0  ...    8.210257    9.723516    7.220030   \n",
       "sample_1    0.000000     0.0     0.0  ...    7.323865    9.740931    6.256586   \n",
       "sample_2    0.452595     0.0     0.0  ...    8.127123   10.908640    5.401607   \n",
       "sample_3    0.434882     0.0     0.0  ...    8.792959   10.141520    8.942805   \n",
       "sample_4    0.360982     0.0     0.0  ...    8.891425   10.373790    7.181162   \n",
       "...              ...     ...     ...  ...         ...         ...         ...   \n",
       "sample_796  0.496922     0.0     0.0  ...    9.118313   10.004852    4.484415   \n",
       "sample_797  0.000000     0.0     0.0  ...    9.623335    9.823921    6.555327   \n",
       "sample_798  1.811101     0.0     0.0  ...    8.610704   10.485517    3.589763   \n",
       "sample_799  0.000000     0.0     0.0  ...    8.605387   11.004677    4.745888   \n",
       "sample_800  0.000000     0.0     0.0  ...    8.594354   10.243079    9.139459   \n",
       "\n",
       "            gene_20525  gene_20526  gene_20527  gene_20528  gene_20529  \\\n",
       "sample_0      9.119813   12.003135    9.650743    8.921326    5.286759   \n",
       "sample_1      8.381612   12.674552   10.517059    9.397854    2.094168   \n",
       "sample_2      9.911597    9.045255    9.788359   10.090470    1.683023   \n",
       "sample_3      9.601208   11.392682    9.694814    9.684365    3.292001   \n",
       "sample_4      9.846910   11.922439    9.217749    9.461191    5.110372   \n",
       "...                ...         ...         ...         ...         ...   \n",
       "sample_796    9.614701   12.031267    9.813063   10.092770    8.819269   \n",
       "sample_797    9.064002   11.633422   10.317266    8.745983    9.659081   \n",
       "sample_798    9.350636   12.180944   10.681194    9.466711    4.677458   \n",
       "sample_799    9.626383   11.198279   10.335513   10.400581    5.718751   \n",
       "sample_800   10.102934   11.641081   10.607358    9.844794    4.550716   \n",
       "\n",
       "            gene_20530  Class  \n",
       "sample_0      0.000000   PRAD  \n",
       "sample_1      0.000000   LUAD  \n",
       "sample_2      0.000000   PRAD  \n",
       "sample_3      0.000000   PRAD  \n",
       "sample_4      0.000000   BRCA  \n",
       "...                ...    ...  \n",
       "sample_796    0.000000   BRCA  \n",
       "sample_797    0.000000   LUAD  \n",
       "sample_798    0.586693   COAD  \n",
       "sample_799    0.000000   PRAD  \n",
       "sample_800    0.000000   PRAD  \n",
       "\n",
       "[801 rows x 20532 columns]"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# new_class = df_class[\"Class\"]\n",
    "# df = df.join(new_class)\n",
    "# df\n",
    "\n",
    "\n",
    "df = pd.concat([df, df_class], axis=1) #\n",
    "df = df.copy()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(801, 20532)"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gene_0</th>\n",
       "      <th>gene_1</th>\n",
       "      <th>gene_2</th>\n",
       "      <th>gene_3</th>\n",
       "      <th>gene_4</th>\n",
       "      <th>gene_5</th>\n",
       "      <th>gene_6</th>\n",
       "      <th>gene_7</th>\n",
       "      <th>gene_8</th>\n",
       "      <th>gene_9</th>\n",
       "      <th>...</th>\n",
       "      <th>gene_20521</th>\n",
       "      <th>gene_20522</th>\n",
       "      <th>gene_20523</th>\n",
       "      <th>gene_20524</th>\n",
       "      <th>gene_20525</th>\n",
       "      <th>gene_20526</th>\n",
       "      <th>gene_20527</th>\n",
       "      <th>gene_20528</th>\n",
       "      <th>gene_20529</th>\n",
       "      <th>gene_20530</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sample_0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.017209</td>\n",
       "      <td>3.265527</td>\n",
       "      <td>5.478487</td>\n",
       "      <td>10.431999</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.175175</td>\n",
       "      <td>0.591871</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.926711</td>\n",
       "      <td>8.210257</td>\n",
       "      <td>9.723516</td>\n",
       "      <td>7.220030</td>\n",
       "      <td>9.119813</td>\n",
       "      <td>12.003135</td>\n",
       "      <td>9.650743</td>\n",
       "      <td>8.921326</td>\n",
       "      <td>5.286759</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample_1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.592732</td>\n",
       "      <td>1.588421</td>\n",
       "      <td>7.586157</td>\n",
       "      <td>9.623011</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.816049</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.593372</td>\n",
       "      <td>7.323865</td>\n",
       "      <td>9.740931</td>\n",
       "      <td>6.256586</td>\n",
       "      <td>8.381612</td>\n",
       "      <td>12.674552</td>\n",
       "      <td>10.517059</td>\n",
       "      <td>9.397854</td>\n",
       "      <td>2.094168</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample_2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.511759</td>\n",
       "      <td>4.327199</td>\n",
       "      <td>6.881787</td>\n",
       "      <td>9.870730</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.972130</td>\n",
       "      <td>0.452595</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.125213</td>\n",
       "      <td>8.127123</td>\n",
       "      <td>10.908640</td>\n",
       "      <td>5.401607</td>\n",
       "      <td>9.911597</td>\n",
       "      <td>9.045255</td>\n",
       "      <td>9.788359</td>\n",
       "      <td>10.090470</td>\n",
       "      <td>1.683023</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample_3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.663618</td>\n",
       "      <td>4.507649</td>\n",
       "      <td>6.659068</td>\n",
       "      <td>10.196184</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.843375</td>\n",
       "      <td>0.434882</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.076566</td>\n",
       "      <td>8.792959</td>\n",
       "      <td>10.141520</td>\n",
       "      <td>8.942805</td>\n",
       "      <td>9.601208</td>\n",
       "      <td>11.392682</td>\n",
       "      <td>9.694814</td>\n",
       "      <td>9.684365</td>\n",
       "      <td>3.292001</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample_4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.655741</td>\n",
       "      <td>2.821547</td>\n",
       "      <td>6.539454</td>\n",
       "      <td>9.738265</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.566967</td>\n",
       "      <td>0.360982</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.996032</td>\n",
       "      <td>8.891425</td>\n",
       "      <td>10.373790</td>\n",
       "      <td>7.181162</td>\n",
       "      <td>9.846910</td>\n",
       "      <td>11.922439</td>\n",
       "      <td>9.217749</td>\n",
       "      <td>9.461191</td>\n",
       "      <td>5.110372</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample_796</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.865642</td>\n",
       "      <td>2.718197</td>\n",
       "      <td>7.350099</td>\n",
       "      <td>10.006003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.764792</td>\n",
       "      <td>0.496922</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.088133</td>\n",
       "      <td>9.118313</td>\n",
       "      <td>10.004852</td>\n",
       "      <td>4.484415</td>\n",
       "      <td>9.614701</td>\n",
       "      <td>12.031267</td>\n",
       "      <td>9.813063</td>\n",
       "      <td>10.092770</td>\n",
       "      <td>8.819269</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample_797</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.942955</td>\n",
       "      <td>4.453807</td>\n",
       "      <td>6.346597</td>\n",
       "      <td>10.056868</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.320331</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.371876</td>\n",
       "      <td>9.623335</td>\n",
       "      <td>9.823921</td>\n",
       "      <td>6.555327</td>\n",
       "      <td>9.064002</td>\n",
       "      <td>11.633422</td>\n",
       "      <td>10.317266</td>\n",
       "      <td>8.745983</td>\n",
       "      <td>9.659081</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample_798</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.249582</td>\n",
       "      <td>3.707492</td>\n",
       "      <td>8.185901</td>\n",
       "      <td>9.504082</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.536589</td>\n",
       "      <td>1.811101</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.719386</td>\n",
       "      <td>8.610704</td>\n",
       "      <td>10.485517</td>\n",
       "      <td>3.589763</td>\n",
       "      <td>9.350636</td>\n",
       "      <td>12.180944</td>\n",
       "      <td>10.681194</td>\n",
       "      <td>9.466711</td>\n",
       "      <td>4.677458</td>\n",
       "      <td>0.586693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample_799</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.590339</td>\n",
       "      <td>2.787976</td>\n",
       "      <td>7.318624</td>\n",
       "      <td>9.987136</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.213464</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.785237</td>\n",
       "      <td>8.605387</td>\n",
       "      <td>11.004677</td>\n",
       "      <td>4.745888</td>\n",
       "      <td>9.626383</td>\n",
       "      <td>11.198279</td>\n",
       "      <td>10.335513</td>\n",
       "      <td>10.400581</td>\n",
       "      <td>5.718751</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample_800</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.325242</td>\n",
       "      <td>3.805932</td>\n",
       "      <td>6.530246</td>\n",
       "      <td>9.560367</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.957027</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.403075</td>\n",
       "      <td>8.594354</td>\n",
       "      <td>10.243079</td>\n",
       "      <td>9.139459</td>\n",
       "      <td>10.102934</td>\n",
       "      <td>11.641081</td>\n",
       "      <td>10.607358</td>\n",
       "      <td>9.844794</td>\n",
       "      <td>4.550716</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>801 rows × 20531 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            gene_0    gene_1    gene_2    gene_3     gene_4  gene_5    gene_6  \\\n",
       "sample_0       0.0  2.017209  3.265527  5.478487  10.431999     0.0  7.175175   \n",
       "sample_1       0.0  0.592732  1.588421  7.586157   9.623011     0.0  6.816049   \n",
       "sample_2       0.0  3.511759  4.327199  6.881787   9.870730     0.0  6.972130   \n",
       "sample_3       0.0  3.663618  4.507649  6.659068  10.196184     0.0  7.843375   \n",
       "sample_4       0.0  2.655741  2.821547  6.539454   9.738265     0.0  6.566967   \n",
       "...            ...       ...       ...       ...        ...     ...       ...   \n",
       "sample_796     0.0  1.865642  2.718197  7.350099  10.006003     0.0  6.764792   \n",
       "sample_797     0.0  3.942955  4.453807  6.346597  10.056868     0.0  7.320331   \n",
       "sample_798     0.0  3.249582  3.707492  8.185901   9.504082     0.0  7.536589   \n",
       "sample_799     0.0  2.590339  2.787976  7.318624   9.987136     0.0  9.213464   \n",
       "sample_800     0.0  2.325242  3.805932  6.530246   9.560367     0.0  7.957027   \n",
       "\n",
       "              gene_7  gene_8  gene_9  ...  gene_20521  gene_20522  gene_20523  \\\n",
       "sample_0    0.591871     0.0     0.0  ...    4.926711    8.210257    9.723516   \n",
       "sample_1    0.000000     0.0     0.0  ...    4.593372    7.323865    9.740931   \n",
       "sample_2    0.452595     0.0     0.0  ...    5.125213    8.127123   10.908640   \n",
       "sample_3    0.434882     0.0     0.0  ...    6.076566    8.792959   10.141520   \n",
       "sample_4    0.360982     0.0     0.0  ...    5.996032    8.891425   10.373790   \n",
       "...              ...     ...     ...  ...         ...         ...         ...   \n",
       "sample_796  0.496922     0.0     0.0  ...    6.088133    9.118313   10.004852   \n",
       "sample_797  0.000000     0.0     0.0  ...    6.371876    9.623335    9.823921   \n",
       "sample_798  1.811101     0.0     0.0  ...    5.719386    8.610704   10.485517   \n",
       "sample_799  0.000000     0.0     0.0  ...    5.785237    8.605387   11.004677   \n",
       "sample_800  0.000000     0.0     0.0  ...    6.403075    8.594354   10.243079   \n",
       "\n",
       "            gene_20524  gene_20525  gene_20526  gene_20527  gene_20528  \\\n",
       "sample_0      7.220030    9.119813   12.003135    9.650743    8.921326   \n",
       "sample_1      6.256586    8.381612   12.674552   10.517059    9.397854   \n",
       "sample_2      5.401607    9.911597    9.045255    9.788359   10.090470   \n",
       "sample_3      8.942805    9.601208   11.392682    9.694814    9.684365   \n",
       "sample_4      7.181162    9.846910   11.922439    9.217749    9.461191   \n",
       "...                ...         ...         ...         ...         ...   \n",
       "sample_796    4.484415    9.614701   12.031267    9.813063   10.092770   \n",
       "sample_797    6.555327    9.064002   11.633422   10.317266    8.745983   \n",
       "sample_798    3.589763    9.350636   12.180944   10.681194    9.466711   \n",
       "sample_799    4.745888    9.626383   11.198279   10.335513   10.400581   \n",
       "sample_800    9.139459   10.102934   11.641081   10.607358    9.844794   \n",
       "\n",
       "            gene_20529  gene_20530  \n",
       "sample_0      5.286759    0.000000  \n",
       "sample_1      2.094168    0.000000  \n",
       "sample_2      1.683023    0.000000  \n",
       "sample_3      3.292001    0.000000  \n",
       "sample_4      5.110372    0.000000  \n",
       "...                ...         ...  \n",
       "sample_796    8.819269    0.000000  \n",
       "sample_797    9.659081    0.000000  \n",
       "sample_798    4.677458    0.586693  \n",
       "sample_799    5.718751    0.000000  \n",
       "sample_800    4.550716    0.000000  \n",
       "\n",
       "[801 rows x 20531 columns]"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = df.iloc[:,-1]\n",
    "X = df.iloc[:,:-1]\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(801, 20531)"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter data if any genes contains only zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     20264\n",
       "False      267\n",
       "dtype: int64"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X != 0).any(axis=0).value_counts() #Presence of 267 genes with null data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtering data allows the removal of 267 genes having null data on its entire column samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.loc[:,(X != 0).any(axis=0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(801, 20264)"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape # No change in shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['PRAD', 'LUAD', 'BRCA', 'KIRC', 'COAD'], dtype=object)"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.unique() # 5 different classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(801,)"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 4,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 4,\n",
       " 2,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 4,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 4,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 0,\n",
       " 4,\n",
       " 2,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 4,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 4,\n",
       " 1,\n",
       " 0,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 4,\n",
       " 0,\n",
       " 0]"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_encoded = []\n",
    "unique_tumours = {}\n",
    "i = 0\n",
    "for tumour_name in Y:\n",
    "    if tumour_name not in unique_tumours:\n",
    "        unique_tumours[tumour_name] = i\n",
    "        i += 1\n",
    "    \n",
    "for value in Y:\n",
    "    if value in unique_tumours:\n",
    "        Y_encoded.append(unique_tumours[value])\n",
    "\n",
    "Y_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_bis = to_categorical(Y_encoded)\n",
    "Y_bis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(801, 5)"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_bis.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split into training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y_bis, test_size=0.3, random_state=42, stratify=Y_bis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(560, 20264)"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(560, 5)"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# init = 'random_uniform'\n",
    "# input_layer = Input(shape=(20264,))\n",
    "# mid_layer = Dense(150, activation = 'relu', kernel_initializer = init)(input_layer)\n",
    "# drop_1 = Dropout(0.1)(mid_layer)\n",
    "# mid_layer_2 = Dense(100, activation = 'relu', kernel_initializer = init)(drop_1)\n",
    "# drop_2 = Dropout(0.1)(mid_layer_2)\n",
    "# mid_layer_3 = Dense(50, activation = 'relu', kernel_initializer = init)(drop_2)\n",
    "# output_layer = Dense(5, activation = 'softmax', kernel_initializer = init)(mid_layer_3)\n",
    "\n",
    "# Model building\n",
    "def create_model(init = \"random_uniform\", layers = 2, neurons = 50, activation_hidden = \"relu\", activation_output = \"softmax\", loss = \"categorical_crossentropy\", optimizer = \"adam\", dropout_rate = 0.1):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(20264,)))\n",
    "    for _ in range(0, layers, 1):\n",
    "        model.add(Dense(neurons, activation = activation_hidden, kernel_initializer = init))\n",
    "        model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(5, activation = activation_output, kernel_initializer = init))\n",
    "    # Compile model\n",
    "    model.compile(loss=loss, optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/p2/mpls35q15k5050t9ppyx93l40000gn/T/ipykernel_47033/120676901.py:5: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead.\n",
      "  model = KerasClassifier(build_fn=create_model, verbose=1)\n"
     ]
    }
   ],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "# create model\n",
    "model = KerasClassifier(build_fn=create_model, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "#batch_size = [x for x in range(32, 100, 32)]\n",
    "epochs = [x for x in range(25, 78, 25)]\n",
    "#optimizer = ['SGD', 'Adam', 'Adamax', 'Nadam'] #'RMSprop', 'Adagrad', 'Adadelta',\n",
    "#loss = [\"binary_crossentropy\", 'categorical_crossentropy', 'sparse_categorical_crossentropy'] #'poisson', 'kl_divergence',\n",
    "#init_mode = ['uniform', 'normal'] #'lecun_uniform', 'zero', 'glorot_normal', 'glorot_uniform', 'he_normal', 'he_uniform'\n",
    "#activation_hidden = ['softmax', 'sigmoid', 'linear'] #'softplus', 'softsign', 'relu', 'tanh', 'hard_sigmoid'\n",
    "#activation_output = ['softmax', 'sigmoid', 'linear'] #'softplus', 'softsign', 'relu', 'tanh', 'hard_sigmoid'\n",
    "#dropout_rate = [x * 0.1 for x in range(0, 4, 1)]\n",
    "layers = [x for x in range(2, 4, 1)]\n",
    "neurons = [x for x in range(20, 65, 20)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'epochs': [25, 50, 75], 'neurons': [20, 40, 60], 'layers': [2, 3]}"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = dict(# batch_size=batch_size, \n",
    "                  epochs=epochs, \n",
    "                #   init = init_mode, \n",
    "                #   activation_hidden = activation_hidden, \n",
    "                #   activation_output = activation_output, \n",
    "                #   dropout_rate = dropout_rate, \n",
    "                #   loss = loss, \n",
    "                #   optimizer = optimizer,\n",
    "                  neurons = neurons,\n",
    "                  layers = layers\n",
    "                 )\n",
    "param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:26:26.820083: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-01-09 14:26:26.820226: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2022-01-09 14:26:26.820337: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-01-09 14:26:26.820607: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2022-01-09 14:26:26.820943: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-01-09 14:26:26.820941: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-01-09 14:26:26.821362: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2022-01-09 14:26:26.821571: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2022-01-09 14:26:26.822038: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-01-09 14:26:26.822235: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2022-01-09 14:26:26.823888: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-01-09 14:26:26.824074: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2022-01-09 14:26:26.825262: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-01-09 14:26:26.825514: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2022-01-09 14:26:26.826811: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-01-09 14:26:26.827051: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n",
      "\n",
      "systemMemory: 16.00 GB\n",
      "maxCacheSize: 5.33 GB\n",
      "\n",
      "Metal device set to: Apple M1\n",
      "\n",
      "systemMemory: 16.00 GB\n",
      "maxCacheSize: 5.33 GB\n",
      "\n",
      "Metal device set to: Apple M1\n",
      "\n",
      "systemMemory: 16.00 GB\n",
      "maxCacheSize: 5.33 GB\n",
      "\n",
      "Metal device set to: Apple M1\n",
      "\n",
      "systemMemory: 16.00 GB\n",
      "maxCacheSize: 5.33 GB\n",
      "\n",
      "Metal device set to: Apple M1\n",
      "\n",
      "systemMemory: 16.00 GB\n",
      "maxCacheSize: 5.33 GB\n",
      "\n",
      "Metal device set to: Apple M1\n",
      "\n",
      "systemMemory: 16.00 GB\n",
      "maxCacheSize: 5.33 GB\n",
      "\n",
      "Metal device set to: Apple M1\n",
      "\n",
      "systemMemory: 16.00 GB\n",
      "maxCacheSize: 5.33 GB\n",
      "\n",
      "Metal device set to: Apple M1\n",
      "\n",
      "systemMemory: 16.00 GB\n",
      "maxCacheSize: 5.33 GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:26:27.851434: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2022-01-09 14:26:27.886998: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2022-01-09 14:26:27.887123: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2022-01-09 14:26:27.895306: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2022-01-09 14:26:27.899380: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2022-01-09 14:26:27.899398: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2022-01-09 14:26:27.904141: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2022-01-09 14:26:27.912289: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "Epoch 1/25\n",
      "Epoch 1/25\n",
      "Epoch 1/25\n",
      "Epoch 1/25\n",
      "Epoch 1/25\n",
      "Epoch 1/25\n",
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:26:28.322325: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-01-09 14:26:28.322348: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-01-09 14:26:28.322349: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-01-09 14:26:28.323989: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-01-09 14:26:28.330891: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-01-09 14:26:28.337182: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-01-09 14:26:28.344666: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-01-09 14:26:28.371973: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 1s 36ms/step - loss: 1.6983 - accuracy: 0.2612- loss: 1.6114 - accuracy: 0.3359 - ETA: 0s - loss: 1.5278 - accuracy: 0.34\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 1.5425 - accuracy: 0.3750Epoch 2/25\n",
      "14/14 [==============================] - 1s 36ms/step - loss: 1.5058 - accuracy: 0.3616\n",
      "Epoch 2/25\n",
      "14/14 [==============================]14/14 [==============================] - 1s 38ms/step - loss: 1.5343 - accuracy: 0.3839\n",
      " - 1s 39ms/step - loss: 1.4487 - accuracy: 0.3884\n",
      "Epoch 2/25\n",
      "Epoch 2/25\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 1.6060 - accuracy: 0.3237\n",
      "Epoch 2/25\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 1.5933 - accuracy: 0.3393\n",
      "14/14 [==============================]\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 1.6791 - accuracy: 0.2478\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 1.4000 - accuracy: 0.5000Epoch 2/25\n",
      "14/14 [==============================] - 1s 45ms/step - loss: 1.7220 - accuracy: 0.3192\n",
      "Epoch 2/25\n",
      "14/14 [==============================] - 0s 22ms/step - loss: 1.4399 - accuracy: 0.3661\n",
      "Epoch 3/25\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 1.3527 - accuracy: 0.4710\n",
      "Epoch 3/25\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 1.3268 - accuracy: 0.4598\n",
      "Epoch 3/25\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.8170 - accuracy: 0.7366\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 1.1160 - accuracy: 0.5312Epoch 3/25\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 1.1666 - accuracy: 0.5268\n",
      "Epoch 3/25\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 1.3133 - accuracy: 0.4420\n",
      "Epoch 3/25\n",
      "14/14 [==============================] - 1s 36ms/step - loss: 1.4971 - accuracy: 0.3259\n",
      "Epoch 3/25\n",
      "14/14 [==============================] - 0s 23ms/step - loss: 1.3135 - accuracy: 0.3683A: 0s - loss: 1.1151 - accuracy: 0.52TA: 0s - loss: 1.1220 - accuracy: 0.53\n",
      "Epoch 4/25\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 1.2876 - accuracy: 0.4531\n",
      "Epoch 3/25\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 1.1537 - accuracy: 0.5134A: 0s - loss: 0.4534 - accuracy: 0.85\n",
      "Epoch 4/25\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 1.1513 - accuracy: 0.5112\n",
      "Epoch 4/25\n",
      "14/14 [==============================] - 0s 20ms/step - loss: 1.1297 - accuracy: 0.4531\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 1.3841 - accuracy: 0.3993Epoch 5/25\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.4261 - accuracy: 0.8527\n",
      "Epoch 4/25\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.9375 - accuracy: 0.6004\n",
      "Epoch 4/25\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 1.3789 - accuracy: 0.4040\n",
      "Epoch 4/25\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 1.1196 - accuracy: 0.5290\n",
      "Epoch 4/25\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.9212 - accuracy: 0.6674A: 0s - loss: 0.9306 - accuracy: 0.67\n",
      " 5/14 [=========>....................] - ETA: 0s - loss: 0.2670 - accuracy: 0.9000Epoch 4/25\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.9177 - accuracy: 0.5826\n",
      "Epoch 5/25\n",
      "14/14 [==============================] - 0s 24ms/step - loss: 0.9069 - accuracy: 0.6027\n",
      "Epoch 6/25\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.9881 - accuracy: 0.5246- loss: 0.7501 - accuracy: 0.6875 - ETA: 0s - loss: 0.9624 - accuracy: 0.55\n",
      " 4/14 [=======>......................] - ETA: 0s - loss: 0.7369 - accuracy: 0.6953Epoch 5/25\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.2221 - accuracy: 0.9263\n",
      "Epoch 5/25\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.7017 - accuracy: 0.7121\n",
      "Epoch 5/25\n",
      "14/14 [==============================] - 0s 21ms/step - loss: 0.7162 - accuracy: 0.6741\n",
      "Epoch 7/25\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 0.8341 - accuracy: 0.5692\n",
      "Epoch 6/25\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 1.2438 - accuracy: 0.4196\n",
      "Epoch 5/25\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.9259 - accuracy: 0.5670\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 0.8020 - accuracy: 0.5521Epoch 5/25\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.6143 - accuracy: 0.7656\n",
      "Epoch 5/25\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.8814 - accuracy: 0.5379\n",
      "Epoch 6/25\n",
      "14/14 [==============================] - 0s 22ms/step - loss: 0.6214 - accuracy: 0.6763\n",
      " 5/14 [=========>....................] - ETA: 0s - loss: 0.4300 - accuracy: 0.8562Epoch 8/25\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.7476 - accuracy: 0.5982- loss: 0.9107 - accuracy: 0.5052 - ETA: 0s - loss: 0.0988 - accuracy: 0.97\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 0.4172 - accuracy: 0.8616Epoch 7/25\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.0956 - accuracy: 0.9732\n",
      "Epoch 6/25\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.5178 - accuracy: 0.8058\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.1698 - accuracy: 0.9688Epoch 6/25\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.3912 - accuracy: 0.8549A: 0s - loss: 0.6517 - accuracy: 0.\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 0.0678 - accuracy: 0.9955Epoch 6/25\n",
      "14/14 [==============================] - 0s 22ms/step - loss: 0.5332 - accuracy: 0.6897\n",
      "Epoch 9/25\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.7760 - accuracy: 0.6027\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.2373 - accuracy: 0.8750Epoch 6/25\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 1.0685 - accuracy: 0.4531\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.8339 - accuracy: 0.5960\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.5197 - accuracy: 0.6875Epoch 6/25\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.8986 - accuracy: 0.5000Epoch 7/25\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.7008 - accuracy: 0.6696\n",
      "Epoch 8/25\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.0471 - accuracy: 0.9955\n",
      "Epoch 7/25\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.4205 - accuracy: 0.8237\n",
      "11/14 [======================>.......] - ETA: 0s - loss: 0.4962 - accuracy: 0.7131Epoch 7/25\n",
      "14/14 [==============================] - 0s 22ms/step - loss: 0.4905 - accuracy: 0.7321\n",
      "Epoch 10/25\n",
      "14/14 [==============================] - 0s 24ms/step - loss: 0.6556 - accuracy: 0.7009\n",
      "Epoch 9/25\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.7334 - accuracy: 0.7054A: 0s - loss: 0.6838 - accuracy: 0.65\n",
      "Epoch 8/25\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.2582 - accuracy: 0.8862\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.9367 - accuracy: 0.4978\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.4718 - accuracy: 0.8750Epoch 7/25\n",
      "Epoch 7/25\n",
      "14/14 [==============================] 9/14 [==================>...........] - 1s 39ms/step - loss: 0.7088 - accuracy: 0.6161\n",
      " - ETA: 0s - loss: 0.4420 - accuracy: 0.7882Epoch 7/25\n",
      "14/14 [==============================] - 0s 21ms/step - loss: 0.4258 - accuracy: 0.7946- loss: 0.9876 - accuracy: 0.4375 - ETA: 0s - loss: 0.0298 - accuracy: 0.99\n",
      " 5/14 [=========>....................] - ETA: 0s - loss: 0.5267 - accuracy: 0.8125Epoch 11/25\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.0294 - accuracy: 0.9933\n",
      "Epoch 8/25\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.4096 - accuracy: 0.8036\n",
      "Epoch 8/25\n",
      "14/14 [==============================] - 0s 24ms/step - loss: 0.6061 - accuracy: 0.7054\n",
      "11/14 [======================>.......] - ETA: 0s - loss: 0.6455 - accuracy: 0.7244Epoch 10/25\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0195 - accuracy: 1.0000 - 0s 30ms/step - loss: 0.6344 - accuracy: 0.7433\n",
      "Epoch 9/25\n",
      "14/14 [==============================] - 0s 20ms/step - loss: 0.4045 - accuracy: 0.8125\n",
      "Epoch 12/25\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.1961 - accuracy: 0.9286\n",
      "Epoch 8/25\n",
      "14/14 [==============================] - 1s 36ms/step - loss: 0.9290 - accuracy: 0.5179\n",
      "Epoch 8/25\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.6295 - accuracy: 0.6317\n",
      "Epoch 8/25\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.3554 - accuracy: 0.8237\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.0143 - accuracy: 1.0000\n",
      "Epoch 9/25\n",
      "Epoch 9/25\n",
      "14/14 [==============================] - 0s 24ms/step - loss: 0.5531 - accuracy: 0.6920\n",
      "Epoch 11/25\n",
      "14/14 [==============================] - 0s 19ms/step - loss: 0.4022 - accuracy: 0.7768\n",
      "Epoch 13/25\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.5945 - accuracy: 0.7679\n",
      "Epoch 10/25\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.1467 - accuracy: 0.9576- loss: 0.9091 - accuracy: 0.5486 - ETA: 0s - loss: 0.0489 - accuracy: 0.\n",
      "Epoch 9/25\n",
      "14/14 [==============================] - 0s 21ms/step - loss: 0.3998 - accuracy: 0.7835\n",
      "Epoch 14/25\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.6408 - accuracy: 0.6295\n",
      "Epoch 9/25\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.8823 - accuracy: 0.5871\n",
      "Epoch 9/25\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.5632 - accuracy: 0.7232\n",
      "Epoch 12/25\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.0417 - accuracy: 0.9911\n",
      "Epoch 10/25\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.3966 - accuracy: 0.8170\n",
      "Epoch 10/25\n",
      "14/14 [==============================] - 0s 18ms/step - loss: 0.3146 - accuracy: 0.8214A: 0s - loss: 0.0129 - accuracy: 1.00\n",
      " 5/14 [=========>....................] - ETA: 0s - loss: 0.0209 - accuracy: 1.0000Epoch 15/25\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.6595 - accuracy: 0.6942\n",
      "Epoch 11/25\n",
      "14/14 [==============================] - 0s 21ms/step - loss: 0.5501 - accuracy: 0.7009\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 0.3093 - accuracy: 0.8705Epoch 13/25\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.3113 - accuracy: 0.8571\n",
      " - 0s 33ms/step - loss: 0.6126 - accuracy: 0.6161\n",
      " 8/14 [================>.............] - ETA: 0s - loss: 0.5385 - accuracy: 0.7695Epoch 11/25\n",
      "Epoch 10/25\n",
      "14/14 [==============================] - 0s 18ms/step - loss: 0.2992 - accuracy: 0.8661- loss: 0.0218 - accuracy: 0.9928 - ETA: 0s - loss: 0.1304 - accuracy: 0.95\n",
      "Epoch 16/25\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.0206 - accuracy: 0.9933\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.8543 - accuracy: 0.6272\n",
      "Epoch 11/25\n",
      "Epoch 10/25\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.1275 - accuracy: 0.9554\n",
      "Epoch 10/25\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.5349 - accuracy: 0.7746\n",
      "Epoch 12/25\n",
      "14/14 [==============================] - 0s 21ms/step - loss: 0.5298 - accuracy: 0.6987\n",
      "Epoch 14/25\n",
      "14/14 [==============================] - 0s 17ms/step - loss: 0.3218 - accuracy: 0.8237- loss: 0.5830 - accuracy: 0.6562 - ETA: 0s - loss: 0.0220 - accuracy: 0.99\n",
      "Epoch 17/25\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.3179 - accuracy: 0.8594\n",
      "Epoch 12/25\n",
      "14/14 [==============================]11/14 [======================>.......] - 0s 30ms/step - loss: 0.0241 - accuracy: 0.9933\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.5701 - accuracy: 0.6652\n",
      "Epoch 12/25\n",
      "Epoch 11/25\n",
      "14/14 [==============================] - 0s 21ms/step - loss: 0.5306 - accuracy: 0.6964\n",
      "Epoch 15/25\n",
      "14/14 [==============================] - 0s 18ms/step - loss: 0.2363 - accuracy: 0.8862\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.5935 - accuracy: 0.6562Epoch 18/25\n",
      "14/14 [==============================] - 0s 36ms/step - loss: 0.8166 - accuracy: 0.6741\n",
      "Epoch 11/25\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.0786 - accuracy: 0.9777\n",
      "Epoch 11/25\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.4747 - accuracy: 0.8482\n",
      "Epoch 13/25\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.3843 - accuracy: 0.8460\n",
      " 8/14 [================>.............] - ETA: 0s - loss: 0.4513 - accuracy: 0.8711Epoch 13/25\n",
      "14/14 [==============================] - 0s 21ms/step - loss: 0.2619 - accuracy: 0.8616\n",
      "14/14 [==============================] - 0s 24ms/step - loss: 0.5046 - accuracy: 0.7366\n",
      "Epoch 19/25\n",
      "Epoch 16/25\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.0150 - accuracy: 0.9978- loss: 0.5203 - accuracy: 0.6847 - ETA: 0s - loss: 0.7650 - accuracy: 0.72\n",
      "Epoch 13/25\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.5399 - accuracy: 0.6786\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.4665 - accuracy: 0.8549\n",
      "Epoch 12/25\n",
      "Epoch 14/25\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.7677 - accuracy: 0.7165\n",
      "Epoch 12/25\n",
      "14/14 [==============================] - 1s 35ms/step - loss: 0.0383 - accuracy: 0.9911\n",
      "Epoch 12/25\n",
      "14/14 [==============================] - 0s 17ms/step - loss: 0.2672 - accuracy: 0.8415\n",
      "Epoch 20/25\n",
      "14/14 [==============================] - 0s 22ms/step - loss: 0.4661 - accuracy: 0.7991A: 0s - loss: 0.0151 - accuracy: 1.00\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 0.7856 - accuracy: 0.6771Epoch 17/25\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.3389 - accuracy: 0.8549\n",
      "11/14 [======================>.......] - ETA: 0s - loss: 0.4175 - accuracy: 0.8494Epoch 14/25\n",
      "14/14 [==============================] - 0s 18ms/step - loss: 0.2165 - accuracy: 0.8839\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.4163 - accuracy: 0.8558Epoch 21/25\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.4274 - accuracy: 0.8571\n",
      "Epoch 15/25\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.0116 - accuracy: 1.0000\n",
      "11/14 [======================>.......] - ETA: 0s - loss: 0.7448 - accuracy: 0.7188Epoch 14/25\n",
      "14/14 [==============================] - 0s 21ms/step - loss: 0.5156 - accuracy: 0.7946\n",
      "Epoch 18/25\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.5269 - accuracy: 0.6897\n",
      "Epoch 13/25\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.7663 - accuracy: 0.7121\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.0480 - accuracy: 0.9832Epoch 13/25\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.0461 - accuracy: 0.9844\n",
      "Epoch 13/25\n",
      "14/14 [==============================] - 0s 18ms/step - loss: 0.2516 - accuracy: 0.8683\n",
      "Epoch 22/25\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.2947 - accuracy: 0.8795\n",
      "Epoch 15/25\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.4034 - accuracy: 0.8795\n",
      "Epoch 16/25\n",
      "14/14 [==============================] - 0s 23ms/step - loss: 0.5095 - accuracy: 0.7969A: 0s - loss: 0.7627 - accuracy: 0.70\n",
      "Epoch 19/25\n",
      "14/14 [==============================] - 0s 19ms/step - loss: 0.2451 - accuracy: 0.8795\n",
      "Epoch 23/25\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.0046 - accuracy: 1.0000\n",
      "Epoch 15/25\n",
      "14/14 [==============================] - 1s 36ms/step - loss: 0.5220 - accuracy: 0.7031- loss: 0.4538 - accuracy: 0.7813 - ETA: 0s - loss: 0.4282 - accuracy: 0.88\n",
      "Epoch 14/25\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.7626 - accuracy: 0.7143\n",
      "Epoch 14/25\n",
      "14/14 [==============================] - 0s 22ms/step - loss: 0.4546 - accuracy: 0.8036\n",
      "14/14 [==============================] - 0s 36ms/step - loss: 0.0334 - accuracy: 0.9844\n",
      "Epoch 20/25\n",
      "Epoch 14/25\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.2342 - accuracy: 0.9063\n",
      "Epoch 16/25\n",
      "14/14 [==============================] - 0s 17ms/step - loss: 0.2644 - accuracy: 0.8884\n",
      "Epoch 24/25\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.4174 - accuracy: 0.8906\n",
      "Epoch 17/25\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0059 - accuracy: 0.9978A: 0s - loss: 0.0142 - accuracy: 0.99\n",
      "Epoch 16/25\n",
      "14/14 [==============================] - 0s 18ms/step - loss: 0.2482 - accuracy: 0.8571\n",
      "Epoch 25/25\n",
      "14/14 [==============================] - 0s 22ms/step - loss: 0.4721 - accuracy: 0.8036\n",
      "Epoch 21/25\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.4847 - accuracy: 0.7589\n",
      "Epoch 15/25\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.7510 - accuracy: 0.7210\n",
      " 4/14 [=======>......................] - ETA: 0s - loss: 0.4226 - accuracy: 0.8203Epoch 15/25\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.2126 - accuracy: 0.9152\n",
      "Epoch 17/25\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.3345 - accuracy: 0.8996\n",
      "Epoch 18/25\n",
      "14/14 [==============================] - 1s 36ms/step - loss: 0.0679 - accuracy: 0.9710\n",
      "Epoch 15/25\n",
      "14/14 [==============================] - 0s 20ms/step - loss: 0.2222 - accuracy: 0.9018- loss: 0.1563 - accuracy: 0.9479 - ETA: 0s - loss: 0.5382 - accuracy: 0.66\n",
      "14/14 [==============================] - 0s 21ms/step - loss: 0.4677 - accuracy: 0.8147\n",
      "Epoch 22/25\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.0072 - accuracy: 0.9978\n",
      "Epoch 17/25\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.5320 - accuracy: 0.7098\n",
      "Epoch 16/25\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.7261 - accuracy: 0.7260"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:26:36.263237: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 29ms/step - loss: 0.1886 - accuracy: 0.9196\n",
      "Epoch 18/25\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.3906 - accuracy: 0.8862\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.4801 - accuracy: 0.8053Epoch 19/25\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.7317 - accuracy: 0.7210\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.1096 - accuracy: 0.9688Epoch 16/25\n",
      "14/14 [==============================] - 0s 19ms/step - loss: 0.4859 - accuracy: 0.8080\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0979 - accuracy: 0.9375Epoch 23/25\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.1680 - accuracy: 0.8750ETA: 0s - loss: 0.1504 - accuracy: 0.9375\n",
      "[CV 1/5] END ...epochs=25, layers=2, neurons=20;, score=0.875 total time=   9.8s\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.0649 - accuracy: 0.9799\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 0.7784 - accuracy: 0.7292Epoch 16/25\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.0078 - accuracy: 0.9978\n",
      "Epoch 18/25\n",
      "14/14 [==============================] - 0s 22ms/step - loss: 0.4832 - accuracy: 0.7857\n",
      "Epoch 24/25\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.3305 - accuracy: 0.9152\n",
      "Epoch 20/25\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.2071 - accuracy: 0.9263\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.4629 - accuracy: 0.8005Epoch 19/25\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.4544 - accuracy: 0.8058\n",
      "Epoch 17/25\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.7231 - accuracy: 0.7254\n",
      "Epoch 17/25\n",
      "14/14 [==============================] - 1s 35ms/step - loss: 0.0393 - accuracy: 0.9888- loss: 0.3249 - accuracy: 0.9375 - ETA: 0s - loss: 0.0044 - accuracy: 1.00\n",
      "Epoch 17/25\n",
      "14/14 [==============================] - 0s 20ms/step - loss: 0.4737 - accuracy: 0.8348A: 0s - loss: 0.4931 - accuracy: 0.75\n",
      "Epoch 25/25\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0047 - accuracy: 1.0000\n",
      "Epoch 19/25\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.3308 - accuracy: 0.9353A: 0s - loss: 0.6884 - accuracy: 0.7312\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.7514 - accuracy: 0.7188Epoch 21/25\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.2528 - accuracy: 0.8918Epoch 1/25\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.2554 - accuracy: 0.8951\n",
      " 7/14 [==============>...............]Epoch 20/25- loss: 0.7273 - accuracy: 0.71\n",
      "14/14 [==============================] - 0s 22ms/step - loss: 0.4187 - accuracy: 0.8326\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.7145 - accuracy: 0.7236 - 0s 36ms/step - loss: 0.4704 - accuracy: 0.7656\n",
      "Epoch 18/25\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.7237 - accuracy: 0.7210\n",
      "Epoch 18/25\n",
      " 5/14 [=========>....................] - ETA: 0s - loss: 0.2382 - accuracy: 0.9000 - ETA: 0s - loss: 0.3027 - accuracy: 0.9414"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:26:37.320462: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-01-09 14:26:37.507672: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 32ms/step - loss: 0.0335 - accuracy: 0.9866\n",
      "Epoch 18/25\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.0248 - accuracy: 0.9933\n",
      "Epoch 20/25\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.3065 - accuracy: 0.9353- loss: 0.4751 - accuracy: 0.7734 - ETA: 0s - loss: 0.0357 - accuracy: 0.98\n",
      "Epoch 22/25\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.2090 - accuracy: 0.9129\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 0.0571 - accuracy: 0.9732Epoch 21/25\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.2677 - accuracy: 0.8750\n",
      "[CV 3/5] END ...epochs=25, layers=2, neurons=40;, score=0.875 total time=  11.0s\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.4569 - accuracy: 0.7902\n",
      " 6/14 [===========>..................] - ETA: 0s - loss: 0.3332 - accuracy: 0.9323Epoch 19/25\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.7194 - accuracy: 0.7143\n",
      "Epoch 19/25\n",
      "14/14 [==============================] - 1s 30ms/step - loss: 2.0455 - accuracy: 0.3259A: 0s - loss: 0.3737 - accuracy: 0.8750 - ETA: 0s - loss: 2.0455 - accuracy: 0.32\n",
      " 8/14 [================>.............] - ETA: 0s - loss: 0.2356 - accuracy: 0.8945Epoch 2/25\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.0249 - accuracy: 0.9933\n",
      " 5/14 [=========>....................] - ETA: 0s - loss: 0.7144 - accuracy: 0.7250Epoch 19/25\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.0538 - accuracy: 0.9754\n",
      "Epoch 21/25\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.2951 - accuracy: 0.9330A: 0s - loss: 0.2371 - accuracy: 0.8969\n",
      "Epoch 23/25\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.2228 - accuracy: 0.9018\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 0.2842 - accuracy: 0.9479Epoch 22/25\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.4512 - accuracy: 0.8371\n",
      " 4/14 [=======>......................] - ETA: 0s - loss: 0.2683 - accuracy: 0.8906Epoch 20/25\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.6989 - accuracy: 0.7254A: 0s - loss: 0.6989 - accuracy: 0.72\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 0.2930 - accuracy: 0.9375Epoch 20/25\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 1.2821 - accuracy: 0.4330\n",
      "Epoch 3/25\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.0567 - accuracy: 0.9777\n",
      "Epoch 22/25\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 0.0197 - accuracy: 0.9888\n",
      "11/14 [======================>.......] - ETA: 0s - loss: 0.2638 - accuracy: 0.8835Epoch 20/25\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.2895 - accuracy: 0.9286\n",
      "Epoch 24/25\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.2596 - accuracy: 0.8862\n",
      "Epoch 23/25\n",
      "14/14 [==============================] - 0s 22ms/step - loss: 0.8379 - accuracy: 0.7121\n",
      " - ETA: 0s - loss: 0.7230 - accuracy: 0.7049Epoch 4/25\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 0.2349 - accuracy: 0.8750Epoch 1/25 - loss: 0.0998 - accuracy: 0.97\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.7228 - accuracy: 0.7121\n",
      "Epoch 21/25\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.4164 - accuracy: 0.8571\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 0.2478 - accuracy: 0.8750Epoch 21/25\n",
      "14/14 [==============================] - 0s 19ms/step - loss: 0.4441 - accuracy: 0.8683\n",
      "Epoch 5/25\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.2709 - accuracy: 0.9375\n",
      "Epoch 25/25\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.1372 - accuracy: 0.9442\n",
      "Epoch 23/25\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.2484 - accuracy: 0.8918"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:26:39.015980: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - ETA: 0s - loss: 0.0114 - accuracy: 0.9978 - 0s 32ms/step - loss: 0.2538 - accuracy: 0.8906\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.0114 - accuracy: 0.9978\n",
      " 2/14 [===>..........................] - ETA: 0s - loss: 0.0715 - accuracy: 0.9844Epoch 24/25\n",
      "Epoch 21/25\n",
      "14/14 [==============================] - 0s 24ms/step - loss: 0.2507 - accuracy: 0.9063A: 0s - loss: 0.2714 - accuracy: 0.\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.4194 - accuracy: 0.8534Epoch 6/25\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.6905 - accuracy: 0.7277\n",
      "Epoch 22/25\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.4275 - accuracy: 0.8549A: 0s - loss: 0.1816 - accuracy: 0.90\n",
      "Epoch 22/25\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.2638 - accuracy: 0.9375\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.2069 - accuracy: 0.9063\n",
      "Epoch 25/25\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.0720 - accuracy: 0.9688\n",
      "11/14 [======================>.......] - ETA: 0s - loss: 0.0092 - accuracy: 0.9943Epoch 24/25\n",
      "14/14 [==============================] - 1s 30ms/step - loss: 1.4957 - accuracy: 0.3929\n",
      "Epoch 2/25\n",
      "14/14 [==============================] - 0s 23ms/step - loss: 0.1937 - accuracy: 0.9129\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.0103 - accuracy: 0.9928Epoch 7/25\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.0111 - accuracy: 0.9933\n",
      "Epoch 22/25\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.4545 - accuracy: 0.8214\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 1.1553 - accuracy: 0.5848Epoch 23/25\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.6870 - accuracy: 0.7254\n",
      "Epoch 23/25\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.2210 - accuracy: 0.8973\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 1.0506 - accuracy: 0.5938\n",
      "Epoch 3/25\n",
      "14/14 [==============================] - 0s 23ms/step - loss: 0.1887 - accuracy: 0.9107\n",
      "Epoch 8/25\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0377 - accuracy: 0.9866\n",
      "Epoch 25/25\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0085 - accuracy: 0.9955A: 0s - loss: 0.7832 - accuracy: 0.74\n",
      "Epoch 23/25\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.0943 - accuracy: 1.0000\n",
      "[CV 3/5] END ...epochs=25, layers=2, neurons=20;, score=1.000 total time=  13.4s\n",
      " 5/14 [=========>....................] - ETA: 0s - loss: 0.0236 - accuracy: 0.9938"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:26:39.889942: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 28ms/step - loss: 0.6759 - accuracy: 0.7321\n",
      "Epoch 24/25\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.4169 - accuracy: 0.8482\n",
      "Epoch 24/25\n",
      "14/14 [==============================] - 0s 23ms/step - loss: 0.1531 - accuracy: 0.9263\n",
      "Epoch 9/25\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 0.6208 - accuracy: 0.8147\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0275 - accuracy: 1.0000Epoch 4/25\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.5141 - accuracy: 0.8438"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:26:40.183107: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 31ms/step - loss: 0.0267 - accuracy: 0.9866\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.0534 - accuracy: 0.9911\n",
      "[CV 2/5] END ...epochs=25, layers=2, neurons=20;, score=0.991 total time=  13.8s\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.0250 - accuracy: 0.9933\n",
      "Epoch 24/25\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.6688 - accuracy: 0.7299\n",
      "Epoch 25/25\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.4253 - accuracy: 0.8438\n",
      "Epoch 25/25\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 0.1602 - accuracy: 0.9129\n",
      "Epoch 10/25\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.3276 - accuracy: 0.9174\n",
      "Epoch 5/25\n",
      " 5/14 [=========>....................] - ETA: 0s - loss: 0.0926 - accuracy: 0.9688: 0s - loss: 0.6711 - accuracy: 0.7188 - ETA: 0s - loss: 0.3171 - accuracy: 0.87"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:26:40.709284: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 32ms/step - loss: 0.0234 - accuracy: 0.9955\n",
      "Epoch 25/25\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.0143 - accuracy: 0.9911\n",
      "[CV 2/5] END ...epochs=25, layers=2, neurons=40;, score=0.991 total time=  14.3s\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.1226 - accuracy: 0.9442\n",
      "Epoch 11/25\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.6430 - accuracy: 0.7366\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.4423 - accuracy: 0.8259\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.2361 - accuracy: 0.9375\n",
      "Epoch 6/25\n",
      "14/14 [==============================] - 0s 19ms/step - loss: 0.1230 - accuracy: 0.9263\n",
      "14/14 [==============================] - 0s 20ms/step - loss: 0.0097 - accuracy: 1.0000\n",
      "Epoch 12/25\n",
      "Epoch 1/25\n",
      "14/14 [==============================] - 0s 23ms/step - loss: 0.1519 - accuracy: 0.9464\n",
      "Epoch 7/25\n",
      "Epoch 1/25\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.0870 - accuracy: 0.9643\n",
      " 5/14 [=========>....................] - ETA: 0s - loss: 0.1400 - accuracy: 0.9500Epoch 13/25\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.3737 - accuracy: 0.9479"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:26:41.417524: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-01-09 14:26:41.418434: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-01-09 14:26:41.498589: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-01-09 14:26:41.555997: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 36ms/step - loss: 0.3734 - accuracy: 0.9554\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.4775 - accuracy: 0.8929\n",
      "[CV 4/5] END ...epochs=25, layers=2, neurons=20;, score=0.893 total time=  15.0s\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "[CV 1/5] END ...epochs=25, layers=2, neurons=40;, score=1.000 total time=  15.1s\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.1090 - accuracy: 0.9519[CV 5/5] END ...epochs=25, layers=2, neurons=20;, score=0.955 total time=  15.1s\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 0.1082 - accuracy: 0.9509\n",
      "Epoch 8/25\n",
      " - ETA: 0s - loss: 0.1482 - accuracy: 0.9271 4/14 [=======>......................] - ETA: 0s - loss: 3.1996 - accuracy: 0.2734\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:26:41.723133: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 25ms/step - loss: 0.1208 - accuracy: 0.9397- loss: 0.1322 - accuracy: 0.9318 - ETA: 0s - loss: 0.1427 - accuracy: 0.94\n",
      "Epoch 14/25\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 3.1961 - accuracy: 0.1771Epoch 1/25\n",
      "14/14 [==============================] - 1s 32ms/step - loss: 2.1690 - accuracy: 0.2857\n",
      "Epoch 2/25\n",
      " 6/14 [===========>..................] - ETA: 0s - loss: 0.0948 - accuracy: 0.9583"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:26:42.127205: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 36ms/step - loss: 0.1257 - accuracy: 0.9487\n",
      "Epoch 9/25\n",
      "14/14 [==============================] - 1s 36ms/step - loss: 0.0955 - accuracy: 0.9643A: 4s - loss: 1.9294 - accuracy: 0.\n",
      "Epoch 15/25\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 1.9482 - accuracy: 0.3393\n",
      " - ETA: 0s - loss: 3.4102 - accuracy: 0.2812Epoch 2/25\n",
      " 4/14 [=======>......................] - ETA: 0s - loss: 2.8452 - accuracy: 0.2266Epoch 1/25\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 1.3874 - accuracy: 0.4688A: 0s - loss: 0.0816 - accuracy: 0.95\n",
      "Epoch 1/25\n",
      " 4/14 [=======>......................] - ETA: 0s - loss: 1.4271 - accuracy: 0.3906Epoch 3/25\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.0714 - accuracy: 0.9665\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 2.2096 - accuracy: 0.2469Epoch 10/25\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.0657 - accuracy: 0.9688Epoch 1/25\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.0956 - accuracy: 0.9665A: 0s - loss: 1.0546 - accuracy: 0.57\n",
      "Epoch 16/25\n",
      "14/14 [==============================] - 1s 34ms/step - loss: 2.0415 - accuracy: 0.2790\n",
      "Epoch 2/25\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 1.3546 - accuracy: 0.4375\n",
      "Epoch 3/25\n",
      "14/14 [==============================] - 0s 24ms/step - loss: 1.0030 - accuracy: 0.5804\n",
      "Epoch 4/25\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.0832 - accuracy: 0.9621\n",
      "Epoch 11/25\n",
      "14/14 [==============================] - 0s 22ms/step - loss: 0.0812 - accuracy: 0.9732\n",
      "Epoch 17/25\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 1.3923 - accuracy: 0.4174\n",
      "Epoch 3/25\n",
      "14/14 [==============================] - 0s 24ms/step - loss: 0.9667 - accuracy: 0.6228\n",
      "Epoch 4/25\n",
      "14/14 [==============================] - 0s 22ms/step - loss: 0.7893 - accuracy: 0.7009\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.6955 - accuracy: 0.6875Epoch 5/25\n",
      "14/14 [==============================] - 0s 20ms/step - loss: 0.0678 - accuracy: 0.9777\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.0709 - accuracy: 0.9712Epoch 12/25\n",
      "14/14 [==============================] - 0s 21ms/step - loss: 0.0727 - accuracy: 0.9710\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.1976 - accuracy: 0.9062"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:26:43.283571: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-01-09 14:26:43.296040: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-01-09 14:26:43.358696: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/25\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 1.1726 - accuracy: 0.5156TA: 0s - loss: 0.0796 - accuracy: 0.96\n",
      "Epoch 4/25\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.9618 - accuracy: 0.5625 - 0s 33ms/step - loss: 0.6677 - accuracy: 0.7545\n",
      " - ETA: 0s - loss: 2.2857 - accuracy: 0.1875Epoch 5/25\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.5299 - accuracy: 0.8304\n",
      "Epoch 6/25\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.0697 - accuracy: 0.9710A: 0s - loss: 2.2830 - accuracy: 0.236A: 0s - loss: 2.0926 - accuracy: 0.\n",
      " 5/14 [=========>....................] - ETA: 0s - loss: 1.6098 - accuracy: 0.2188 - ETA: 0s - loss: 0.3775 - accuracy: 0.8813Epoch 13/25\n",
      "14/14 [==============================] - 1s 35ms/step - loss: 0.0683 - accuracy: 0.9732\n",
      " 6/14 [===========>..................]Epoch 19/25- loss: 0.4439 - accuracy: 0.83\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.9276 - accuracy: 0.5759A: 0s - loss: 0.1097 - accuracy: 0.96\n",
      "11/14 [======================>.......] - ETA: 0s - loss: 1.8972 - accuracy: 0.2500Epoch 5/25\n",
      "14/14 [==============================] - 0s 36ms/step - loss: 0.4002 - accuracy: 0.8482\n",
      "14/14 [==============================]Epoch 6/25 - loss: 0.8456 - accuracy: 0.50\n",
      " - 2s 50ms/step - loss: 1.9790 - accuracy: 0.2991\n",
      "11/14 [======================>.......] - ETA: 0s - loss: 1.5608 - accuracy: 0.2955Epoch 2/25\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.3076 - accuracy: 0.9129A: 0s - loss: 1.2748 - accuracy: 0.53TA: 0s - loss: 0.8229 - accuracy: 0.51\n",
      "14/14 [==============================] - 2s 53ms/step - loss: 1.7902 - accuracy: 0.2768\n",
      "Epoch 7/25\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.0823 - accuracy: 0.9757Epoch 2/25 - loss: 0.0725 - accuracy: 0.\n",
      "14/14 [==============================] - 2s 56ms/step - loss: 1.5534 - accuracy: 0.3125A: 0s - loss: 1.5464 - accuracy: 0.3149\n",
      "Epoch 2/25\n",
      "14/14 [==============================] - 1s 36ms/step - loss: 0.0768 - accuracy: 0.9643\n",
      "Epoch 20/25\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 0.0767 - accuracy: 0.9754\n",
      " 6/14 [===========>..................] - ETA: 0s - loss: 0.7139 - accuracy: 0.6615Epoch 14/25\n",
      "14/14 [==============================] - 1s 44ms/step - loss: 0.3047 - accuracy: 0.8929- loss: 1.1568 - accuracy: 0.5868 - ETA: 0s - loss: 1.2576 - accuracy: 0.45\n",
      "Epoch 7/25\n",
      "14/14 [==============================] - 1s 55ms/step - loss: 0.6430 - accuracy: 0.7031\n",
      "Epoch 6/25\n",
      "14/14 [==============================] - 1s 47ms/step - loss: 0.2055 - accuracy: 0.9509\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.0988 - accuracy: 0.9625Epoch 8/25\n",
      "14/14 [==============================] - 1s 57ms/step - loss: 1.0912 - accuracy: 0.5848\n",
      " 5/14 [=========>....................] - ETA: 0s - loss: 0.2906 - accuracy: 0.9125Epoch 3/25\n",
      "14/14 [==============================] - 1s 49ms/step - loss: 1.1923 - accuracy: 0.5201\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 0.5483 - accuracy: 0.8021Epoch 3/25\n",
      "14/14 [==============================] - 1s 45ms/step - loss: 1.5021 - accuracy: 0.3571\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.7553 - accuracy: 0.7188Epoch 3/25\n",
      "14/14 [==============================] - 1s 46ms/step - loss: 0.1074 - accuracy: 0.9554- loss: 0.2843 - accuracy: 0.9107 - ETA: 0s - loss: 0.5348 - accuracy: 0.7969\n",
      " - ETA: 1s - loss: 0.9294 - accuracy: 0.7812Epoch 21/25\n",
      "14/14 [==============================] - 1s 44ms/step - loss: 0.0932 - accuracy: 0.9621- loss: 0.0932 - accuracy: 0.9621 - ETA: 0s - loss: 0.5189 - accuracy: 0.80\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 0.7656 - accuracy: 0.7396Epoch 15/25\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.2728 - accuracy: 0.9085\n",
      "Epoch 8/25\n",
      "14/14 [==============================] - 1s 35ms/step - loss: 0.1534 - accuracy: 0.9576\n",
      "11/14 [======================>.......] - ETA: 0s - loss: 1.4577 - accuracy: 0.3580Epoch 9/25\n",
      "14/14 [==============================] - 1s 50ms/step - loss: 0.4882 - accuracy: 0.8170\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.0871 - accuracy: 0.9621\n",
      "14/14 [==============================] - 1s 43ms/step - loss: 0.6030 - accuracy: 0.8192\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 1.4358 - accuracy: 0.3683\n",
      "Epoch 7/25\n",
      "Epoch 22/25\n",
      "Epoch 4/25\n",
      "Epoch 4/25\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.7609 - accuracy: 0.7902\n",
      "Epoch 4/25\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.0595 - accuracy: 0.9777\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.2410 - accuracy: 0.9236Epoch 16/25\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.2202 - accuracy: 0.9330A: 0s - loss: 0.0849 - accuracy: 0.98\n",
      "Epoch 9/25\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.1227 - accuracy: 0.9643A: 0s - loss: 1.2948 - accuracy: 0.39\n",
      "Epoch 10/25\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.0623 - accuracy: 0.9598A: 0s - loss: 0.3290 - accuracy: 0.90\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.0805 - accuracy: 0.9792Epoch 23/25\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.3880 - accuracy: 0.8393\n",
      "Epoch 8/25\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 1.2869 - accuracy: 0.3817\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 0.0730 - accuracy: 0.9792Epoch 5/25\n",
      "14/14 [==============================] - 1s 34ms/step - loss: 0.2933 - accuracy: 0.9174\n",
      "Epoch 5/25\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.4407 - accuracy: 0.8594\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.0635 - accuracy: 0.9821\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.3807 - accuracy: 0.8750Epoch 5/25\n",
      " 5/14 [=========>....................] - ETA: 0s - loss: 0.0754 - accuracy: 0.9750Epoch 17/25\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.1229 - accuracy: 0.9598\n",
      "Epoch 11/25\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.1746 - accuracy: 0.9576A: 0s - loss: 0.0654 - accuracy: 0.97\n",
      "14/14 [==============================] - 0s 21ms/step - loss: 0.0593 - accuracy: 0.9799\n",
      "Epoch 10/25\n",
      "Epoch 24/25\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.3310 - accuracy: 0.8973\n",
      "Epoch 9/25\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.1045 - accuracy: 0.9665\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.1870 - accuracy: 0.9576\n",
      "Epoch 18/25\n",
      "Epoch 6/25\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 1.1214 - accuracy: 0.4732\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.2118 - accuracy: 0.9062Epoch 6/25\n",
      "14/14 [==============================] - 1s 35ms/step - loss: 0.2853 - accuracy: 0.9129A: 0s - loss: 0.1488 - accuracy: 0.9570\n",
      "14/14 [==============================] - 0s 24ms/step - loss: 0.0860 - accuracy: 0.9621\n",
      " 4/14 [=======>......................] - ETA: 0s - loss: 0.1433 - accuracy: 0.9375Epoch 6/25\n",
      "Epoch 25/25\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.0974 - accuracy: 0.9710\n",
      "Epoch 12/25\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.1550 - accuracy: 0.9487\n",
      "Epoch 11/25\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.1023 - accuracy: 0.9576\n",
      "Epoch 19/25\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.3034 - accuracy: 0.8862\n",
      "12/14 [========================>.....] - ETA: 0s - loss: 0.1125 - accuracy: 0.9714Epoch 10/25\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 0.0367 - accuracy: 0.9844\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.1047 - accuracy: 0.9732\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.9128 - accuracy: 0.5536\n",
      "Epoch 7/25\n",
      "Epoch 7/25\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.1139 - accuracy: 0.9576 0s - loss: 1.0628 - accuracy: 0.5625\n",
      "Epoch 13/25\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.2021 - accuracy: 0.9375A: 0s - loss: 0.0624 - accuracy: 0.97\n",
      "Epoch 7/25\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.8134 - accuracy: 0.6562 - 0s 31ms/step - loss: 0.1184 - accuracy: 0.9732\n",
      "Epoch 12/25\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0542 - accuracy: 0.9821\n",
      "Epoch 20/25\n",
      "14/14 [==============================] - 1s 36ms/step - loss: 0.2547 - accuracy: 0.9129- loss: 0.1374 - accuracy: 0.9583 - ETA: 0s - loss: 0.2535 - accuracy: 0.91\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.0826 - accuracy: 0.9712Epoch 11/25\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.0862 - accuracy: 0.9688\n",
      "Epoch 14/25\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.0706 - accuracy: 0.9866\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.7494 - accuracy: 0.7054Epoch 8/25\n",
      "14/14 [==============================] - 1s 36ms/step - loss: 0.7494 - accuracy: 0.7054\n",
      "Epoch 8/25\n",
      "14/14 [==============================] 3/14 [=====>........................] - ETA: 0s - loss: 0.2109 - accuracy: 0.9167 - 0s 32ms/step - loss: 0.1862 - accuracy: 0.9308\n",
      " 2/14 [===>..........................] - ETA: 0s - loss: 0.0731 - accuracy: 0.9688Epoch 8/25\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.1399 - accuracy: 0.9621A: 0s - loss: 0.2414 - accuracy: 0.91\n",
      " 6/14 [===========>..................] - ETA: 0s - loss: 0.0850 - accuracy: 0.9635Epoch 13/25\n",
      "14/14 [==============================] - 0s 37ms/step - loss: 0.1356 - accuracy: 0.9487\n",
      "Epoch 21/25\n",
      "2/4 [==============>...............] - ETA: 0s - loss: 0.1475 - accuracy: 0.984486 - ETA: 0s - loss: 0.5761 - accuracy: 0.78"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:26:47.858773: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 1s 40ms/step - loss: 0.2331 - accuracy: 0.9129\n",
      " - ETA: 0s - loss: 0.1936 - accuracy: 0.9187Epoch 12/25\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.0479 - accuracy: 0.9911\n",
      "4/4 [==============================] - 1s 58ms/step - loss: 0.0854 - accuracy: 0.9911\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.0810 - accuracy: 0.9688[CV 4/5] END ...epochs=25, layers=2, neurons=40;, score=0.991 total time=  11.3s\n",
      "Epoch 9/25\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 0.0734 - accuracy: 0.9710A: 0s - loss: 0.1468 - accuracy: 0.95\n",
      "Epoch 15/25\n",
      "14/14 [==============================] - 1s 47ms/step - loss: 0.5244 - accuracy: 0.8170\n",
      " 1/14 [=>............................] - ETA: 1s - loss: 0.0079 - accuracy: 1.0000Epoch 9/25\n",
      "14/14 [==============================] - 1s 46ms/step - loss: 0.1880 - accuracy: 0.9353A: 0s - loss: 0.0724 - accuracy: 0.96\n",
      "Epoch 9/25\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 0.1364 - accuracy: 0.9598\n",
      "Epoch 14/25\n",
      "14/14 [==============================] - 1s 47ms/step - loss: 0.1769 - accuracy: 0.9308- loss: 0.0569 - accuracy: 0.9750 - ETA: 0s - loss: 0.0795 - accuracy: 0.96\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 0.0599 - accuracy: 0.9732Epoch 22/25\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.2088 - accuracy: 0.9174\n",
      "Epoch 13/25\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 0.0628 - accuracy: 0.9799A: 0s - loss: 0.3508 - accuracy: 0.89\n",
      "14/14 [==============================] - 1s 45ms/step - loss: 0.0746 - accuracy: 0.9688\n",
      "Epoch 10/25\n",
      "Epoch 16/25\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.1373 - accuracy: 0.9531\n",
      "Epoch 10/25\n",
      "14/14 [==============================] - 1s 47ms/step - loss: 0.3243 - accuracy: 0.8996A: 0s - loss: 0.1681 - accuracy: 0.9375: 0s - loss: 0.3400 - accuracy: 0.90\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 0.0367 - accuracy: 1.0000Epoch 10/25\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.0627 - accuracy: 0.9754\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 0.1663 - accuracy: 0.9420Epoch 23/25\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.1327 - accuracy: 0.9554\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.1053 - accuracy: 0.9688Epoch 15/25\n",
      "14/14 [==============================] - 1s 36ms/step - loss: 0.1923 - accuracy: 0.9219\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.1006 - accuracy: 0.9583Epoch 14/25\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.0722 - accuracy: 0.9710\n",
      "Epoch 17/25\n",
      "14/14 [==============================] - 1s 35ms/step - loss: 0.0398 - accuracy: 0.9911\n",
      "Epoch 11/25\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.1108 - accuracy: 0.9576\n",
      "Epoch 11/25\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0251 - accuracy: 0.9911A: 0s - loss: 0.0432 - accuracy: 1.00\n",
      "Epoch 24/25\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.2159 - accuracy: 0.9286A: 0s - loss: 0.2159 - accuracy: 0.92\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 0.0213 - accuracy: 1.0000Epoch 11/25\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.1387 - accuracy: 0.9464\n",
      "Epoch 16/25\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.1923 - accuracy: 0.9174- loss: 0.0297 - accuracy: 0.9969 - ETA: 0s - loss: 0.0219 - accuracy: 0.99\n",
      "Epoch 15/25\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.0685 - accuracy: 0.9643\n",
      "Epoch 18/25\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.0709 - accuracy: 0.9688Epoch 1/25\n",
      "14/14 [==============================] - 0s 36ms/step - loss: 0.0770 - accuracy: 0.9710\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.0258 - accuracy: 0.9978\n",
      "Epoch 12/25\n",
      "Epoch 12/25\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.0203 - accuracy: 0.9933\n",
      "12/14 [========================>.....] - ETA: 0s - loss: 0.1825 - accuracy: 0.9271Epoch 25/25\n",
      "14/14 [==============================] - 1s 36ms/step - loss: 0.1861 - accuracy: 0.9286\n",
      "14/14 [==============================] - 0s 36ms/step - loss: 0.2144 - accuracy: 0.9174\n",
      "Epoch 12/25\n",
      "Epoch 17/25\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.2035 - accuracy: 0.9152A: 0s - loss: 0.0694 - accuracy: 0.97TA: 0s - loss: 0.0153 - accuracy: 1.\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 0.1522 - accuracy: 0.9420Epoch 16/25\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 0.0355 - accuracy: 0.9888\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.0871 - accuracy: 0.9621\n",
      "Epoch 19/25\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.0946 - accuracy: 0.9621\n",
      "Epoch 13/25\n",
      "14/14 [==============================] - 0s 36ms/step - loss: 0.0195 - accuracy: 0.9955\n",
      "Epoch 13/25\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.2016 - accuracy: 0.9219\n",
      "Epoch 18/25\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.1505 - accuracy: 0.9420\n",
      "Epoch 13/25\n",
      " 5/14 [=========>....................] - ETA: 0s - loss: 0.1543 - accuracy: 0.9313"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:26:50.504504: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-01-09 14:26:50.578125: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 1s 38ms/step - loss: 0.2056 - accuracy: 0.9018- loss: 0.1925 - accuracy: 0.9087 - ETA: 0s - loss: 0.1426 - accuracy: 0.94\n",
      "Epoch 17/25\n",
      "14/14 [==============================] - 0s 36ms/step - loss: 0.1493 - accuracy: 0.9442\n",
      "Epoch 20/25\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.0036 - accuracy: 1.0000\n",
      "[CV 5/5] END ...epochs=25, layers=2, neurons=40;, score=1.000 total time=  12.7s\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.0091 - accuracy: 1.0000\n",
      " 5/14 [=========>....................] - ETA: 0s - loss: 1.5971 - accuracy: 0.2438 Epoch 14/25\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.0331 - accuracy: 0.9933\n",
      "Epoch 14/25\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.1155 - accuracy: 0.9531\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 0.0074 - accuracy: 1.0000Epoch 19/25\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.0996 - accuracy: 0.9621\n",
      "Epoch 14/25\n",
      "14/14 [==============================] - 1s 26ms/step - loss: 1.5660 - accuracy: 0.3080A: 0s - loss: 0.1168 - accuracy: 0.95\n",
      "Epoch 2/25\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.1054 - accuracy: 0.9576\n",
      "Epoch 21/25\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.1732 - accuracy: 0.9196 [=>............................] - ETA: 0s - loss: 0.0141 - accuracy: 1.00\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.0977 - accuracy: 0.9549Epoch 18/25\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0070 - accuracy: 1.00TA: 0s - loss: 0.0073 - accuracy: 1.0000 - ETA: 0s - loss: 0.0895 - accuracy: 0.95 - 1s 38ms/step - loss: 0.0070 - accuracy: 1.0000\n",
      "Epoch 15/25\n",
      "14/14 [==============================] - 1s 36ms/step - loss: 0.0291 - accuracy: 0.9911\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.0817 - accuracy: 0.9621\n",
      "Epoch 15/25\n",
      "Epoch 20/25\n",
      "14/14 [==============================]14/14 [==============================] - ETA: 0s - loss: 0.0971 - accuracy: 0.9663 - ETA: 0s - loss: 1.5116 - accuracy: 0.37 - 0s 31ms/step - loss: 1.5116 - accuracy: 0.3750\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.0920 - accuracy: 0.9688\n",
      "Epoch 3/25\n",
      "Epoch 15/25\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.0513 - accuracy: 0.9777\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 1.5089 - accuracy: 0.3542Epoch 22/25\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.1951 - accuracy: 0.9174\n",
      "Epoch 19/25\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.0601 - accuracy: 0.9732\n",
      "Epoch 21/25\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.0093 - accuracy: 0.9978- loss: 0.1711 - accuracy: 0.9271 - ETA: 0s - loss: 0.1083 - accuracy: 0.96\n",
      "Epoch 16/25\n",
      " - 1s 37ms/step - loss: 0.0321 - accuracy: 0.9888\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 0.0613 - accuracy: 0.9688Epoch 16/25\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 1.4775 - accuracy: 0.3750\n",
      "Epoch 4/25\n",
      "14/14 [==============================] - 1s 36ms/step - loss: 0.1100 - accuracy: 0.9576\n",
      "Epoch 16/25\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.0666 - accuracy: 0.9688\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.0391 - accuracy: 1.0000Epoch 23/25\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.1628 - accuracy: 0.9286- loss: 1.4247 - accuracy: 0.3646 - ETA: 0s - loss: 0.0287 - accuracy: 0.98\n",
      "Epoch 20/25\n",
      "Epoch 1/25\n",
      "14/14 [==============================] - 1s 36ms/step - loss: 0.0652 - accuracy: 0.9710\n",
      "12/14 [========================>.....] - ETA: 0s - loss: 1.4087 - accuracy: 0.3672Epoch 22/25\n",
      "14/14 [==============================] - 1s 35ms/step - loss: 0.0081 - accuracy: 1.0000\n",
      "Epoch 17/25\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 1.3900 - accuracy: 0.3750\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.0011 - accuracy: 1.0000Epoch 5/25\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.0314 - accuracy: 0.9911\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.1051 - accuracy: 0.9563Epoch 17/25\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.0459 - accuracy: 0.9799\n",
      "Epoch 24/25\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.1191 - accuracy: 0.9487\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 0.0034 - accuracy: 1.0000Epoch 17/25\n",
      "14/14 [==============================] - 1s 36ms/step - loss: 0.1734 - accuracy: 0.9152\n",
      " - 0s 28ms/step - loss: 1.2424 - accuracy: 0.3996\n",
      "Epoch 21/25\n",
      "Epoch 6/25\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.0590 - accuracy: 0.9799\n",
      "Epoch 23/25\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.0038 - accuracy: 1.0000\n",
      "Epoch 18/25\n",
      " 8/14 [================>.............] - 0s 35ms/step - loss: 0.0292 - accuracy: 0.9955A: 0s - loss: 0.0591 - accuracy: 0.97\n",
      " 5/14 [=========>....................] - ETA: 0s - loss: 1.0844 - accuracy: 0.4813Epoch 18/25\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.0328 - accuracy: 0.9688"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:26:52.894623: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - ETA: 0s - loss: 0.0520 - accuracy: 0.9844 - 0s 36ms/step - loss: 0.0599 - accuracy: 0.9710\n",
      "Epoch 25/25\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.1037 - accuracy: 0.9621A: 0s - loss: 0.0062 - accuracy: 1.00\n",
      "Epoch 18/25=>........................] - ETA: 0s - loss: 0.0855 - accuracy: 0.9479\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 1.0822 - accuracy: 0.4799 [=>............................] - ETA: 11s - loss: 1.6126 - accuracy: 0.09\n",
      " 5/14 [=========>....................] - ETA: 0s - loss: 0.0577 - accuracy: 0.9688Epoch 7/25\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.1658 - accuracy: 0.9174\n",
      "Epoch 22/25\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.0568 - accuracy: 0.9821\n",
      "Epoch 24/25\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.0062 - accuracy: 1.0000- loss: 0.1562 - accuracy: 0.9375 - ETA: 0s - loss: 0.0054 - accuracy: 1.00\n",
      "Epoch 19/25\n",
      "14/14 [==============================] 6/14 [===========>..................] - 0s 34ms/step - loss: 0.0276 - accuracy: 0.98881: 0s - loss: 0.0713 - accuracy: 0.96\n",
      "12/14 [========================>.....] - ETA: 0s - loss: 0.0652 - accuracy: 0.9688 - ETA: 0s - loss: 1.5924 - accuracy: 0.2448Epoch 19/25\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0680 - accuracy: 0.9665\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.9263 - accuracy: 0.5179\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.0624 - accuracy: 0.9757Epoch 8/25\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.0937 - accuracy: 0.9688\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 0.0281 - accuracy: 0.9955Epoch 19/25\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 1.5514 - accuracy: 0.3237\n",
      "Epoch 2/25\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.0635 - accuracy: 0.9732\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 1.2689 - accuracy: 0.5625Epoch 25/25\n",
      "14/14 [==============================] - 0s 36ms/step - loss: 0.1365 - accuracy: 0.9308\n",
      "Epoch 23/25\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.0078 - accuracy: 0.9978\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.1040 - accuracy: 0.9688Epoch 20/25\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.0233 - accuracy: 0.9978A: 0s - loss: 0.0853 - accuracy: 0.96\n",
      "Epoch 20/25\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.8784 - accuracy: 0.5848\n",
      "Epoch 9/25\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 0.1367 - accuracy: 0.9286"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:26:53.949685: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 29ms/step - loss: 1.5087 - accuracy: 0.3795A: 0s - loss: 0.8934 - accuracy: 0.61\n",
      "11/14 [======================>.......] - ETA: 0s - loss: 0.1525 - accuracy: 0.9176Epoch 3/25\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.0579 - accuracy: 0.9754\n",
      "Epoch 20/25\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0685 - accuracy: 0.9732\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.1531 - accuracy: 0.9174- loss: 0.0135 - accuracy: 1.0000 - ETA: 0s - loss: 0.1531 - accuracy: 0.91\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.0031 - accuracy: 1.0000Epoch 24/25\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.0032 - accuracy: 1.0000\n",
      "Epoch 21/25\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 0.0289 - accuracy: 0.9911\n",
      "[CV 1/5] END ...epochs=25, layers=2, neurons=60;, score=0.991 total time=  14.0s\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.0078 - accuracy: 0.9978\n",
      "Epoch 21/25\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.8610 - accuracy: 0.6183\n",
      "Epoch 10/25\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 1.4635 - accuracy: 0.3795\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 0.1487 - accuracy: 0.9219\n",
      "Epoch 4/25\n",
      "12/14 [========================>.....] - ETA: 0s - loss: 0.0510 - accuracy: 0.9740Epoch 25/25\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0084 - accuracy: 1.000074"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:26:54.604832: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 34ms/step - loss: 0.0506 - accuracy: 0.9754\n",
      "Epoch 21/25\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.0099 - accuracy: 0.9978\n",
      "Epoch 22/25\n",
      "14/14 [==============================] - 0s 24ms/step - loss: 0.8140 - accuracy: 0.6362\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0248 - accuracy: 0.9955\n",
      "Epoch 11/25\n",
      "Epoch 22/25\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.0397 - accuracy: 0.9911\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 0.1585 - accuracy: 0.9107[CV 2/5] END ...epochs=25, layers=2, neurons=60;, score=0.991 total time=  14.1s\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 1.3534 - accuracy: 0.3795\n",
      " 8/14 [================>.............] - ETA: 0s - loss: 0.0052 - accuracy: 1.0000Epoch 5/25\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.1468 - accuracy: 0.9219\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.0364 - accuracy: 0.9933\n",
      "12/14 [========================>.....] - ETA: 0s - loss: 0.0244 - accuracy: 1.0000Epoch 22/25\n",
      "14/14 [==============================] - 0s 24ms/step - loss: 0.7682 - accuracy: 0.6562\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.0046 - accuracy: 1.0000Epoch 12/25\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0044 - accuracy: 1.0000\n",
      "Epoch 23/25\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.0249 - accuracy: 1.0000\n",
      "Epoch 23/25\n",
      " - ETA: 0s - loss: 0.0149 - accuracy: 1.0000 3/14 [=====>........................] - ETA: 0s - loss: 0.0043 - accuracy: 1.0000Epoch 1/25\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 1.1349 - accuracy: 0.3929\n",
      "Epoch 6/25\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.8310 - accuracy: 0.6652\n",
      "Epoch 13/25\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0254 - accuracy: 0.9978\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 0.0052 - accuracy: 1.0000\n",
      "Epoch 23/25\n",
      "Epoch 24/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:26:55.390841: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0273 - accuracy: 0.9933\n",
      "Epoch 24/25\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.0060 - accuracy: 1.0000Epoch 1/25\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.0181 - accuracy: 1.0000\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 0.0290 - accuracy: 0.9896[CV 3/5] END ...epochs=25, layers=2, neurons=60;, score=1.000 total time=  14.2s\n",
      "14/14 [==============================] - 0s 24ms/step - loss: 0.8482 - accuracy: 0.6741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:26:55.666790: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/25\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 0.7653 - accuracy: 0.6875\n",
      "14/14 [==============================] - 0s 24ms/step - loss: 0.0037 - accuracy: 1.0000\n",
      "Epoch 14/25\n",
      "Epoch 25/25\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.0250 - accuracy: 0.9911\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 4.8521e-04 - accuracy: 1.0000Epoch 24/25\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0415 - accuracy: 0.9888\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 0.7208 - accuracy: 0.6354Epoch 25/25\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.6239 - accuracy: 0.7344- ETA: 0s - loss: 0.0314 - accuracy: 1.00\n",
      "Epoch 8/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:26:55.975021: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 28ms/step - loss: 0.7824 - accuracy: 0.6719\n",
      "Epoch 15/25\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "14/14 [==============================] 6/14 [===========>..................] - 1s 34ms/step - loss: 1.5578 - accuracy: 0.3438\n",
      " - ETA: 0s - loss: 0.5527 - accuracy: 0.7708Epoch 2/25\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.0341 - accuracy: 0.9888\n",
      "Epoch 25/25\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.0556 - accuracy: 0.9688Epoch 1/25\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.0190 - accuracy: 1.0000\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.5259 - accuracy: 0.7746\n",
      " 8/14 [================>.............] - ETA: 0s - loss: 1.5056 - accuracy: 0.3633Epoch 9/25\n",
      "14/14 [==============================] - 1s 29ms/step - loss: 1.5217 - accuracy: 0.3839\n",
      "Epoch 2/25\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.7726 - accuracy: 0.6540- loss: 0.4673 - accuracy: 0.7708 - ETA: 0s - loss: 1.4384 - accuracy: 0.34\n",
      "Epoch 16/25\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 1.5042 - accuracy: 0.3661\n",
      "Epoch 3/25\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.0325 - accuracy: 0.9832  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:26:56.578993: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-01-09 14:26:56.629483: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-01-09 14:26:56.735081: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 35ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.0316 - accuracy: 0.9844\n",
      "[CV 4/5] END ...epochs=25, layers=2, neurons=60;, score=1.000 total time=  14.8s\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 0.4546 - accuracy: 0.7902\n",
      "Epoch 10/25\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.0410 - accuracy: 0.9911\n",
      " - ETA: 0s - loss: 1.4815 - accuracy: 0.3611[CV 5/5] END ...epochs=25, layers=2, neurons=60;, score=0.991 total time=  14.9s\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 1.4380 - accuracy: 0.3795A: 0s - loss: 0.3764 - accuracy: 0.81\n",
      " 4/14 [=======>......................] - ETA: 0s - loss: 1.5585 - accuracy: 0.2656Epoch 3/25\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.7386 - accuracy: 0.6719\n",
      "Epoch 17/25\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 1.4636 - accuracy: 0.4040\n",
      "Epoch 4/25\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 1.5472 - accuracy: 0.3371\n",
      "Epoch 2/25\n",
      "14/14 [==============================] - 0s 37ms/step - loss: 0.3567 - accuracy: 0.8304\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 1.4016 - accuracy: 0.3571Epoch 11/25\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 1.3013 - accuracy: 0.4397\n",
      "12/14 [========================>.....] - ETA: 0s - loss: 0.7566 - accuracy: 0.6510Epoch 4/25\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.7400 - accuracy: 0.6652\n",
      "Epoch 18/25\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 1.3188 - accuracy: 0.4196\n",
      "Epoch 5/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:26:57.455577: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 36ms/step - loss: 0.0398 - accuracy: 0.9911\n",
      " 8/14 [================>.............] - ETA: 0s - loss: 1.4269 - accuracy: 0.3828[CV 1/5] END ...epochs=25, layers=3, neurons=20;, score=0.991 total time=  15.6s\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 1.4207 - accuracy: 0.3661\n",
      "Epoch 3/25\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.3020 - accuracy: 0.8549\n",
      "Epoch 12/25\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.7267 - accuracy: 0.6741\n",
      "Epoch 19/25\n",
      "11/14 [======================>.......] - ETA: 0s - loss: 1.0815 - accuracy: 0.5085Epoch 1/25\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.9846 - accuracy: 0.6116\n",
      "Epoch 5/25\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 1.0537 - accuracy: 0.5112\n",
      " 5/14 [=========>....................] - ETA: 0s - loss: 0.6050 - accuracy: 0.7438Epoch 6/25\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.2998 - accuracy: 0.8862\n",
      "Epoch 13/25\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 1.1854 - accuracy: 0.4330\n",
      "Epoch 4/25\n",
      " 1/14 [=>............................] - 0s 31ms/step - loss: 0.7062 - accuracy: 0.6964\n",
      "11/14 [======================>.......] - ETA: 0s - loss: 0.6385 - accuracy: 0.8068Epoch 20/25\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.6039 - accuracy: 0.8237\n",
      "Epoch 6/25\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.8304 - accuracy: 0.5513\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.4153 - accuracy: 0.8438Epoch 7/25\n",
      "11/14 [======================>.......] - ETA: 0s - loss: 0.2535 - accuracy: 0.9014 - ETA: 0s - loss: 0.7702 - accuracy: 0.6790Epoch 1/25s: 0.2543 - accuracy: 0.\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.2566 - accuracy: 0.8973\n",
      "12/14 [========================>.....]Epoch 14/25- loss: 0.7370 - accuracy: 0.62\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.7559 - accuracy: 0.6674\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.7346 - accuracy: 0.7254\n",
      "Epoch 5/25\n",
      "Epoch 21/25\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.7060 - accuracy: 0.6295\n",
      "Epoch 8/25\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.3553 - accuracy: 0.8728\n",
      "Epoch 7/25\n",
      "11/14 [======================>.......] - ETA: 0s - loss: 0.2439 - accuracy: 0.9034"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:26:59.081680: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 5/14 [=========>....................]14/14 [==============================] - ETA: 0s - loss: 0.2496 - accuracy: 0.9000 - 0s 30ms/step - loss: 0.2330 - accuracy: 0.9107\n",
      "Epoch 15/25\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.7168 - accuracy: 0.6875\n",
      "Epoch 22/25\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.3959 - accuracy: 0.8460\n",
      "Epoch 6/25\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.7288 - accuracy: 0.6228A: 0s - loss: 0.6624 - accuracy: 0.\n",
      "Epoch 9/25\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.2221 - accuracy: 0.9063\n",
      "Epoch 8/25\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.2717 - accuracy: 0.8715 - ETA: 0s - loss: 1.6344 - accuracy: 0.187"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:26:59.455573: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 27ms/step - loss: 0.2106 - accuracy: 0.9063\n",
      "Epoch 1/25\n",
      "Epoch 16/25\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.7233 - accuracy: 0.6853\n",
      "Epoch 23/25\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.2601 - accuracy: 0.8750\n",
      "Epoch 7/25\n",
      "14/14 [==============================] - 0s 24ms/step - loss: 0.2379 - accuracy: 0.8862\n",
      "Epoch 9/25\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.5946 - accuracy: 0.6964- loss: 0.2371 - accuracy: 0.8688 - ETA: 0s - loss: 0.1912 - accuracy: 0.9176\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 1.5636 - accuracy: 0.3245Epoch 10/25\n",
      "14/14 [==============================] - 2s 41ms/step - loss: 1.5624 - accuracy: 0.3281\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.1871 - accuracy: 0.9159Epoch 2/25\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.1882 - accuracy: 0.9174\n",
      "Epoch 17/25\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.7007 - accuracy: 0.6853\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 0.5520 - accuracy: 0.7604Epoch 24/25\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.1895 - accuracy: 0.8996\n",
      "Epoch 8/25\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.5704 - accuracy: 0.7292"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:27:00.057389: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 34ms/step - loss: 0.1813 - accuracy: 0.9219\n",
      "12/14 [========================>.....]Epoch 10/25- loss: 1.4777 - accuracy: 0.36\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.5422 - accuracy: 0.7366\n",
      "Epoch 11/25\n",
      "14/14 [==============================] - 0s 23ms/step - loss: 0.6846 - accuracy: 0.6942\n",
      "Epoch 25/25\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.1998 - accuracy: 0.9152\n",
      "Epoch 18/25\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 1.4724 - accuracy: 0.3683A: 0s - loss: 1.5513 - accuracy: 0.34\n",
      "Epoch 3/25\n",
      "14/14 [==============================] - 2s 40ms/step - loss: 1.5522 - accuracy: 0.3527\n",
      " 4/14 [=======>......................] - ETA: 0s - loss: 0.2132 - accuracy: 0.9219Epoch 2/25\n",
      " - 0s 29ms/step - loss: 0.1211 - accuracy: 0.9665- loss: 1.4144 - accuracy: 0.3983\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 0.4333 - accuracy: 0.8080Epoch 9/25\n",
      "14/14 [==============================] - 0s 21ms/step - loss: 0.6796 - accuracy: 0.7076A: 0s - loss: 0.1065 - accuracy: 0.95\n",
      "14/14 [==============================] - 1s 35ms/step - loss: 1.5443 - accuracy: 0.3393\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 0.1899 - accuracy: 0.8958Epoch 2/25\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 0.2216 - accuracy: 0.9063\n",
      "Epoch 19/25\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.1249 - accuracy: 0.9554\n",
      "Epoch 11/25\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.4323 - accuracy: 0.7969\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.0743 - accuracy: 1.0000Epoch 12/25\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 1.3426 - accuracy: 0.3817A: 0s - loss: 1.3456 - accuracy: 0.38\n",
      "Epoch 4/25\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 1.4557 - accuracy: 0.3839\n",
      "Epoch 3/25\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.1297 - accuracy: 0.9420\n",
      "Epoch 10/25\n",
      "14/14 [==============================] - 0s 22ms/step - loss: 0.1814 - accuracy: 0.9152\n",
      "Epoch 20/25\n",
      " 5/14 [=========>....................] - ETA: 0s - loss: 1.2432 - accuracy: 0.3688"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:27:00.929357: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 24ms/step - loss: 0.5206 - accuracy: 0.7411\n",
      "[CV 2/5] END ...epochs=25, layers=3, neurons=20;, score=0.741 total time=  12.4s\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.1068 - accuracy: 0.9777A: 0s - loss: 1.3632 - accuracy: 0.38\n",
      "Epoch 12/25\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 1.4227 - accuracy: 0.4063\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.2971 - accuracy: 0.8996\n",
      "Epoch 3/25\n",
      "Epoch 13/25\n",
      "14/14 [==============================] 5/14 [=========>....................] - ETA: 0s - loss: 0.0703 - accuracy: 0.9938 - 0s 31ms/step - loss: 1.1357 - accuracy: 0.4464\n",
      "12/14 [========================>.....] - ETA: 0s - loss: 0.1319 - accuracy: 0.9349Epoch 5/25\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 0.1420 - accuracy: 0.9330\n",
      "Epoch 21/25\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 1.3092 - accuracy: 0.3817A: 0s - loss: 0.3179 - accuracy: 0.84\n",
      "Epoch 4/25\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.0773 - accuracy: 0.9710\n",
      "Epoch 11/25\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.2680 - accuracy: 0.9152\n",
      "Epoch 14/25\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.0830 - accuracy: 0.9844\n",
      "Epoch 13/25\n",
      "14/14 [==============================] - 1s 36ms/step - loss: 1.1542 - accuracy: 0.5670\n",
      "Epoch 4/25\n",
      "14/14 [==============================] - 0s 22ms/step - loss: 0.1792 - accuracy: 0.9174\n",
      "Epoch 22/25\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.9165 - accuracy: 0.5379\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.9440 - accuracy: 0.5625Epoch 6/25\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 0.1959 - accuracy: 0.9554Epoch 1/25\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 1.0068 - accuracy: 0.4844A: 0s - loss: 0.1085 - accuracy: 0.\n",
      " 5/14 [=========>....................] - ETA: 0s - loss: 0.8564 - accuracy: 0.5375Epoch 5/25\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.0547 - accuracy: 0.9799\n",
      "Epoch 12/25\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.1898 - accuracy: 0.9397\n",
      "Epoch 15/25\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.0601 - accuracy: 0.9799\n",
      "Epoch 14/25\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.1449 - accuracy: 0.9375"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:27:02.019917: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 26ms/step - loss: 0.1476 - accuracy: 0.9308\n",
      "Epoch 23/25\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.7177 - accuracy: 0.7366\n",
      "Epoch 5/25\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.7840 - accuracy: 0.5893\n",
      "Epoch 7/25\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.6067 - accuracy: 0.7121\n",
      "Epoch 6/25\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.1447 - accuracy: 0.9487\n",
      "Epoch 16/25\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.0777 - accuracy: 0.9754\n",
      "11/14 [======================>.......] - ETA: 0s - loss: 0.0739 - accuracy: 0.9801Epoch 13/25\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.0616 - accuracy: 0.9844\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.1930 - accuracy: 0.9129\n",
      "Epoch 15/25\n",
      " 5/14 [=========>....................] - ETA: 0s - loss: 0.4580 - accuracy: 0.8375Epoch 24/25\n",
      "14/14 [==============================] - 1s 22ms/step - loss: 1.5241 - accuracy: 0.3438\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.0249 - accuracy: 1.0000Epoch 2/25\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.3639 - accuracy: 0.8638A: 0s - loss: 0.3733 - accuracy: 0.86\n",
      "Epoch 6/25\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.6256 - accuracy: 0.7902\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 0.1567 - accuracy: 0.9241Epoch 8/25\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0938 - accuracy: 0.9665\n",
      "11/14 [======================>.......] - ETA: 0s - loss: 1.3907 - accuracy: 0.4062Epoch 17/25\n",
      "14/14 [==============================] - 0s 23ms/step - loss: 0.1545 - accuracy: 0.9263\n",
      "Epoch 25/25\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.2618 - accuracy: 0.9063\n",
      " 1/14 [=>............................] - 0s 35ms/step - loss: 0.4070 - accuracy: 0.8281\n",
      " - ETA: 0s - loss: 0.0274 - accuracy: 1.0000Epoch 14/25\n",
      "Epoch 7/25\n",
      "14/14 [==============================] - 0s 23ms/step - loss: 1.3916 - accuracy: 0.3862\n",
      "Epoch 3/25\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0384 - accuracy: 0.9866\n",
      "Epoch 16/25\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.5710 - accuracy: 0.8125A: 0s - loss: 1.1938 - accuracy: 0.39\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.1493 - accuracy: 0.9479Epoch 9/25\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.1859 - accuracy: 0.9353\n",
      "Epoch 7/25\n",
      "14/14 [==============================] - 0s 20ms/step - loss: 1.1716 - accuracy: 0.3884\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.5372 - accuracy: 0.7188Epoch 4/25\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 0.1811 - accuracy: 0.9152\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.1034 - accuracy: 0.9665\n",
      "Epoch 18/25\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.1272 - accuracy: 0.9487\n",
      "Epoch 15/25\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.0188 - accuracy: 0.9955\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 0.9380 - accuracy: 0.5268Epoch 17/25\n",
      "14/14 [==============================] - 1s 36ms/step - loss: 0.2977 - accuracy: 0.8527\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 0.5320 - accuracy: 0.8080Epoch 8/25\n",
      "14/14 [==============================] - 0s 20ms/step - loss: 0.8260 - accuracy: 0.5982\n",
      "Epoch 5/25\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.0971 - accuracy: 0.9719"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:27:03.440715: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 33ms/step - loss: 0.5527 - accuracy: 0.8036\n",
      "Epoch 10/25\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.0982 - accuracy: 0.9754\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.1085 - accuracy: 0.9688Epoch 19/25\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.0061 - accuracy: 1.0000\n",
      "[CV 3/5] END ...epochs=25, layers=3, neurons=20;, score=1.000 total time=  12.4s\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.1819 - accuracy: 0.9554A: 0s - loss: 0.5860 - accuracy: 0.75\n",
      "Epoch 8/25\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0201 - accuracy: 0.9955\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 0.0783 - accuracy: 0.9792Epoch 18/25\n",
      "14/14 [==============================] - 0s 20ms/step - loss: 0.5882 - accuracy: 0.7679\n",
      "Epoch 6/25\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.1010 - accuracy: 0.9665\n",
      " 5/14 [=========>....................] - ETA: 0s - loss: 0.0969 - accuracy: 0.9688Epoch 16/25\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.2460 - accuracy: 0.8594\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 0.0632 - accuracy: 0.9688Epoch 9/25\n",
      "14/14 [==============================] - 0s 20ms/step - loss: 0.4748 - accuracy: 0.7969\n",
      "Epoch 7/25\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.0760 - accuracy: 0.9799A: 0s - loss: 0.5683 - accuracy: 0.81\n",
      "Epoch 20/25\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.5538 - accuracy: 0.8259\n",
      "Epoch 11/25\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0112 - accuracy: 0.9955\n",
      " 4/14 [=======>......................] - ETA: 0s - loss: 0.3296 - accuracy: 0.8828Epoch 19/25\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.0860 - accuracy: 0.9777\n",
      " 4/14 [=======>......................] - ETA: 0s - loss: 0.0909 - accuracy: 0.9688Epoch 9/25\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.0483 - accuracy: 0.9799\n",
      "Epoch 17/25\n",
      "14/14 [==============================] - 0s 18ms/step - loss: 0.3633 - accuracy: 0.8616\n",
      "Epoch 8/25\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.2137 - accuracy: 0.8839\n",
      "Epoch 10/25\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.0855 - accuracy: 0.9732\n",
      "Epoch 21/25\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.5213 - accuracy: 0.8549\n",
      "Epoch 12/25\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0166 - accuracy: 0.9933\n",
      " 5/14 [=========>....................] - ETA: 0s - loss: 0.2340 - accuracy: 0.8750Epoch 20/25\n",
      "14/14 [==============================] - 0s 18ms/step - loss: 0.2687 - accuracy: 0.8795\n",
      "Epoch 9/25\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.4064 - accuracy: 0.7812Epoch 1/25\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.0664 - accuracy: 0.9844A: 0s - loss: 0.0664 - accuracy: 0.98\n",
      "Epoch 10/25\n",
      "14/14 [==============================] 5/14 [=========>....................] - ETA: 0s - loss: 0.0297 - accuracy: 0.9812 - 0s 32ms/step - loss: 0.0463 - accuracy: 0.9821\n",
      "Epoch 18/25\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.2151 - accuracy: 0.9085A: 0s - loss: 0.0265 - accuracy: 0.\n",
      " 5/14 [=========>....................] - ETA: 0s - loss: 0.0409 - accuracy: 0.9875Epoch 11/25\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.0546 - accuracy: 0.9866\n",
      "Epoch 22/25\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.3299 - accuracy: 0.8616\n",
      "Epoch 10/25\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.0337 - accuracy: 0.9799\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 0.0877 - accuracy: 0.9583Epoch 21/25\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.4781 - accuracy: 0.8705\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.0506 - accuracy: 0.9688Epoch 13/25\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.0395 - accuracy: 0.9911\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.0390 - accuracy: 0.9888\n",
      "Epoch 11/25\n",
      "Epoch 19/25\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.1553 - accuracy: 0.9062: 0s - loss: 0.1665 - accuracy: 0.8750 - ETA: 0s - loss: 0.0496 - accuracy: 0.98"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:27:05.093766: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 29ms/step - loss: 0.3146 - accuracy: 0.8482A: 0s - loss: 0.4852 - accuracy: 0.83\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 0.4533 - accuracy: 0.8438Epoch 11/25\n",
      "14/14 [==============================] - 1s 35ms/step - loss: 0.1475 - accuracy: 0.9241\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.0593 - accuracy: 0.9732\n",
      "Epoch 12/25\n",
      "Epoch 23/25\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.0446 - accuracy: 0.9888A: 0s - loss: 0.0693 - accuracy: 0.98\n",
      "Epoch 22/25\n",
      "14/14 [==============================] - 1s 36ms/step - loss: 0.4719 - accuracy: 0.8504A: 0s - loss: 0.0285 - accuracy: 1.00\n",
      " 4/14 [=======>......................] - ETA: 0s - loss: 0.0644 - accuracy: 0.9844Epoch 14/25\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.0719 - accuracy: 0.9754\n",
      "Epoch 12/25\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.0508 - accuracy: 0.98880 1/14 [=>............................] - ETA: 14s - loss: 1.6448 - accuracy: 0.12\n",
      "Epoch 20/25\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.2262 - accuracy: 0.9219\n",
      "Epoch 12/25\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.0549 - accuracy: 0.9821\n",
      " 8/14 [================>.............] - ETA: 0s - loss: 0.0397 - accuracy: 0.9922Epoch 24/25\n",
      " 9/14 [==================>...........] - 1s 44ms/step - loss: 0.0626 - accuracy: 0.9821=============================]\n",
      " - ETA: 0s - loss: 0.1863 - accuracy: 0.9444Epoch 13/25\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.0302 - accuracy: 0.9844\n",
      "Epoch 23/25\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.4645 - accuracy: 0.8460\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.0046 - accuracy: 1.0000Epoch 15/25\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.0182 - accuracy: 0.9955\n",
      "Epoch 13/25\n",
      "14/14 [==============================] - 2s 39ms/step - loss: 1.5751 - accuracy: 0.3259\n",
      "Epoch 2/25\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.1768 - accuracy: 0.9464\n",
      "Epoch 13/25\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.0282 - accuracy: 0.9933A: 0s - loss: 1.3607 - accuracy: 0.46\n",
      " 6/14 [===========>..................] - ETA: 0s - loss: 0.0368 - accuracy: 0.9948Epoch 21/25\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.0556 - accuracy: 0.9821- loss: 0.0073 - accuracy: 1.0000 - ETA: 0s - loss: 1.3741 - accuracy: \n",
      "Epoch 25/25\n",
      "14/14 [==============================] - 1s 35ms/step - loss: 0.0321 - accuracy: 0.9866\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.0797 - accuracy: 0.9760Epoch 24/25\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.0789 - accuracy: 0.9754\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.0722 - accuracy: 0.9375Epoch 14/25\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.5200 - accuracy: 0.8237\n",
      "Epoch 16/25\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 1.2660 - accuracy: 0.4732- loss: 1.2729 - accuracy: 0.4760 - ETA: 0s - loss: 0.1327 - accuracy: 0.9479\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 0.0504 - accuracy: 0.9792Epoch 3/25\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.0055 - accuracy: 1.0000A: 0s - loss: 0.9142 - accuracy: 0.65\n",
      " 3/14 [=====>........................] - 1s 35ms/step - loss: 0.1298 - accuracy: 0.9509\n",
      " - ETA: 0s - loss: 0.4024 - accuracy: 0.8854Epoch 14/25\n",
      " 5/14 [=========>....................] - ETA: 0s - loss: 0.1272 - accuracy: 0.9375Epoch 14/25\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.0212 - accuracy: 0.9933A: 0s - loss: 0.1350 - accuracy: 0.93\n",
      "Epoch 22/25\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.2046 - accuracy: 0.9308 [====================>.........] - ETA: 0s - loss: 0.0703 - accuracy: 0.97\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.8605 - accuracy: 0.5969Epoch 25/25\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.0678 - accuracy: 0.9799\n",
      "11/14 [======================>.......] - ETA: 0s - loss: 0.1444 - accuracy: 0.9261Epoch 15/25\n",
      "14/14 [==============================] - 1s 44ms/step - loss: 0.0460 - accuracy: 0.9888A: 0s - loss: 0.0460 - accuracy: 0.98\n",
      "14/14 [==============================] - 1s 47ms/step - loss: 0.4942 - accuracy: 0.8571- loss: 0.0503 - accuracy: 0.9826 - ETA: 0s - loss: 0.0075 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.0069 - accuracy: 1.0000A: 0s - loss: 0.0481 - accuracy: 0.98\n",
      "Epoch 17/25\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.1283 - accuracy: 0.9353\n",
      "Epoch 15/25\n",
      "Epoch 15/25\n",
      "14/14 [==============================] - 1s 45ms/step - loss: 0.7938 - accuracy: 0.6362\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.4990 - accuracy: 0.8438Epoch 4/25\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 0.0422 - accuracy: 0.9866\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 0.0736 - accuracy: 0.9688Epoch 23/25\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.1084 - accuracy: 0.9665A: 0s - loss: 0.0061 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.0417 - accuracy: 0.9888\n",
      "Epoch 16/25\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.0242 - accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:27:07.586662: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 1s 36ms/step - loss: 0.1125 - accuracy: 0.9621\n",
      "Epoch 16/25\n",
      "14/14 [==============================] 9/14 [==================>...........] - ETA: 0s - loss: 0.0176 - accuracy: 1.0000 - 1s 39ms/step - loss: 0.4840 - accuracy: 0.8371\n",
      "Epoch 18/25\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.0088 - accuracy: 0.9978\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1002 - accuracy: 0.9896    Epoch 16/25\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.4351 - accuracy: 0.8281\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.0175 - accuracy: 1.0000Epoch 5/25\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 0.0859 - accuracy: 0.9911\n",
      "[CV 4/5] END ...epochs=25, layers=3, neurons=20;, score=0.991 total time=  13.0s\n",
      "14/14 [==============================] - 1s 44ms/step - loss: 0.0244 - accuracy: 0.9978\n",
      "Epoch 24/25\n",
      " 4/14 [=======>......................] - ETA: 0s - loss: 0.0358 - accuracy: 0.9922 - ETA: 0s - loss: 0.0198 - accuracy: 1.00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:27:08.070298: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 1s 39ms/step - loss: 0.0691 - accuracy: 0.9799\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.0110 - accuracy: 1.0000Epoch 17/25\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.4421 - accuracy: 0.8504\n",
      "14/14 [==============================] - 1s 35ms/step - loss: 0.0822 - accuracy: 0.9799\n",
      "Epoch 19/25\n",
      "Epoch 17/25\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.2358 - accuracy: 0.9063\n",
      "Epoch 6/25\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 0.0180 - accuracy: 0.9911\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.0087 - accuracy: 1.0000\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.1172 - accuracy: 0.9688Epoch 17/25\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 0.0808 - accuracy: 0.9583[CV 5/5] END ...epochs=25, layers=3, neurons=20;, score=0.991 total time=  13.2s\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.0251 - accuracy: 0.9955\n",
      "Epoch 25/25\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.0762 - accuracy: 0.9799\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.0200 - accuracy: 1.0000 - ETA: 0s - loss: 0.0190 - accuracy: 0.9965Epoch 18/25\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.4555 - accuracy: 0.8415- loss: 0.0635 - accuracy: 0.9732 - ETA: 0s - loss: 0.4555 - accuracy: 0.84\n",
      " - 1s 39ms/step - loss: 0.0635 - accuracy: 0.9732\n",
      "Epoch 20/25\n",
      "Epoch 18/25\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.1939 - accuracy: 0.9397\n",
      "Epoch 7/25\n",
      "14/14 [==============================] - 1s 36ms/step - loss: 0.0247 - accuracy: 0.9911\n",
      "Epoch 18/25\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.0493 - accuracy: 0.9933A: 0s - loss: 0.4317 - accuracy: 0.86\n",
      "14/14 [==============================] - 1s 36ms/step - loss: 0.0486 - accuracy: 0.9844- loss: 0.0887 - accuracy: 0.9777 - ETA: 0s - loss: 0.1291 - accuracy: 0.\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.0699 - accuracy: 0.9754\n",
      "Epoch 19/25\n",
      "Epoch 19/25\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.1156 - accuracy: 0.9598\n",
      "Epoch 8/25\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.4539 - accuracy: 0.8438\n",
      "Epoch 21/25\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.0842 - accuracy: 0.9732\n",
      "Epoch 19/25\n",
      " 4/14 [=======>......................] - ETA: 0s - loss: 0.1191 - accuracy: 0.9453Epoch 1/25 - loss: 0.0427 - accuracy: 1.00\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 9.8471e-04 - accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:27:09.380839: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0732 - accuracy: 0.9799\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.5426 - accuracy: 0.7991\n",
      "Epoch 22/25\n",
      "Epoch 9/25\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.0732 - accuracy: 0.9754\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.0284 - accuracy: 0.9904Epoch 20/25\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.4162 - accuracy: 0.7812Epoch 1/25\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.0021 - accuracy: 1.0000\n",
      "[CV 1/5] END ...epochs=25, layers=3, neurons=40;, score=1.000 total time=  13.7s\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.0265 - accuracy: 0.9911\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.0228 - accuracy: 1.0000Epoch 20/25\n",
      " 4/14 [=======>......................] - ETA: 0s - loss: 0.0468 - accuracy: 0.9844"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:27:09.736096: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 36ms/step - loss: 0.0152 - accuracy: 0.9955\n",
      " 6/14 [===========>..................]Epoch 20/25\n",
      "13/14 [==========================>...]14/14 [==============================] - 0s 27ms/step - loss: 0.0670 - accuracy: 0.9799\n",
      " - ETA: 0s - loss: 0.4619 - accuracy: 0.8365Epoch 21/25\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.0941 - accuracy: 0.9688 [==============================] - ETA: 0s - loss: 0.0941 - accuracy: 0.96\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.4556 - accuracy: 0.8460\n",
      "Epoch 10/25\n",
      "Epoch 23/25\n",
      "14/14 [==============================] - ETA: 0s - loss: 1.6176 - accuracy: 0.3125 - 0s 31ms/step - loss: 0.0083 - accuracy: 0.9978\n",
      "Epoch 21/25\n",
      "11/14 [======================>.......] - ETA: 0s - loss: 0.0173 - accuracy: 0.997200"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:27:10.031838: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 36ms/step - loss: 0.0146 - accuracy: 0.9978\n",
      "Epoch 21/25\n",
      "14/14 [==============================] - 1s 36ms/step - loss: 0.0943 - accuracy: 0.9598 [===>..........................] - ETA: 0s - loss: 1.6050 - accuracy: 0.28\n",
      "Epoch 22/25\n",
      "14/14 [==============================] - 1s 46ms/step - loss: 1.5739 - accuracy: 0.3638\n",
      "Epoch 2/25\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.0978 - accuracy: 0.9710- loss: 1.4810 - accuracy: 0.3125 - ETA: 0s - loss: 1.6097 - accuracy: 0.32\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.4328 - accuracy: 0.8594\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 0.1168 - accuracy: 0.9375Epoch 11/25\n",
      "Epoch 24/25\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.0185 - accuracy: 0.9911\n",
      "Epoch 22/25\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.0056 - accuracy: 0.9978\n",
      "Epoch 22/25\n",
      "14/14 [==============================] - 1s 55ms/step - loss: 1.5204 - accuracy: 0.3705A: 0s - loss: 0.0232 - accuracy: 0.98\n",
      " 9/14 [==================>...........]Epoch 2/25\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.0922 - accuracy: 0.9643\n",
      "Epoch 23/25\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 1.4251 - accuracy: 0.4174A: 0s - loss: 0.0092 - accuracy: 1.00\n",
      "11/14 [======================>.......] - ETA: 0s - loss: 0.3496 - accuracy: 0.8665Epoch 3/25\n",
      "12/14 [========================>.....]Epoch 1/25 - loss: 1.3766 - accuracy: 0.4055\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.3490 - accuracy: 0.8750\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.0088 - accuracy: 0.9965Epoch 25/25\n",
      "14/14 [==============================] - 1s 46ms/step - loss: 0.0630 - accuracy: 0.9866\n",
      "11/14 [======================>.......] - ETA: 0s - loss: 0.0075 - accuracy: 0.9972Epoch 12/25\n",
      "14/14 [==============================] - 1s 44ms/step - loss: 0.0301 - accuracy: 0.9888\n",
      " 6/14 [===========>..................] - ETA: 0s - loss: 1.2486 - accuracy: 0.5104Epoch 23/25\n",
      "14/14 [==============================] - 0s 36ms/step - loss: 0.0060 - accuracy: 0.9978\n",
      "11/14 [======================>.......] - ETA: 0s - loss: 1.3183 - accuracy: 0.4489Epoch 23/25: 0.0030 - accuracy: 1.0000 - ETA: 0s - loss: 0.1018 - accuracy: 0.95\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.1036 - accuracy: 0.9576A: 0s - loss: 6.2111e-04 - accuracy: 1.00\n",
      " 4/14 [=======>......................] - ETA: 0s - loss: 0.3667 - accuracy: 0.8672Epoch 24/25\n",
      "14/14 [==============================] - 0s 37ms/step - loss: 1.2599 - accuracy: 0.4799\n",
      "Epoch 3/25\n",
      "14/14 [==============================] - 0s 36ms/step - loss: 1.1059 - accuracy: 0.5737A: 0s - loss: 0.0295 - accuracy: 0.98\n",
      "Epoch 4/25\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.0423 - accuracy: 0.9799- loss: 0.0866 - accuracy: 0.9732 - ETA: 0s - loss: 0.0412 - accuracy: 0.98\n",
      "Epoch 13/25\n",
      "14/14 [==============================] - 1s 44ms/step - loss: 0.3485 - accuracy: 0.8571- loss: 0.0257 - accuracy: 0.9896 - ETA: 0s - loss: 0.0841 - accuracy: 0.97\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0253 - accuracy: 0.9911"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:27:11.756727: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 1s 39ms/step - loss: 0.0253 - accuracy: 0.9911\n",
      "Epoch 24/25\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.0746 - accuracy: 0.9732\n",
      "11/14 [======================>.......] - ETA: 0s - loss: 6.4644e-04 - accuracy: 1.0000Epoch 25/25\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.8480 - accuracy: 0.6920\n",
      "Epoch 4/25\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 6.7214e-04 - accuracy: 1.0000\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 0.0324 - accuracy: 0.9792Epoch 24/25\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.5132 - accuracy: 0.8304\n",
      "Epoch 5/25\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.0196 - accuracy: 0.9978TA: 0s - loss: 0.0017 - accuracy: 1.0000  \n",
      "11/14 [======================>.......] - ETA: 0s - loss: 0.0498 - accuracy: 0.9773Epoch 14/25\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.0479 - accuracy: 0.9821A: 0s - loss: 0.0487 - accuracy: 0.\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.0252 - accuracy: 0.9866\n",
      "Epoch 25/25\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.4808 - accuracy: 0.8281\n",
      "Epoch 5/25\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.2029 - accuracy: 0.9563Epoch 25/25\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.1995 - accuracy: 0.9487\n",
      "Epoch 6/25\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 1.6506 - accuracy: 0.3264"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:27:12.428290: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-01-09 14:27:12.597676: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 23ms/step - loss: 0.0123 - accuracy: 0.9955\n",
      "Epoch 15/25\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 1.6139 - accuracy: 0.3326\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.0076 - accuracy: 1.0000Epoch 2/25\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.2335 - accuracy: 0.9464\n",
      "[CV 2/5] END ...epochs=25, layers=3, neurons=40;, score=0.946 total time=  15.2s\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.0074 - accuracy: 1.0000\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.1506 - accuracy: 0.9643\n",
      "[CV 5/5] END ...epochs=25, layers=3, neurons=40;, score=0.964 total time=  11.5s 5/14 [=========>....................]\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.2629 - accuracy: 0.9174\n",
      "Epoch 6/25\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.0035 - accuracy: 0.9978\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.1101 - accuracy: 0.9554\n",
      "Epoch 7/25\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0140 - accuracy: 0.9955\n",
      " 4/14 [=======>......................] - ETA: 0s - loss: 0.1610 - accuracy: 0.9531Epoch 16/25\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 1.4496 - accuracy: 0.3929\n",
      "Epoch 3/25\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.1405 - accuracy: 0.9643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:27:13.284382: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-01-09 14:27:13.290696: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/25\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.0296 - accuracy: 0.9933\n",
      "Epoch 17/25\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.0681 - accuracy: 0.9799\n",
      "Epoch 8/25\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 0.0574 - accuracy: 0.9911\n",
      "[CV 4/5] END ...epochs=25, layers=3, neurons=40;, score=0.991 total time=  15.3s\n",
      "4/4 [==============================] - 0s 92ms/step - loss: 6.5037e-04 - accuracy: 1.0000\n",
      "[CV 3/5] END ...epochs=25, layers=3, neurons=40;, score=1.000 total time=  15.9s\n",
      "14/14 [==============================] - 1s 36ms/step - loss: 1.1208 - accuracy: 0.5402\n",
      "Epoch 4/25\n",
      " - 1s 38ms/step - loss: 0.0882 - accuracy: 0.9754- loss: 0.0882 - accuracy: 0.97\n",
      " 5/14 [=========>....................] - ETA: 0s - loss: 0.8239 - accuracy: 0.6687Epoch 8/25\n",
      "14/14 [==============================] - 1s 44ms/step - loss: 0.0113 - accuracy: 1.0000- loss: 0.0969 - accuracy: 0.9712 - ETA: 0s - loss: 0.0113 - accuracy: 1.00\n",
      "Epoch 18/25\n",
      "14/14 [==============================] - 1s 48ms/step - loss: 0.0931 - accuracy: 0.9732\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.8227 - accuracy: 0.6406Epoch 9/25\n",
      " 5/14 [=========>....................] - ETA: 0s - loss: 0.0082 - accuracy: 1.0000Epoch 1/25\n",
      "14/14 [==============================] - 1s 49ms/step - loss: 0.7751 - accuracy: 0.6607\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.0466 - accuracy: 0.9861Epoch 5/25\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.0082 - accuracy: 1.0000Epoch 1/50\n",
      "14/14 [==============================] - 1s 35ms/step - loss: 0.0441 - accuracy: 0.9866\n",
      " 4/14 [=======>......................] - ETA: 0s - loss: 0.4771 - accuracy: 0.7656Epoch 9/25\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0091 - accuracy: 0.9978\n",
      "Epoch 19/25\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.0433 - accuracy: 0.9866\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 0.0265 - accuracy: 0.9911Epoch 10/25\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.4178 - accuracy: 0.8304\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 0.0198 - accuracy: 0.9896Epoch 6/25\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.0302 - accuracy: 0.9888A: 0s - loss: 0.0018 - accuracy: 1.00\n",
      "Epoch 10/25\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.0266 - accuracy: 0.9911- loss: 0.0583 - accuracy: 0.9688 - ETA: 0s - loss: 0.0278 - accuracy: 0.\n",
      "14/14 [==============================]Epoch 11/25\n",
      "14/14 [==============================] - 1s 51ms/step - loss: 0.0109 - accuracy: 0.9955\n",
      "Epoch 20/25\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.2745 - accuracy: 0.8951\n",
      "Epoch 7/25\n",
      "12/14 [========================>.....] - ETA: 0s - loss: 0.0857 - accuracy: 0.9609"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:27:15.330217: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================]11/14 [======================>.......] - 1s 41ms/step - loss: 0.1194 - accuracy: 0.9509\n",
      " - ETA: 0s - loss: 0.0099 - accuracy: 0.9972Epoch 11/25\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.0105 - accuracy: 0.9978\n",
      "Epoch 21/25\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.0217 - accuracy: 0.9955\n",
      "Epoch 12/25\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.1875 - accuracy: 0.9554A: 0s - loss: 0.0912 - accuracy: 0.\n",
      "Epoch 8/25\n",
      "14/14 [==============================] - 0s 22ms/step - loss: 0.0056 - accuracy: 0.9978\n",
      "Epoch 22/25\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0484 - accuracy: 0.9821\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.0039 - accuracy: 1.0000Epoch 12/25\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 1.6525 - accuracy: 0.2531Epoch 1/50\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 0.0120 - accuracy: 0.9896Epoch 1/50\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.0094 - accuracy: 1.0000\n",
      " 5/14 [=========>....................] - ETA: 0s - loss: 0.0091 - accuracy: 0.9938Epoch 13/25\n",
      "14/14 [==============================] - 2s 20ms/step - loss: 1.6048 - accuracy: 0.2879\n",
      "Epoch 2/50\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.0058 - accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:27:16.055550: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 33ms/step - loss: 0.1484 - accuracy: 0.9509A: 0s - loss: 0.0454 - accuracy: 0.9948\n",
      "Epoch 9/25\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0079 - accuracy: 0.9978\n",
      " 5/14 [=========>....................] - ETA: 0s - loss: 0.1130 - accuracy: 0.9375Epoch 23/25\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0246 - accuracy: 0.9955\n",
      "Epoch 13/25\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0207 - accuracy: 0.9978- loss: 0.0207 - accuracy: 0.9978 - ETA: 0s - loss: 1.4253 - accuracy: 0.37\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 0.0054 - accuracy: 1.0000Epoch 14/25\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 1.4187 - accuracy: 0.3728\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.0094 - accuracy: 1.0000Epoch 3/50\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.1237 - accuracy: 0.9464\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.0022 - accuracy: 1.0000Epoch 10/25\n",
      "11/14 [======================>.......] - ETA: 0s - loss: 0.0026 - accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:27:16.700795: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 32ms/step - loss: 0.0028 - accuracy: 1.0000\n",
      " 5/14 [=========>....................]Epoch 24/25- loss: 0.0086 - accuracy: 0.99\n",
      "14/14 [==============================] - 0s 36ms/step - loss: 0.0093 - accuracy: 0.9978\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.0091 - accuracy: 0.9978\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 0.0767 - accuracy: 0.9777Epoch 14/25\n",
      "Epoch 15/25\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 1.2027 - accuracy: 0.4576\n",
      "Epoch 4/50\n",
      " 8/14 [================>.............] - ETA: 0s - loss: 1.6010 - accuracy: 0.2930 - ETA: 0s - loss: 0.0029 - accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:27:16.915723: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================]13/14 [==========================>...] - ETA: 0s - loss: 1.6008 - accuracy: 0.2668 - 0s 34ms/step - loss: 0.0767 - accuracy: 0.9777\n",
      "Epoch 11/25\n",
      "14/14 [==============================] - 3s 39ms/step - loss: 1.5862 - accuracy: 0.2812\n",
      "Epoch 2/25\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.0012 - accuracy: 1.0000A: 0s - loss: 0.0012 - accuracy: 1.0034\n",
      " 5/14 [=========>....................]Epoch 25/25\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.0057 - accuracy: 1.0000A: 0s - loss: 1.6826 - accuracy: 0.3063\n",
      "Epoch 15/25\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.9377 - accuracy: 0.6674\n",
      "Epoch 5/50\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.0038 - accuracy: 1.0000\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 1.0779 - accuracy: 0.6250 - ETA: 0s - loss: 1.8682 - accuracy: 0.3021Epoch 16/25\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.0752 - accuracy: 0.9754- loss: 1.6457 - accuracy: 0.3047 - ETA: 0s - loss: 0.0782 - accuracy: 0.\n",
      "Epoch 12/25\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 1.3381 - accuracy: 0.4308- loss: 1.6920 - accuracy: 0.2768 - ETA: 0s - loss: 0.0026 - accuracy: 1.00\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 3/25\n",
      "14/14 [==============================] - 2s 53ms/step - loss: 1.5949 - accuracy: 0.3371\n",
      "Epoch 2/50\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.6675 - accuracy: 0.7701\n",
      "Epoch 6/50\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.0020 - accuracy: 1.0000A: 0s - loss: 1.1420 - accuracy: 0.50\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 1.6002 - accuracy: 0.3005Epoch 17/25\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.0022 - accuracy: 1.0000- loss: 0.0571 - accuracy: 0.9777 - ETA: 0s - loss: 0.5206 - accuracy: 0.8047\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 1.0636 - accuracy: 0.5714Epoch 16/25\n",
      "14/14 [==============================] - 2s 54ms/step - loss: 1.6053 - accuracy: 0.2946\n",
      "Epoch 2/50\n",
      "14/14 [==============================] - 0s 23ms/step - loss: 0.4271 - accuracy: 0.8594A: 0s - loss: 1.5580 - accuracy: 0.\n",
      "Epoch 7/50\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.9572 - accuracy: 0.6205\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 1.4301 - accuracy: 0.3683\n",
      "Epoch 4/25\n",
      "Epoch 3/50\n",
      "14/14 [==============================] - 1s 44ms/step - loss: 0.0791 - accuracy: 0.9688\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 1.4118 - accuracy: 0.3125Epoch 13/25\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0079 - accuracy: 0.9978\n",
      "11/14 [======================>.......] - ETA: 0s - loss: 1.4258 - accuracy: 0.3438Epoch 18/25\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.0016 - accuracy: 1.0000- loss: 0.0016 - accuracy: 1.0000 - ETA: 0s - loss: 1.4102 - accuracy: 0.34\n",
      " 8/14 [================>.............] - ETA: 0s - loss: 0.3387 - accuracy: 0.8867Epoch 17/25\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 1.3910 - accuracy: 0.3571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:27:18.386824: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/50\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 5.1781e-04 - accuracy: 1.0000 0s - loss: 0.0729 - accuracy: 0.96\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.3089 - accuracy: 0.8973\n",
      "Epoch 8/50\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.0064 - accuracy: 0.9965[CV 1/5] END ...epochs=25, layers=3, neurons=60;, score=1.000 total time=  14.6s\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.5152 - accuracy: 0.8415A: 0s - loss: 1.2445 - accuracy: 0.\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.0819 - accuracy: 0.9639Epoch 5/25\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.0877 - accuracy: 0.9621\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.0025 - accuracy: 1.0000Epoch 14/25\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 1.2763 - accuracy: 0.4040\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.0281 - accuracy: 1.0000Epoch 4/50\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.0075 - accuracy: 0.9978\n",
      "Epoch 19/25\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.0020 - accuracy: 1.0000A: 0s - loss: 0.0043 - accuracy: 1.0000  \n",
      " 4/14 [=======>......................] - ETA: 0s - loss: 1.0877 - accuracy: 0.3984Epoch 18/25\n",
      "14/14 [==============================] - 0s 22ms/step - loss: 0.2743 - accuracy: 0.9085\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 0.2844 - accuracy: 0.8973Epoch 9/50\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 1.1549 - accuracy: 0.4219\n",
      "Epoch 4/50\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.1015 - accuracy: 0.9665\n",
      "Epoch 15/25\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.2430 - accuracy: 0.9219\n",
      " 8/14 [================>.............] - ETA: 0s - loss: 0.9036 - accuracy: 0.5859Epoch 6/25\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.0066 - accuracy: 1.0000\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.2509 - accuracy: 0.9236Epoch 20/25\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 1.0646 - accuracy: 0.5022A: 0s - loss: 1.0646 - accuracy: 0.50\n",
      "Epoch 5/50\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0011 - accuracy: 1.0000A: 0s - loss: 0.0011 - accuracy: 1.00\n",
      "12/14 [========================>.....] - ETA: 0s - loss: 0.9040 - accuracy: 0.5781Epoch 19/25\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.2485 - accuracy: 0.9063\n",
      " 8/14 [================>.............] - ETA: 0s - loss: 0.0882 - accuracy: 0.9648Epoch 10/50\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.8795 - accuracy: 0.5938\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.3156 - accuracy: 0.8438Epoch 5/50\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 0.1441 - accuracy: 0.9643Epoch 1/50\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.0602 - accuracy: 0.9777\n",
      "Epoch 16/25\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.0056 - accuracy: 0.9978\n",
      "Epoch 21/25\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.1364 - accuracy: 0.9643\n",
      "Epoch 7/25\n",
      "14/14 [==============================] - 0s 22ms/step - loss: 0.1736 - accuracy: 0.9442\n",
      "Epoch 11/50\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.2065 - accuracy: 0.9375"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:27:19.493351: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 20/25\n",
      "14/14 [==============================] - 1s 36ms/step - loss: 0.8777 - accuracy: 0.6562\n",
      " 4/14 [=======>......................] - ETA: 0s - loss: 0.1916 - accuracy: 0.9219Epoch 6/50\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.6855 - accuracy: 0.7232\n",
      "Epoch 6/50\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.0066 - accuracy: 1.0000- loss: 0.0066 - accuracy: 1.0000 - ETA: 0s - loss: 1.5662 - accuracy: 0.27\n",
      "Epoch 22/25\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.0182 - accuracy: 0.9933\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 0.7809 - accuracy: 0.7098Epoch 17/25\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 0.1718 - accuracy: 0.9442\n",
      "14/14 [==============================] - 1s 26ms/step - loss: 1.5733 - accuracy: 0.2768\n",
      "Epoch 12/50\n",
      "Epoch 2/50\n",
      "14/14 [==============================] - 1s 36ms/step - loss: 0.1051 - accuracy: 0.9688A: 0s - loss: 0.5254 - accuracy: 0.\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 8/25\n",
      "Epoch 21/25\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.7503 - accuracy: 0.7411- loss: 0.0132 - accuracy: 0.9955 - ETA: 0s - loss: 0.1495 - accuracy: 0.95\n",
      "Epoch 7/50\n",
      "14/14 [==============================] - 0s 20ms/step - loss: 0.1415 - accuracy: 0.9509\n",
      " 5/14 [=========>....................] - ETA: 0s - loss: 0.0535 - accuracy: 0.9875Epoch 13/50\n",
      "14/14 [==============================] - 0s 24ms/step - loss: 1.4173 - accuracy: 0.3951\n",
      "Epoch 3/50\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 23/25\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.5288 - accuracy: 0.7813\n",
      "Epoch 7/50\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.0162 - accuracy: 0.9955\n",
      "Epoch 18/25\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.0034 - accuracy: 1.0000\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 0.6995 - accuracy: 0.7679Epoch 22/25\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.0387 - accuracy: 0.9911\n",
      "Epoch 9/25\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 0.1318 - accuracy: 0.9420\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.0034 - accuracy: 1.0000Epoch 14/50\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 1.1879 - accuracy: 0.4911\n",
      " 8/14 [================>.............] - ETA: 0s - loss: 0.0322 - accuracy: 0.9922Epoch 4/50\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.0282 - accuracy: 0.9866\n",
      "11/14 [======================>.......] - ETA: 0s - loss: 0.4401 - accuracy: 0.9148Epoch 24/25\n",
      "14/14 [==============================] - 1s 44ms/step - loss: 0.6904 - accuracy: 0.7768\n",
      "Epoch 8/50\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.4234 - accuracy: 0.9107\n",
      "11/14 [======================>.......] - ETA: 0s - loss: 0.1017 - accuracy: 0.9688Epoch 8/50\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0244 - accuracy: 0.9933\n",
      "14/14 [==============================] - 0s 36ms/step - loss: 0.0312 - accuracy: 0.9866\n",
      "Epoch 23/25\n",
      "Epoch 19/25\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.1059 - accuracy: 0.9665\n",
      "Epoch 15/50\n",
      "14/14 [==============================] 4/14 [=======>......................] - ETA: 0s - loss: 0.0315 - accuracy: 0.9922 - 1s 36ms/step - loss: 0.0247 - accuracy: 0.9978\n",
      " 5/14 [=========>....................] - ETA: 0s - loss: 0.0293 - accuracy: 0.9875Epoch 10/25\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.9324 - accuracy: 0.5379A: 0s - loss: 0.7396 - accuracy: 0.\n",
      "Epoch 5/50\n",
      "14/14 [==============================] - 1s 34ms/step - loss: 0.0859 - accuracy: 0.9732\n",
      "Epoch 25/25\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.6723 - accuracy: 0.7813A: 0s - loss: 0.1367 - accuracy: 0.96\n",
      "Epoch 9/50\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.1835 - accuracy: 0.9353\n",
      "Epoch 16/50\n",
      "14/14 [==============================] - 1s 36ms/step - loss: 0.0199 - accuracy: 0.9955A: 0s - loss: 0.0199 - accuracy: 0.99\n",
      "Epoch 24/25\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.0262 - accuracy: 0.9911A: 0s - loss: 0.8547 - accuracy: 0.5382\n",
      "Epoch 20/25\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.3861 - accuracy: 0.9107\n",
      "11/14 [======================>.......] - ETA: 0s - loss: 0.0379 - accuracy: 0.9858Epoch 9/50\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.0384 - accuracy: 0.9866A: 0s - loss: 0.8044 - accuracy: 0.\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 0.3411 - accuracy: 0.9062Epoch 11/25\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.8076 - accuracy: 0.5513\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 0.6526 - accuracy: 0.7991Epoch 6/50\n",
      "11/14 [======================>.......] - 0s 30ms/step - loss: 0.0834 - accuracy: 0.9688\n",
      "14/14 [==============================] - 0s 24ms/step - loss: 0.1427 - accuracy: 0.9397\n",
      " 5/14 [=========>....................] - ETA: 0s - loss: 0.0282 - accuracy: 0.9938Epoch 17/50\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.0199 - accuracy: 0.9978\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.3636 - accuracy: 0.8924Epoch 25/25\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.6545 - accuracy: 0.7857\n",
      "Epoch 10/50\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.0114 - accuracy: 0.9955\n",
      "Epoch 21/25\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.3501 - accuracy: 0.9107- loss: 0.6773 - accuracy: 0.7708 - ETA: 0s - loss: 0.7806 - accuracy: 0.56\n",
      "11/14 [======================>.......] - ETA: 0s - loss: 0.0245 - accuracy: 0.9943Epoch 10/50\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.7968 - accuracy: 0.5960\n",
      "Epoch 7/50\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.0214 - accuracy: 0.9955\n",
      "Epoch 12/25\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 0.1356 - accuracy: 0.9442\n",
      " 5/14 [=========>....................] - ETA: 0s - loss: 0.2976 - accuracy: 0.9500Epoch 18/50\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 0.2952 - accuracy: 0.9420"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:27:22.101236: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 29ms/step - loss: 0.1657 - accuracy: 0.9509\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.6495 - accuracy: 0.7723\n",
      "Epoch 11/50\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0133 - accuracy: 0.9955A: 0s - loss: 0.0147 - accuracy: 0.99\n",
      "Epoch 22/25\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.0037 - accuracy: 1.0000\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.0161 - accuracy: 1.0000[CV 2/5] END ...epochs=25, layers=3, neurons=60;, score=1.000 total time=  13.9s\n",
      "11/14 [======================>.......] - 0s 27ms/step - loss: 0.7479 - accuracy: 0.5982A: 0s - loss: 0.7453 - accuracy: 0.\n",
      "14/14 [==============================]Epoch 8/50\n",
      " - 0s 32ms/step - loss: 0.2855 - accuracy: 0.9442\n",
      "Epoch 11/50\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.0203 - accuracy: 0.9933\n",
      "14/14 [==============================]Epoch 13/25- loss: 0.1342 - accuracy: 0.94\n",
      " - 0s 27ms/step - loss: 0.1342 - accuracy: 0.9464\n",
      "Epoch 19/50\n",
      " 4/14 [=======>......................] - ETA: 0s - loss: 0.0623 - accuracy: 0.9844"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:27:22.524992: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - ETA: 0s - loss: 0.0197 - accuracy: 0.9938 - 0s 25ms/step - loss: 0.0147 - accuracy: 0.9933\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.6279 - accuracy: 0.7857\n",
      "10/14 [====================>.........]Epoch 23/25\n",
      " - ETA: 0s - loss: 0.7964 - accuracy: 0.6781Epoch 12/50\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.0255 - accuracy: 0.9911\n",
      "[CV 3/5] END ...epochs=25, layers=3, neurons=60;, score=0.991 total time=  13.6s\n",
      "14/14 [==============================] - 0s 24ms/step - loss: 0.7664 - accuracy: 0.6562\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.0122 - accuracy: 0.9969Epoch 9/50\n",
      "14/14 [==============================] - 0s 24ms/step - loss: 0.0754 - accuracy: 0.9710A: 0s - loss: 0.0226 - accuracy: 0.99\n",
      "Epoch 20/50\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.2592 - accuracy: 0.9576\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 0.6848 - accuracy: 0.7500Epoch 12/50\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0150 - accuracy: 0.9978\n",
      "Epoch 14/25\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0177 - accuracy: 0.9955\n",
      "Epoch 24/25\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.6406 - accuracy: 0.7835\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.1049 - accuracy: 0.9500Epoch 13/50\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.7070 - accuracy: 0.5960\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.7233 - accuracy: 0.8438Epoch 10/50\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.0994 - accuracy: 0.9509A: 0s - loss: 0.3059 - accuracy: 0.92\n",
      "Epoch 21/50\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.0216 - accuracy: 0.9911\n",
      "Epoch 15/25\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.3039 - accuracy: 0.9308\n",
      "Epoch 13/50\n",
      " 6/14 [===========>..................] - ETA: 0s - loss: 0.6732 - accuracy: 0.5729Epoch 1/50\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.0204 - accuracy: 0.9933\n",
      "Epoch 25/25\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.7025 - accuracy: 0.5647\n",
      "14/14 [==============================] - 0s 22ms/step - loss: 0.0737 - accuracy: 0.9643\n",
      "Epoch 11/50\n",
      "Epoch 22/50\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.6143 - accuracy: 0.8013\n",
      "Epoch 14/50\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 0.0269 - accuracy: 0.9911\n",
      "Epoch 16/25\n",
      "11/14 [======================>.......] 1/14 [=>............................] - ETA: 0s - loss: 0.2735 - accuracy: 0.9403 - ETA: 0s - loss: 0.0049 - accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:27:23.599066: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 31ms/step - loss: 0.2603 - accuracy: 0.9464\n",
      " 8/14 [================>.............] - ETA: 0s - loss: 0.0598 - accuracy: 0.9766Epoch 14/50\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0143 - accuracy: 0.9933\n",
      "14/14 [==============================] - 0s 23ms/step - loss: 0.0612 - accuracy: 0.9732\n",
      "Epoch 23/50\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.6919 - accuracy: 0.5804\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.0301 - accuracy: 1.0000Epoch 12/50\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.6106 - accuracy: 0.8058\n",
      "Epoch 15/50\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.0081 - accuracy: 0.9978A: 0s - loss: 1.7029 - accuracy: 0.21\n",
      "Epoch 17/25\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 0.6242 - accuracy: 0.7604Epoch 1/50\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.2788 - accuracy: 0.9397\n",
      "12/14 [========================>.....] - ETA: 0s - loss: 0.0850 - accuracy: 0.9609Epoch 15/50\n",
      "14/14 [==============================] - 0s 22ms/step - loss: 0.0814 - accuracy: 0.9621\n",
      "Epoch 24/50\n",
      "14/14 [==============================] - 1s 35ms/step - loss: 1.6276 - accuracy: 0.2500\n",
      "Epoch 2/50\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.6584 - accuracy: 0.5424\n",
      "Epoch 13/50\n",
      " 4/14 [=======>......................] - ETA: 0s - loss: 0.0533 - accuracy: 0.9844"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:27:24.189308: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-01-09 14:27:24.377392: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 28ms/step - loss: 0.6066 - accuracy: 0.7723\n",
      " 5/14 [=========>....................] - ETA: 0s - loss: 1.4910 - accuracy: 0.3875Epoch 16/50\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.0108 - accuracy: 0.9933\n",
      "Epoch 18/25\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.0275 - accuracy: 0.9911\n",
      "[CV 4/5] END ...epochs=25, layers=3, neurons=60;, score=0.991 total time=  14.4s\n",
      "14/14 [==============================] - 0s 21ms/step - loss: 0.0872 - accuracy: 0.9665\n",
      "12/14 [========================>.....] - ETA: 0s - loss: 0.2805 - accuracy: 0.9349Epoch 25/50\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.2857 - accuracy: 0.9353\n",
      "Epoch 16/50\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.6434 - accuracy: 0.5603A: 0s - loss: 0.6006 - accuracy: 0.81\n",
      "Epoch 14/50\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 1.4676 - accuracy: 0.3772\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 0.0718 - accuracy: 0.9598Epoch 3/50\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0142 - accuracy: 0.9978- loss: 0.0968 - accuracy: 0.9557 - ETA: 0s - loss: 0.0142 - accuracy: 0.99\n",
      " 5/14 [=========>....................] - ETA: 0s - loss: 0.5834 - accuracy: 0.5938Epoch 19/25\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.5997 - accuracy: 0.7924\n",
      "Epoch 17/50\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 0.0963 - accuracy: 0.9531\n",
      "Epoch 26/50\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.2610 - accuracy: 0.9487\n",
      "Epoch 17/50\n",
      "14/14 [==============================] - 1s 35ms/step - loss: 1.7764 - accuracy: 0.2656\n",
      "Epoch 2/50\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.6166 - accuracy: 0.5804\n",
      "Epoch 15/50\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 1.2800 - accuracy: 0.4085\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 0.2146 - accuracy: 0.9479Epoch 4/50\n",
      "14/14 [==============================] - 0s 24ms/step - loss: 0.0831 - accuracy: 0.9509\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 1.1929 - accuracy: 0.3958Epoch 27/50\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.0190 - accuracy: 0.9933\n",
      "Epoch 20/25\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.5821 - accuracy: 0.7969\n",
      "Epoch 18/50\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 0.6269 - accuracy: 0.5737- loss: 1.5567 - accuracy: 0.3352 - ETA: 0s - loss: 0.2561 - accuracy: 0.95\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 1.1410 - accuracy: 0.5139Epoch 16/50\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 1.5402 - accuracy: 0.3527\n",
      "Epoch 3/50\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.2428 - accuracy: 0.9554\n",
      "Epoch 18/50\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 1.0748 - accuracy: 0.5577Epoch 1/50 - loss: 0.5369 - accuracy: 0.69\n",
      "14/14 [==============================] - 0s 20ms/step - loss: 0.0606 - accuracy: 0.9688\n",
      "Epoch 28/50\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 1.0623 - accuracy: 0.5625\n",
      "Epoch 5/50\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.0039 - accuracy: 1.0000\n",
      "Epoch 21/25\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.5974 - accuracy: 0.7902A: 0s - loss: 0.0021 - accuracy: 1.00\n",
      "Epoch 19/50\n",
      "14/14 [==============================] - 0s 24ms/step - loss: 0.5970 - accuracy: 0.6138\n",
      " 8/14 [================>.............] - ETA: 0s - loss: 0.8811 - accuracy: 0.6445Epoch 17/50\n",
      "11/14 [======================>.......] - ETA: 0s - loss: 0.8584 - accuracy: 0.6335"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:27:25.763691: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 28ms/step - loss: 1.5020 - accuracy: 0.3438\n",
      "Epoch 4/50\n",
      "14/14 [==============================] - 0s 23ms/step - loss: 0.0664 - accuracy: 0.9643\n",
      " 4/14 [=======>......................] - ETA: 0s - loss: 0.6042 - accuracy: 0.5781Epoch 29/50\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.8151 - accuracy: 0.6562\n",
      "Epoch 6/50\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.2622 - accuracy: 0.9420\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.5855 - accuracy: 0.7188Epoch 19/50\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0014 - accuracy: 1.0000A: 0s - loss: 2.0492 - accuracy: 0.\n",
      "Epoch 22/25\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 0.6062 - accuracy: 0.5804\n",
      "11/14 [======================>.......] - ETA: 0s - loss: 0.0524 - accuracy: 0.9744Epoch 18/50\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.5523 - accuracy: 0.8170\n",
      "Epoch 20/50\n",
      "14/14 [==============================] - 0s 22ms/step - loss: 0.0568 - accuracy: 0.9754\n",
      " 6/14 [===========>..................] - ETA: 0s - loss: 0.2374 - accuracy: 0.9583Epoch 30/50\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 1.4256 - accuracy: 0.3862\n",
      "Epoch 5/50\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.6372 - accuracy: 0.7500\n",
      "Epoch 7/50\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 1.6062 - accuracy: 0.3884\n",
      "11/14 [======================>.......]Epoch 2/50\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.2665 - accuracy: 0.9420\n",
      "Epoch 20/50\n",
      "14/14 [==============================] - 0s 21ms/step - loss: 0.0644 - accuracy: 0.9821\n",
      "Epoch 31/50\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.6050 - accuracy: 0.6339\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.5625 - accuracy: 0.8125Epoch 19/50\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 7.2860e-04 - accuracy: 1.0000\n",
      "Epoch 23/25\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 1.2012 - accuracy: 0.4754A: 0s - loss: 1.1975 - accuracy: 0.49\n",
      " 4/14 [=======>......................] - ETA: 0s - loss: 0.2880 - accuracy: 0.9531Epoch 6/50\n",
      "14/14 [==============================] - 1s 34ms/step - loss: 0.5730 - accuracy: 0.7946\n",
      "Epoch 21/50\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.5094 - accuracy: 0.7991\n",
      " 8/14 [================>.............] - ETA: 0s - loss: 0.2399 - accuracy: 0.9570Epoch 8/50\n",
      "14/14 [==============================] - 0s 21ms/step - loss: 0.0551 - accuracy: 0.9732\n",
      "Epoch 32/50\n",
      "14/14 [==============================] - 0s 24ms/step - loss: 0.5837 - accuracy: 0.6250\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 1.0267 - accuracy: 0.5491Epoch 20/50\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.9351 - accuracy: 0.6830\n",
      "Epoch 3/50\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 3.6096e-04 - accuracy: 1.0000ss: 0.2441 - accuracy: 0.9495 - ETA: 0s - loss: 3.2027e-04 - accuracy: 1.00\n",
      "Epoch 24/25\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.2382 - accuracy: 0.9509\n",
      "Epoch 21/50\n",
      "14/14 [==============================] - 0s 20ms/step - loss: 0.0383 - accuracy: 0.9933\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.9665 - accuracy: 0.5982\n",
      "Epoch 33/50\n",
      "Epoch 7/50\n",
      "14/14 [==============================]13/14 [==========================>...] - 0s 26ms/step - loss: 0.4849 - accuracy: 0.7746\n",
      " - ETA: 0s - loss: 0.5633 - accuracy: 0.7957Epoch 9/50\n",
      "14/14 [==============================] - 0s 23ms/step - loss: 0.5367 - accuracy: 0.6540\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.5722 - accuracy: 0.7946\n",
      "Epoch 22/50\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.5030 - accuracy: 0.6875Epoch 21/50\n",
      "14/14 [==============================] - 0s 20ms/step - loss: 0.0404 - accuracy: 0.9933\n",
      " 6/14 [===========>..................] - ETA: 0s - loss: 0.4862 - accuracy: 0.6354Epoch 34/50\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.5419 - accuracy: 0.8259\n",
      "Epoch 4/50\n",
      "14/14 [==============================] - 0s 36ms/step - loss: 2.6446e-04 - accuracy: 1.0000\n",
      "Epoch 25/25\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.8731 - accuracy: 0.6116\n",
      "Epoch 8/50\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.2740 - accuracy: 0.9330\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.8468 - accuracy: 0.6250Epoch 22/50\n",
      "14/14 [==============================] - 0s 24ms/step - loss: 0.5167 - accuracy: 0.6518\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.0454 - accuracy: 0.9875Epoch 22/50\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.4284 - accuracy: 0.7835\n",
      "Epoch 10/50\n",
      "14/14 [==============================] - 0s 18ms/step - loss: 0.0418 - accuracy: 0.9888A: 0s - loss: 2.3848e-04 - accuracy: 1.00\n",
      "Epoch 35/50\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.5789 - accuracy: 0.7991\n",
      " 6/14 [===========>..................] - ETA: 0s - loss: 0.3964 - accuracy: 0.8073Epoch 23/50\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.2242 - accuracy: 0.9509\n",
      "Epoch 5/50\n",
      "14/14 [==============================] - 0s 19ms/step - loss: 0.0402 - accuracy: 0.9866\n",
      "Epoch 36/50\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 0.5012 - accuracy: 0.7076\n",
      "Epoch 23/50\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.8074 - accuracy: 0.6585\n",
      "Epoch 9/50\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 0.4488 - accuracy: 0.7879\n",
      "Epoch 11/50\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 2.6943e-04 - accuracy: 1.0000\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.2342 - accuracy: 0.9554\n",
      "Epoch 23/50\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.1053 - accuracy: 0.9688"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:27:28.036750: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 22ms/step - loss: 0.0294 - accuracy: 0.9978\n",
      "Epoch 37/50\n",
      "14/14 [==============================]1/4 [======>.......................] - 0s 34ms/step - loss: 0.6082 - accuracy: 0.7679\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.4391 - accuracy: 0.7625Epoch 24/50\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 0.5081 - accuracy: 0.7857\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.4490 - accuracy: 0.7812Epoch 24/50\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0855 - accuracy: 0.9821\n",
      "12/14 [========================>.....] - ETA: 0s - loss: 0.4344 - accuracy: 0.7682Epoch 6/50\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.0265 - accuracy: 0.9911\n",
      "[CV 5/5] END ...epochs=25, layers=3, neurons=60;, score=0.991 total time=  14.9s\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.7852 - accuracy: 0.6719\n",
      "Epoch 10/50\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.4353 - accuracy: 0.7723\n",
      "Epoch 12/50\n",
      "14/14 [==============================] - 0s 21ms/step - loss: 0.0445 - accuracy: 0.9844A: 0s - loss: 0.5499 - accuracy: 0.78\n",
      " 5/14 [=========>....................] - ETA: 0s - loss: 0.3919 - accuracy: 0.8063Epoch 38/50\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.3356 - accuracy: 0.9018\n",
      "Epoch 24/50\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 0.5210 - accuracy: 0.7790\n",
      "Epoch 25/50\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.6917 - accuracy: 0.7277\n",
      "Epoch 25/50\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0643 - accuracy: 0.9799\n",
      "Epoch 7/50\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.3741 - accuracy: 0.8058\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.7679 - accuracy: 0.6719\n",
      "Epoch 13/50\n",
      "Epoch 11/50\n",
      "14/14 [==============================] - 0s 22ms/step - loss: 0.0349 - accuracy: 0.9911\n",
      "Epoch 39/50\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.5859 - accuracy: 0.7917Epoch 1/50\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.5853 - accuracy: 0.7567\n",
      "Epoch 26/50\n",
      "14/14 [==============================] - 1s 34ms/step - loss: 0.2951 - accuracy: 0.9241- loss: 0.7818 - accuracy: 0.6632 - ETA: 0s - loss: 0.0609 - accuracy: 0.98\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.5841 - accuracy: 0.7879\n",
      "Epoch 25/50\n",
      "Epoch 26/50\n",
      "14/14 [==============================] - 0s 24ms/step - loss: 0.0223 - accuracy: 0.9933\n",
      "Epoch 40/50\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.7736 - accuracy: 0.6652\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.3866 - accuracy: 0.7991\n",
      "Epoch 12/50\n",
      "Epoch 14/50\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.0598 - accuracy: 0.9866\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.0592 - accuracy: 0.9688Epoch 8/50\n",
      "14/14 [==============================] - 0s 24ms/step - loss: 0.7563 - accuracy: 0.6406\n",
      "Epoch 27/50\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.5238 - accuracy: 0.8438"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:27:29.252074: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 23ms/step - loss: 0.0201 - accuracy: 0.9978A: 0s - loss: 0.0572 - accuracy: 0.98\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 0.6260 - accuracy: 0.6741Epoch 41/50\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.3674 - accuracy: 0.8103\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.3227 - accuracy: 0.9085\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.7757 - accuracy: 0.6611Epoch 26/50\n",
      "Epoch 15/50\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.5526 - accuracy: 0.8058\n",
      "Epoch 27/50\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.7717 - accuracy: 0.6585\n",
      "Epoch 13/50\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.0495 - accuracy: 0.9911\n",
      "Epoch 9/50\n",
      "14/14 [==============================] - 0s 24ms/step - loss: 0.6714 - accuracy: 0.6585\n",
      "Epoch 28/50\n",
      "14/14 [==============================] - 0s 20ms/step - loss: 0.0138 - accuracy: 0.9978\n",
      "Epoch 42/50\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.3504 - accuracy: 0.8237\n",
      "Epoch 16/50\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.7646 - accuracy: 0.6652\n",
      "Epoch 14/50\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.0240 - accuracy: 0.9933\n",
      "Epoch 10/50\n",
      "14/14 [==============================] - 0s 24ms/step - loss: 0.6673 - accuracy: 0.6406\n",
      " - ETA: 0s - loss: 0.0156 - accuracy: 0.997614/14 [==============================] - 1s 39ms/step - loss: 1.5871 - accuracy: 0.3214\n",
      "Epoch 29/50\n",
      "Epoch 2/50\n",
      "14/14 [==============================] - 0s 19ms/step - loss: 0.0152 - accuracy: 0.9978\n",
      "Epoch 43/50\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.2710 - accuracy: 0.9286\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.0062 - accuracy: 1.0000Epoch 27/50\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.4938 - accuracy: 0.8214\n",
      "Epoch 28/50\n",
      "14/14 [==============================] - 0s 23ms/step - loss: 0.0233 - accuracy: 0.9933\n",
      "11/14 [======================>.......] - ETA: 0s - loss: 0.5653 - accuracy: 0.7330Epoch 44/50\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.3492 - accuracy: 0.8170\n",
      "Epoch 17/50\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.7351 - accuracy: 0.6719\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.2327 - accuracy: 0.9062Epoch 15/50\n",
      " - ETA: 0s - loss: 0.0338 - accuracy: 0.989614/14 [==============================] - 0s 30ms/step - loss: 0.5479 - accuracy: 0.7188- loss: 0.4930 - accuracy: 0.82\n",
      "Epoch 30/50\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.0088 - accuracy: 1.0000\n",
      "Epoch 11/50\n",
      "14/14 [==============================] - 1s 36ms/step - loss: 1.3056 - accuracy: 0.3795\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.3257 - accuracy: 0.9062Epoch 3/50\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.4892 - accuracy: 0.8192\n",
      "Epoch 29/50\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 0.0264 - accuracy: 0.9911\n",
      "10/14 [====================>.........]Epoch 45/50\n",
      "14/14 [==============================] - 1s 45ms/step - loss: 0.3005 - accuracy: 0.9152\n",
      "Epoch 28/50\n",
      "14/14 [==============================] - 0s 24ms/step - loss: 0.4866 - accuracy: 0.8415\n",
      "Epoch 31/50\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.3078 - accuracy: 0.8661\n",
      "11/14 [======================>.......] - ETA: 0s - loss: 0.0086 - accuracy: 0.9972Epoch 18/50\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.7668 - accuracy: 0.6607\n",
      "Epoch 16/50\n",
      "14/14 [==============================] - 1s 35ms/step - loss: 0.0084 - accuracy: 0.9978\n",
      "Epoch 12/50\n",
      "14/14 [==============================] - 0s 19ms/step - loss: 0.0129 - accuracy: 0.9978\n",
      "Epoch 46/50\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 1.1628 - accuracy: 0.3996- loss: 0.7763 - accuracy: 0.6458 - ETA: 0s - loss: 1.1628 - accuracy: 0.39\n",
      "Epoch 4/50\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.5556 - accuracy: 0.7835- loss: 0.0102 - accuracy: 1.0000 - ETA: 0s - loss: 1.0723 - accuracy: 0.48\n",
      "Epoch 30/50\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.4926 - accuracy: 0.8326\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.0373 - accuracy: 0.9812Epoch 32/50\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.2452 - accuracy: 0.9353\n",
      "Epoch 29/50\n",
      "14/14 [==============================] - 0s 19ms/step - loss: 0.0381 - accuracy: 0.9821\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.0049 - accuracy: 1.0000Epoch 47/50\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.3192 - accuracy: 0.8348\n",
      "Epoch 19/50\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.7401 - accuracy: 0.6607\n",
      " 6/14 [===========>..................] - ETA: 0s - loss: 0.5420 - accuracy: 0.8021Epoch 17/50\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.0058 - accuracy: 1.0000\n",
      " 5/14 [=========>....................]Epoch 13/50- loss: 1.0902 - accuracy: 0.47\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 1.1028 - accuracy: 0.4688\n",
      "Epoch 5/50\n",
      "14/14 [==============================] - 0s 22ms/step - loss: 0.5078 - accuracy: 0.8348\n",
      "Epoch 33/50\n",
      "14/14 [==============================] - 0s 18ms/step - loss: 0.0181 - accuracy: 0.9933\n",
      "Epoch 48/50\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.5395 - accuracy: 0.7879\n",
      "Epoch 31/50\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.3148 - accuracy: 0.8438A: 0s - loss: 0.0034 - accuracy: 1.00\n",
      "Epoch 20/50\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.7498 - accuracy: 0.6719\n",
      "Epoch 18/50\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.2202 - accuracy: 0.9509\n",
      "Epoch 30/50\n",
      "14/14 [==============================] - 0s 18ms/step - loss: 0.0262 - accuracy: 0.9844\n",
      "Epoch 49/50\n",
      "14/14 [==============================] - 0s 23ms/step - loss: 0.5110 - accuracy: 0.8013\n",
      " 6/14 [===========>..................] - ETA: 0s - loss: 0.3347 - accuracy: 0.8646Epoch 34/50\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 1.0924 - accuracy: 0.4866\n",
      "Epoch 6/50\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.0042 - accuracy: 1.0000\n",
      " 8/14 [================>.............] - ETA: 0s - loss: 0.3306 - accuracy: 0.8516Epoch 14/50\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.5232 - accuracy: 0.7902\n",
      "Epoch 32/50\n",
      "14/14 [==============================] - 0s 22ms/step - loss: 0.0086 - accuracy: 0.9978\n",
      "Epoch 50/50\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.3077 - accuracy: 0.8482\n",
      "11/14 [======================>.......] - ETA: 0s - loss: 0.5122 - accuracy: 0.8381Epoch 21/50\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.7561 - accuracy: 0.6696A: 0s - loss: 0.3359 - accuracy: 0.78\n",
      "Epoch 19/50\n",
      "14/14 [==============================] - 0s 22ms/step - loss: 0.4805 - accuracy: 0.8638\n",
      "Epoch 35/50\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.2120 - accuracy: 0.9464\n",
      "Epoch 31/50\n",
      "14/14 [==============================] - 0s 20ms/step - loss: 0.0425 - accuracy: 0.9844- loss: 0.7248 - accuracy: 0.6920 - ETA: 0s - loss: 0.5000 - accuracy: 0.79\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 15/50\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 1.0980 - accuracy: 0.4844\n",
      "Epoch 7/50\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.3306 - accuracy: 0.8259\n",
      "Epoch 22/50\n",
      "14/14 [==============================] - 0s 23ms/step - loss: 0.4394 - accuracy: 0.8594A: 0s - loss: 0.4394 - accuracy: 0.85\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.4932 - accuracy: 0.8053Epoch 36/50\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.5043 - accuracy: 0.8036\n",
      "Epoch 33/50\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.6818 - accuracy: 0.6897\n",
      "Epoch 20/50\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 3.2322e-04 - accuracy: 1.00: 0s - loss: 1.0043 - accuracy: 0.5188 - ETA: 0s - loss: 0.4806 - accuracy: 0.78"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:27:32.478950: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 32ms/step - loss: 0.2232 - accuracy: 0.9375\n",
      "Epoch 32/50\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 4.9533e-04 - accuracy: 1.0000\n",
      "[CV 1/5] END ...epochs=50, layers=2, neurons=20;, score=1.000 total time=  19.3s\n",
      "14/14 [==============================] - 0s 20ms/step - loss: 0.4616 - accuracy: 0.8705\n",
      "Epoch 37/50\n",
      "14/14 [==============================] - 0s 24ms/step - loss: 0.3139 - accuracy: 0.8237\n",
      "Epoch 23/50\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 16/50\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 1.0807 - accuracy: 0.4933\n",
      "Epoch 8/50\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.7279 - accuracy: 0.6629\n",
      "Epoch 21/50\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.4996 - accuracy: 0.8058\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.7838 - accuracy: 0.6250Epoch 34/50\n",
      "14/14 [==============================] - 0s 23ms/step - loss: 0.4215 - accuracy: 0.8728\n",
      "11/14 [======================>.......] - ETA: 0s - loss: 0.2010 - accuracy: 0.9460Epoch 38/50\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.2128 - accuracy: 0.9420\n",
      " 8/14 [================>.............] - ETA: 0s - loss: 0.7644 - accuracy: 0.6562Epoch 33/50\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.2996 - accuracy: 0.8170\n",
      "Epoch 24/50\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 17/50\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 1.0725 - accuracy: 0.5000\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.4337 - accuracy: 0.9062Epoch 9/50\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.7027 - accuracy: 0.6786\n",
      "Epoch 22/50\n",
      "14/14 [==============================] - 0s 24ms/step - loss: 0.4438 - accuracy: 0.9018\n",
      "Epoch 39/50\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.4975 - accuracy: 0.8058\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.3728 - accuracy: 0.9375Epoch 35/50\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.5352 - accuracy: 0.8438Epoch 1/50\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.2963 - accuracy: 0.8080\n",
      "Epoch 25/50\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.2209 - accuracy: 0.9375\n",
      "Epoch 34/50\n",
      "14/14 [==============================] - 0s 18ms/step - loss: 0.4405 - accuracy: 0.9152\n",
      "Epoch 40/50\n",
      "12/14 [========================>.....] - ETA: 0s - loss: 0.6772 - accuracy: 0.6797"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:27:33.476204: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 33ms/step - loss: 9.3616e-04 - accuracy: 1.0000\n",
      "Epoch 18/50\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.6966 - accuracy: 0.6808\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 1.0774 - accuracy: 0.4955\n",
      "Epoch 23/50\n",
      "Epoch 10/50\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.4899 - accuracy: 0.8036- loss: 8.1355e-04 - accuracy: 1.0000 - ETA: 0s - loss: 0.3225 - accuracy: 0.\n",
      "12/14 [========================>.....] - ETA: 0s - loss: 0.3008 - accuracy: 0.8047Epoch 36/50\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.2999 - accuracy: 0.8058\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.0011 - accuracy: 1.0000Epoch 26/50\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.4505 - accuracy: 0.8482\n",
      "Epoch 41/50\n",
      "14/14 [==============================] - 1s 27ms/step - loss: 1.9693 - accuracy: 0.2768\n",
      "Epoch 2/50\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.2032 - accuracy: 0.9442\n",
      "Epoch 35/50\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 19/50\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.6695 - accuracy: 0.6920A: 0s - loss: 0.6695 - accuracy: 0.69\n",
      "Epoch 24/50\n",
      "14/14 [==============================] - 1s 35ms/step - loss: 1.0645 - accuracy: 0.5000\n",
      "Epoch 11/50\n",
      "14/14 [==============================] - 0s 24ms/step - loss: 0.4338 - accuracy: 0.9085- loss: 0.4250 - accuracy: 0.9219 - ETA: 0s - loss: 0.4885 - accuracy: 0.\n",
      "14/14 [==============================] - 0s 24ms/step - loss: 1.2808 - accuracy: 0.4621\n",
      "Epoch 42/50\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 0.2670 - accuracy: 0.9152Epoch 3/50\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.4828 - accuracy: 0.7991\n",
      "Epoch 37/50\n",
      "14/14 [==============================] - 1s 35ms/step - loss: 0.2779 - accuracy: 0.8438\n",
      "Epoch 27/50\n",
      " 8/14 [================>.............]14/14 [==============================] - 0s 27ms/step - loss: 0.6645 - accuracy: 0.6853\n",
      " - ETA: 0s - loss: 0.9963 - accuracy: 0.6797Epoch 25/50\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.1971 - accuracy: 0.9487\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 0.5357 - accuracy: 0.7768Epoch 36/50\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 9.1644e-04 - accuracy: 1.0000\n",
      "12/14 [========================>.....] - ETA: 0s - loss: 0.9445 - accuracy: 0.6927Epoch 20/50\n",
      "14/14 [==============================] - 0s 22ms/step - loss: 0.9150 - accuracy: 0.7009\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.5115 - accuracy: 0.7951Epoch 4/50\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 1.0702 - accuracy: 0.4911\n",
      "Epoch 12/50\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 0.4290 - accuracy: 0.8951\n",
      "Epoch 43/50\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.4837 - accuracy: 0.7991- loss: 0.2009 - accuracy: 0.9500 - ETA: 0s - loss: 0.7072 - accuracy: 0.64\n",
      "Epoch 38/50\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.2883 - accuracy: 0.8371\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.8132 - accuracy: 0.6111Epoch 28/50\n",
      "14/14 [==============================] - 0s 20ms/step - loss: 0.5115 - accuracy: 0.8371\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 1.0438 - accuracy: 0.5243Epoch 5/50\n",
      "14/14 [==============================] - 0s 22ms/step - loss: 0.9168 - accuracy: 0.5670\n",
      "Epoch 44/50\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.6835 - accuracy: 0.6875\n",
      "Epoch 26/50\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.0017 - accuracy: 1.0000 [==============>...............] - ETA: 0s - loss: 0.3815 - accuracy: 0.83\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 1.0663 - accuracy: 0.5096Epoch 21/50\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.2256 - accuracy: 0.9286\n",
      "Epoch 37/50\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 1.0684 - accuracy: 0.5067\n",
      "Epoch 13/50\n",
      "14/14 [==============================] - 0s 19ms/step - loss: 0.3404 - accuracy: 0.8527\n",
      " 4/14 [=======>......................] - ETA: 0s - loss: 0.0010 - accuracy: 1.0000Epoch 6/50\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.5996 - accuracy: 0.7946\n",
      " 5/14 [=========>....................] - ETA: 0s - loss: 1.0510 - accuracy: 0.5312Epoch 29/50\n",
      "14/14 [==============================] - 0s 24ms/step - loss: 1.0996 - accuracy: 0.4531\n",
      "Epoch 45/50\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.4586 - accuracy: 0.8147\n",
      "Epoch 39/50\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.6559 - accuracy: 0.7098\n",
      "Epoch 27/50\n",
      "14/14 [==============================] - 0s 22ms/step - loss: 0.2720 - accuracy: 0.8951- loss: 0.3880 - accuracy: 0.8542 - ETA: 0s - loss: 1.0425 - accuracy: 0.\n",
      "Epoch 7/50\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 22/50\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.2173 - accuracy: 0.9353\n",
      "Epoch 38/50\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 1.0525 - accuracy: 0.5134\n",
      "Epoch 14/50\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 1.0301 - accuracy: 0.4799\n",
      "Epoch 46/50\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.5440 - accuracy: 0.7478\n",
      "Epoch 30/50\n",
      "14/14 [==============================] - 0s 18ms/step - loss: 0.2254 - accuracy: 0.9107\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.4354 - accuracy: 0.8149Epoch 8/50\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.6584 - accuracy: 0.7143\n",
      "Epoch 28/50\n",
      "14/14 [==============================] - 1s 36ms/step - loss: 0.4453 - accuracy: 0.8147\n",
      "Epoch 40/50\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.0496 - accuracy: 0.9866\n",
      "Epoch 23/50\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.2229 - accuracy: 0.9286\n",
      "Epoch 39/50\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 1.0473 - accuracy: 0.4866\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.0128 - accuracy: 1.0000Epoch 47/50\n",
      "14/14 [==============================] - 0s 19ms/step - loss: 0.1932 - accuracy: 0.9196\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.0706 - accuracy: 0.9688Epoch 9/50\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 1.0771 - accuracy: 0.5000\n",
      "Epoch 15/50\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.3385 - accuracy: 0.8371\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 0.1912 - accuracy: 0.9330Epoch 31/50\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.6556 - accuracy: 0.7076\n",
      " 5/14 [=========>....................] - ETA: 0s - loss: 1.0453 - accuracy: 0.5312Epoch 29/50\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.4796 - accuracy: 0.7902\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 1.0196 - accuracy: 0.5433Epoch 41/50\n",
      "14/14 [==============================] - 0s 19ms/step - loss: 0.1580 - accuracy: 0.9420\n",
      "14/14 [==============================] - 0s 22ms/step - loss: 1.0277 - accuracy: 0.5357\n",
      "Epoch 10/50\n",
      "Epoch 48/50\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.0426 - accuracy: 0.9888- loss: 0.2379 - accuracy: 0.8938 - ETA: 0s - loss: 0.0503 - accuracy: 0.9858\n",
      "11/14 [======================>.......] - ETA: 0s - loss: 1.0601 - accuracy: 0.5142Epoch 24/50\n",
      "14/14 [==============================] - 0s 36ms/step - loss: 0.1813 - accuracy: 0.9509\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 0.9865 - accuracy: 0.6071Epoch 40/50\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 1.0410 - accuracy: 0.5201- loss: 0.2746 - accuracy: 0.8466 - ETA: 0s - loss: 1.0410 - accuracy: 0.52\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 0.0207 - accuracy: 1.0000Epoch 16/50\n",
      "14/14 [==============================] - 0s 20ms/step - loss: 0.1567 - accuracy: 0.9420\n",
      "Epoch 11/50\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.2926 - accuracy: 0.8393\n",
      "Epoch 32/50\n",
      "14/14 [==============================] - 0s 23ms/step - loss: 0.9102 - accuracy: 0.6429\n",
      "Epoch 49/50\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.6473 - accuracy: 0.7254\n",
      "Epoch 30/50\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.4671 - accuracy: 0.7946A: 0s - loss: 0.9465 - accuracy: 0.64\n",
      "Epoch 42/50\n",
      "14/14 [==============================] - 0s 21ms/step - loss: 0.1640 - accuracy: 0.9420- loss: 0.1672 - accuracy: 0.9423 - ETA: 0s - loss: 0.0391 - accuracy: 0.99\n",
      "Epoch 12/50\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.0393 - accuracy: 0.9911\n",
      "Epoch 25/50\n",
      "14/14 [==============================] - 0s 24ms/step - loss: 0.8595 - accuracy: 0.7031\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 1.0785 - accuracy: 0.4978\n",
      "Epoch 50/50\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.1769 - accuracy: 0.9487\n",
      "Epoch 17/50\n",
      "Epoch 41/50\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.2807 - accuracy: 0.8817\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.8125 - accuracy: 0.6683Epoch 33/50\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.8251 - accuracy: 0.6674\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.3233 - accuracy: 0.7812Epoch 31/50\n",
      "11/14 [======================>.......] - ETA: 0s - loss: 0.4318 - accuracy: 0.8068 - 0s 20ms/step - loss: 0.1366 - accuracy: 0.9509\n",
      " 5/14 [=========>....................] - ETA: 0s - loss: 1.0213 - accuracy: 0.4938Epoch 13/50\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.4366 - accuracy: 0.8080A: 0s - loss: 0.1852 - accuracy: 0.95\n",
      " 5/14 [=========>....................] - ETA: 0s - loss: 0.7112 - accuracy: 0.6500Epoch 43/50\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 0.8383 - accuracy: 0.7054\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.0251 - accuracy: 0.9955\n",
      "Epoch 26/50\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 1.0422 - accuracy: 0.5179\n",
      " 4/14 [=======>......................] - ETA: 0s - loss: 0.0207 - accuracy: 0.9922Epoch 18/50\n",
      "14/14 [==============================] - 0s 36ms/step - loss: 0.1867 - accuracy: 0.9464\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.8409 - accuracy: 0.5938Epoch 42/50\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.1260 - accuracy: 0.9509\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 0.4375 - accuracy: 0.8125Epoch 14/50\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.7586 - accuracy: 0.6674\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.0434 - accuracy: 1.0000Epoch 32/50\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.2846 - accuracy: 0.8616\n",
      "Epoch 34/50\n",
      "12/14 [========================>.....] - ETA: 0s - loss: 0.0108 - accuracy: 0.9948 - ETA: 0s - loss: 0.0091 - accuracy: 0.99"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:27:37.709593: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 1s 37ms/step - loss: 0.4513 - accuracy: 0.7991\n",
      "Epoch 44/50\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.0095 - accuracy: 0.9955\n",
      "Epoch 27/50\n",
      "14/14 [==============================] - 0s 24ms/step - loss: 0.0867 - accuracy: 0.9799A: 0s - loss: 0.6999 - accuracy: 0.69\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.7765 - accuracy: 0.7292Epoch 15/50\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.8039 - accuracy: 0.7143\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 1.0765 - accuracy: 0.5000\n",
      "Epoch 19/50\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.2743 - accuracy: 0.8415\n",
      "Epoch 35/50\n",
      "14/14 [==============================] - 1s 36ms/step - loss: 0.1744 - accuracy: 0.9509\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.7200 - accuracy: 0.6875\n",
      "Epoch 43/50\n",
      "Epoch 33/50\n",
      " 4/14 [=======>......................] - ETA: 0s - loss: 0.2990 - accuracy: 0.8047[CV 4/5] END ...epochs=50, layers=2, neurons=20;, score=0.714 total time=  19.1s\n",
      "14/14 [==============================] - 0s 21ms/step - loss: 0.1194 - accuracy: 0.9643\n",
      "Epoch 16/50\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.4782 - accuracy: 0.7969\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.0127 - accuracy: 0.9955\n",
      " 6/14 [===========>..................]Epoch 45/50\n",
      " - ETA: 0s - loss: 0.2156 - accuracy: 0.9323Epoch 28/50\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.2864 - accuracy: 0.8214- loss: 0.2864 - accuracy: 0.8214 - ETA: 0s - loss: 0.1408 - accuracy: 0.95\n",
      "Epoch 36/50\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 1.0634 - accuracy: 0.5045\n",
      "Epoch 20/50\n",
      "14/14 [==============================] - 0s 22ms/step - loss: 0.1218 - accuracy: 0.9643\n",
      "Epoch 17/50\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.8174 - accuracy: 0.6629\n",
      "Epoch 34/50\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.1842 - accuracy: 0.9464A: 0s - loss: 0.0120 - accuracy: 0.99\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 0.2754 - accuracy: 0.8170Epoch 44/50\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.4436 - accuracy: 0.7969\n",
      "Epoch 46/50\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.0090 - accuracy: 0.9955\n",
      "Epoch 29/50\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.2563 - accuracy: 0.8460\n",
      "Epoch 37/50\n",
      "14/14 [==============================] - 0s 23ms/step - loss: 0.0747 - accuracy: 0.9844\n",
      "11/14 [======================>.......] - ETA: 0s - loss: 1.0694 - accuracy: 0.4886Epoch 18/50\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 1.0704 - accuracy: 0.5000- loss: 0.7289 - accuracy: 0.6719 - ETA: 0s - loss: 0.0064 - accuracy: 1.00\n",
      " 5/14 [=========>....................] - ETA: 0s - loss: 0.0060 - accuracy: 1.0000Epoch 21/50\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.7242 - accuracy: 0.6808\n",
      "Epoch 35/50\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.1782 - accuracy: 0.9464A: 0s - loss: 0.1848 - accuracy: 0.\n",
      "Epoch 45/50\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.3103 - accuracy: 0.8077Epoch 1/50\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.0037 - accuracy: 1.0000\n",
      " 9/14 [==================>...........] - 0s 29ms/step - loss: 0.3083 - accuracy: 0.8103\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.1382 - accuracy: 0.9688 - ETA: 0s - loss: 0.7724 - accuracy: 0.6840Epoch 30/50\n",
      "Epoch 38/50\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.4383 - accuracy: 0.8058\n",
      "Epoch 47/50\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.0744 - accuracy: 0.9777\n",
      "Epoch 19/50\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 1.0249 - accuracy: 0.5246- loss: 0.4890 - accuracy: 0.8125 - ETA: 0s - loss: 0.1083 - accuracy: 0.97\n",
      "Epoch 22/50\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.7583 - accuracy: 0.6853\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.9419 - accuracy: 0.5000Epoch 36/50\n",
      "14/14 [==============================] - 0s 18ms/step - loss: 0.0876 - accuracy: 0.9754\n",
      "Epoch 20/50\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.1560 - accuracy: 0.9576\n",
      "Epoch 46/50\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.2788 - accuracy: 0.8504\n",
      "Epoch 39/50\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.4448 - accuracy: 0.7969\n",
      "Epoch 31/50\n",
      "Epoch 48/50\n",
      "14/14 [==============================] - 0s 23ms/step - loss: 0.0617 - accuracy: 0.9754- loss: 0.4220 - accuracy: 0.8021 - ETA: 0s - loss: 0.7596 - accuracy: 0.67\n",
      "Epoch 21/50\n",
      " 6/14 [===========>..................] - ETA: 0s - loss: 0.2592 - accuracy: 0.8438"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:27:39.756729: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 32ms/step - loss: 0.7525 - accuracy: 0.6719\n",
      "Epoch 37/50\n",
      "14/14 [==============================] - 1s 36ms/step - loss: 1.0521 - accuracy: 0.5112\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.7674 - accuracy: 0.6875Epoch 23/50\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.1623 - accuracy: 0.9531\n",
      "12/14 [========================>.....] - ETA: 0s - loss: 0.2724 - accuracy: 0.8385Epoch 47/50\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.2572 - accuracy: 0.8504\n",
      "11/14 [======================>.......] - ETA: 0s - loss: 0.4668 - accuracy: 0.7926Epoch 40/50\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 7.0482e-04 - accuracy: 1.0000\n",
      "Epoch 32/50\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.1023 - accuracy: 0.9710\n",
      "Epoch 22/50\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.4623 - accuracy: 0.7991- ETA: 0s - loss: 0.9954 - accuracy: 0.53\n",
      "Epoch 49/50\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.7340 - accuracy: 0.6719\n",
      "Epoch 38/50\n",
      " 9/14 [==================>...........]14/14 [==============================] - 1s 33ms/step - loss: 1.6898 - accuracy: 0.2969\n",
      " - ETA: 0s - loss: 0.0567 - accuracy: 0.9826Epoch 2/50\n",
      "14/14 [==============================] - 1s 36ms/step - loss: 1.0349 - accuracy: 0.5179\n",
      "Epoch 24/50\n",
      "14/14 [==============================] - 0s 22ms/step - loss: 0.0520 - accuracy: 0.9866\n",
      "Epoch 23/50\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.2748 - accuracy: 0.8281A: 0s - loss: 3.4144e-04 - accuracy: 1.00\n",
      "Epoch 41/50\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.1427 - accuracy: 0.9621\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 0.0440 - accuracy: 0.9792Epoch 48/50\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 3.4469e-04 - accuracy: 1.0000\n",
      " 4/14 [=======>......................] - ETA: 0s - loss: 0.2663 - accuracy: 0.8125Epoch 33/50\n",
      "14/14 [==============================] - 0s 36ms/step - loss: 0.4277 - accuracy: 0.8103\n",
      "Epoch 50/50\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.6637 - accuracy: 0.7076\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 4.0902e-04 - accuracy: 1.0000Epoch 39/50\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 1.2989 - accuracy: 0.4531A: 0s - loss: 1.2989 - accuracy: 0.45\n",
      "Epoch 3/50\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0420 - accuracy: 0.9866\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 2.8993e-04 - accuracy: 1.0000Epoch 24/50\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.2473 - accuracy: 0.8393\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 1.0542 - accuracy: 0.5067\n",
      "Epoch 42/50\n",
      "Epoch 25/50\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 2.5071e-04 - accuracy: 1.0000ss: 0.7796 - accuracy: 0.6534 - ETA: 0s - loss: 1.0212 - accuracy: 0.57\n",
      " 5/14 [=========>....................] - ETA: 0s - loss: 0.2500 - accuracy: 0.8500Epoch 34/50\n",
      "14/14 [==============================] - 1s 43ms/step - loss: 0.1719 - accuracy: 0.9464\n",
      " 5/14 [=========>....................] - ETA: 0s - loss: 1.0122 - accuracy: 0.5688Epoch 49/50\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.9248 - accuracy: 0.6607\n",
      "Epoch 4/50\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.7499 - accuracy: 0.6674\n",
      "14/14 [==============================] - 0s 24ms/step - loss: 0.0826 - accuracy: 0.9710\n",
      "Epoch 40/50\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.8889 - accuracy: 0.5625Epoch 25/50\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.4504 - accuracy: 0.8013A: 0s - loss: 0.4443 - accuracy: 0.80\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.2703 - accuracy: 0.8371\n",
      "Epoch 43/50\n",
      "14/14 [==============================] - 1s 36ms/step - loss: 1.0242 - accuracy: 0.5246\n",
      "Epoch 26/50\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.5797 - accuracy: 0.7902- loss: 0.9981 - accuracy: 0.5625 - ETA: 0s - loss: 1.5185e-04 - accuracy: 1.00\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 1.4138e-04 - accuracy: 1.0000Epoch 5/50\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.0804 - accuracy: 0.9710\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.5415 - accuracy: 0.7812Epoch 26/50\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 1.6244e-04 - accuracy: 1.0000\n",
      "Epoch 35/50\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.1694 - accuracy: 0.9464A: 0s - loss: 0.6894 - accuracy: 0.69\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.6944 - accuracy: 0.6920\n",
      "Epoch 50/50\n",
      "Epoch 41/50\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.2660 - accuracy: 0.833800\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:27:41.542788: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 58ms/step - loss: 0.2853 - accuracy: 0.9196A: 0s - loss: 0.1821 - accuracy: 0.92\n",
      " - 0s 27ms/step - loss: 0.2491 - accuracy: 0.8460\n",
      "[CV 2/5] END ...epochs=50, layers=2, neurons=20;, score=0.920 total time=  27.7s\n",
      "Epoch 44/50\n",
      "14/14 [==============================] - 0s 23ms/step - loss: 0.0805 - accuracy: 0.9665\n",
      "Epoch 27/50\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 1.0566 - accuracy: 0.5045A: 0s - loss: 1.0566 - accuracy: 0.50\n",
      "Epoch 27/50\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.3321 - accuracy: 0.8929A: 0s - loss: 0.2909 - accuracy: 0.81\n",
      "Epoch 6/50\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 1.1881 - accuracy: 0.4271 - 0s 30ms/step - loss: 0.7077 - accuracy: 0.6875\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 3.8347e-04 - accuracy: 1.0000\n",
      "Epoch 42/50\n",
      "Epoch 36/50\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.1786 - accuracy: 0.9420- loss: 0.2408 - accuracy: 0.9750 - ETA: 0s - loss: 0.6852 - accuracy: 0.7188\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.2838 - accuracy: 0.8326\n",
      "14/14 [==============================] - 0s 23ms/step - loss: 0.0661 - accuracy: 0.9777\n",
      "Epoch 45/50\n",
      "Epoch 28/50\n",
      "14/14 [==============================] - 0s 23ms/step - loss: 0.2399 - accuracy: 0.9509\n",
      "Epoch 7/50\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 1.0557 - accuracy: 0.5045\n",
      "Epoch 28/50\n",
      "14/14 [==============================] - ETA: 0s - loss: 1.1045 - accuracy: 0.5000 - 0s 28ms/step - loss: 3.6661e-04 - accuracy: 1.0000\n",
      "Epoch 37/50\n",
      " 8/14 [================>.............] - ETA: 0s - loss: 0.2545 - accuracy: 0.8359"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:27:42.476511: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 34ms/step - loss: 0.6901 - accuracy: 0.6920\n",
      "Epoch 43/50\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0602 - accuracy: 0.9844- ETA: 0s - loss: 0.0162 - accuracy: 1.00\n",
      "12/14 [========================>.....] - ETA: 0s - loss: 0.1939 - accuracy: 0.9427Epoch 29/50\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.2662 - accuracy: 0.8415\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.1895 - accuracy: 0.9464- loss: 1.6532e-04 - accuracy: 1.0000 - ETA: 0s - loss: 0.1895 - accuracy: 0.94\n",
      "Epoch 46/50\n",
      "Epoch 8/50\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.0231 - accuracy: 1.0000\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 1.0720 - accuracy: 0.4955- ETA: 0s - loss: 1.0720 - accuracy: 0.49\n",
      "Epoch 29/50\n",
      " 4/14 [=======>......................] - ETA: 0s - loss: 0.2329 - accuracy: 0.8672[CV 3/5] END ...epochs=50, layers=2, neurons=20;, score=1.000 total time=  28.7s\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 2.4630e-04 - accuracy: 1.0000ss: 2.4630e-04 - accuracy: 1.0000 - ETA: 0s - loss: 0.0839 - accuracy: 0.97: 0.\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 0.2266 - accuracy: 0.8705Epoch 38/50\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.7191 - accuracy: 0.6763\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.1790 - accuracy: 0.9500Epoch 44/50\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0910 - accuracy: 0.9688\n",
      "Epoch 30/50\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.1650 - accuracy: 0.9487\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 2.3622e-04 - accuracy: 1.0000Epoch 9/50\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.2372 - accuracy: 0.8527\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.1279 - accuracy: 0.9688Epoch 47/50\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 1.0472 - accuracy: 0.5048Epoch 1/50 - loss: 2.2276e-04 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 1.0458 - accuracy: 0.5089\n",
      "Epoch 30/50\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 2.3549e-04 - accuracy: 1.0000\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.1374 - accuracy: 0.9618Epoch 39/50\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.0767 - accuracy: 0.9799\n",
      " 5/14 [=========>....................] - ETA: 0s - loss: 1.0789 - accuracy: 0.5312Epoch 31/50\n",
      "14/14 [==============================] - 1s 36ms/step - loss: 0.7391 - accuracy: 0.6652\n",
      "Epoch 45/50\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.1321 - accuracy: 0.9665\n",
      "Epoch 10/50\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.2698 - accuracy: 0.8415\n",
      " 6/14 [===========>..................] - ETA: 0s - loss: 0.7359 - accuracy: 0.6667Epoch 48/50\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 1.0370 - accuracy: 0.5156\n",
      "Epoch 31/50\n",
      "14/14 [==============================] - 0s 24ms/step - loss: 0.0798 - accuracy: 0.9688\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.1077 - accuracy: 0.9625Epoch 32/50\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.7323 - accuracy: 0.6719A: 0s - loss: 0.9729 - accuracy: 0.5312\n",
      "Epoch 46/50\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 1.6189e-04 - accuracy: 1.0000s - loss: 1.6593 - accuracy: 0.40\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.7548 - accuracy: 0.7188Epoch 40/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:27:43.760554: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 27ms/step - loss: 0.1057 - accuracy: 0.9688\n",
      "Epoch 11/50\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.2307 - accuracy: 0.8728- loss: 1.0501 - accuracy: 0.4883 - ETA: 0s - loss: 0.2274 - accuracy: 0.87\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.2265 - accuracy: 0.9281Epoch 49/50\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.2683 - accuracy: 0.9196\n",
      "Epoch 33/50\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 1.0574 - accuracy: 0.5045\n",
      "Epoch 32/50\n",
      "11/14 [======================>.......] - ETA: 0s - loss: 1.7253e-04 - accuracy: 1.0000Epoch 1/50\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.7126 - accuracy: 0.6897\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 0.2607 - accuracy: 0.8616Epoch 47/50\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.0862 - accuracy: 0.9754\n",
      "Epoch 12/50\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 3.5435e-04 - accuracy: 1.0000s - loss: 0.1971 - accuracy: 0.91\n",
      "Epoch 41/50\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.2622 - accuracy: 0.8482A: 0s - loss: 2.2424 - accuracy: 0.26\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 2.0510e-04 - accuracy: 1.0000Epoch 50/50\n",
      "14/14 [==============================] - 1s 51ms/step - loss: 2.1702 - accuracy: 0.2835\n",
      "Epoch 2/50\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.2333 - accuracy: 0.9040\n",
      " 5/14 [=========>....................] - ETA: 0s - loss: 0.2384 - accuracy: 0.8562Epoch 34/50\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 1.0438 - accuracy: 0.5089\n",
      "Epoch 33/50\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.7194 - accuracy: 0.6808\n",
      "Epoch 48/50\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.0761 - accuracy: 0.9777\n",
      "Epoch 13/50\n",
      "14/14 [==============================] - 0s 36ms/step - loss: 1.8643e-04 - accuracy: 1.0000================>...........] - ETA: 0s - loss: 0.2528 - accuracy: 0.84\n",
      "Epoch 42/50\n",
      " 5/14 [=========>....................] - ETA: 0s - loss: 0.8194 - accuracy: 0.6625"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:27:44.865627: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 32ms/step - loss: 0.2570 - accuracy: 0.8549\n",
      "14/14 [==============================] - 0s 23ms/step - loss: 0.2113 - accuracy: 0.9420\n",
      "Epoch 35/50\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 1.3301 - accuracy: 0.4531\n",
      "Epoch 3/50\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.6720 - accuracy: 0.7321\n",
      " 5/14 [=========>....................] - ETA: 0s - loss: 3.3695 - accuracy: 0.2188Epoch 49/50\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 1.0560 - accuracy: 0.5045\n",
      "Epoch 34/50\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0521 - accuracy: 0.9866\n",
      "Epoch 14/50\n",
      "14/14 [==============================] - 1s 35ms/step - loss: 1.8913e-04 - accuracy: 1.0000ss: 0.7796 - accuracy: 0.6250 - ETA: 0s - loss: 1.2374 - accuracy: 0.46\n",
      "Epoch 43/50\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.1155 - accuracy: 0.9665\n",
      "Epoch 36/50\n",
      " 3/14 [=====>........................]14/14 [==============================] - ETA: 0s - loss: 0.0774 - accuracy: 0.9583 - 1s 40ms/step - loss: 2.3455 - accuracy: 0.3170\n",
      "Epoch 2/50\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 1.0347 - accuracy: 0.5580\n",
      "Epoch 4/50\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 1.0816 - accuracy: 0.4911A: 0s - loss: 0.0631 - accuracy: 0.97\n",
      "Epoch 35/50\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.0805 - accuracy: 0.9732\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 1.4220 - accuracy: 0.4062Epoch 15/50\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.6205 - accuracy: 0.7924\n",
      "Epoch 50/50\n",
      "12/14 [========================>.....] - ETA: 0s - loss: 1.2239e-04 - accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:27:45.632105: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 60ms/step - loss: 0.1744 - accuracy: 0.8393\n",
      " 4/14 [=======>......................] - ETA: 0s - loss: 0.6252 - accuracy: 0.8281[CV 5/5] END ...epochs=50, layers=2, neurons=20;, score=0.839 total time=  23.2s\n",
      "14/14 [==============================] 8/14 [================>.............] - ETA: 0s - loss: 0.7817 - accuracy: 0.6875 - 0s 32ms/step - loss: 1.4468e-04 - accuracy: 1.0000\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 1.3236 - accuracy: 0.4938Epoch 44/50\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.0676 - accuracy: 0.9732\n",
      "Epoch 37/50\n",
      "14/14 [==============================] - 0s 36ms/step - loss: 1.2812 - accuracy: 0.4933- loss: 1.1266 - accuracy: 0.4643 - ETA: 0s - loss: 0.6044 - accuracy: 0.\n",
      "Epoch 3/50\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.0710 - accuracy: 0.9777\n",
      "Epoch 16/50\n",
      "14/14 [==============================] - 0s 37ms/step - loss: 0.7058 - accuracy: 0.7098\n",
      "Epoch 5/50\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.5800 - accuracy: 0.8348A: 0s - loss: 1.0398 - accuracy: 0.60\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 1.0551 - accuracy: 0.5045\n",
      "Epoch 36/50\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.0828 - accuracy: 0.9754A: 0s - loss: 0.1014 - accuracy: 0.96TA: 0s - loss: 1.0026 - accuracy: 0.53\n",
      "Epoch 38/50\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 1.7882e-04 - accuracy: 1.0000\n",
      "Epoch 45/50\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.8353 - accuracy: 0.6853\n",
      "Epoch 4/50\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.0768 - accuracy: 0.9754\n",
      "Epoch 17/50\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.5645 - accuracy: 0.7634\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.7396 - accuracy: 0.7812Epoch 6/50\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.5959 - accuracy: 0.656200"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:27:46.574659: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 30ms/step - loss: 1.0327 - accuracy: 0.5134\n",
      "Epoch 37/50\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 0.0399 - accuracy: 0.9911\n",
      "Epoch 39/50\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.5155 - accuracy: 0.8393\n",
      "[CV 1/5] END ...epochs=50, layers=2, neurons=40;, score=0.839 total time=  23.4s\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 1.4131e-04 - accuracy: 1.0000\n",
      " 6/14 [===========>..................] - ETA: 0s - loss: 1.0399 - accuracy: 0.5156Epoch 46/50\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.5176 - accuracy: 0.8326\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.3917 - accuracy: 0.8259\n",
      "Epoch 5/50\n",
      "Epoch 7/50\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.0351 - accuracy: 0.9933\n",
      "11/14 [======================>.......] - ETA: 0s - loss: 1.0495 - accuracy: 0.5028Epoch 18/50\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 0.4399 - accuracy: 0.8958Epoch 1/50\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 1.0409 - accuracy: 0.5089A: 0s - loss: 0.0572 - accuracy: 0.99\n",
      "Epoch 38/50\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.0521 - accuracy: 0.9978\n",
      " 6/14 [===========>..................] - ETA: 0s - loss: 0.3645 - accuracy: 0.8125Epoch 40/50\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 1.6901e-04 - accuracy: 1.0000\n",
      "Epoch 47/50\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.3142 - accuracy: 0.8571A: 0s - loss: 1.0265 - accuracy: 0.52\n",
      "Epoch 8/50\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.0416 - accuracy: 0.9911\n",
      "Epoch 19/50\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.3396 - accuracy: 0.9063\n",
      "Epoch 6/50\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 1.0226 - accuracy: 0.5179\n",
      "Epoch 39/50\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0947 - accuracy: 0.9688\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 9.1744e-05 - accuracy: 1.0000Epoch 41/50\n",
      "14/14 [==============================] - 0s 24ms/step - loss: 1.4187e-04 - accuracy: 1.0000\n",
      "Epoch 48/50\n",
      "14/14 [==============================] - 0s 23ms/step - loss: 0.0444 - accuracy: 0.9866\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 1.0375 - accuracy: 0.5312Epoch 20/50\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.2965 - accuracy: 0.8750\n",
      "Epoch 9/50\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.2242 - accuracy: 0.9219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:27:47.868564: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/50\n",
      "14/14 [==============================] - 0s 24ms/step - loss: 0.0693 - accuracy: 0.9754\n",
      "Epoch 42/50\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 1.0129 - accuracy: 0.5223\n",
      "Epoch 40/50\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 1.8203e-04 - accuracy: 1.0000\n",
      "Epoch 49/50\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.0201 - accuracy: 0.9955\n",
      "12/14 [========================>.....] - ETA: 0s - loss: 0.2397 - accuracy: 0.9089Epoch 21/50\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.1451 - accuracy: 0.9594Epoch 1/50\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.2234 - accuracy: 0.9174\n",
      "12/14 [========================>.....] - ETA: 0s - loss: 0.1386 - accuracy: 0.9635Epoch 10/50\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.1358 - accuracy: 0.9643\n",
      "11/14 [======================>.......] - ETA: 0s - loss: 1.0480 - accuracy: 0.5085Epoch 8/50\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.0547 - accuracy: 0.9844\n",
      "Epoch 43/50\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 1.0616 - accuracy: 0.4978\n",
      "Epoch 41/50\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 2.0614 - accuracy: 0.3348\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 1.0391 - accuracy: 0.5000Epoch 2/50\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 2.2200e-04 - accuracy: 1.0000\n",
      "Epoch 50/50\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.0137 - accuracy: 1.0000\n",
      "Epoch 22/50\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.1943 - accuracy: 0.9219A: 0s - loss: 0.0880 - accuracy: 0.96\n",
      "Epoch 11/50\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.1215 - accuracy: 0.9621\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 1.1722 - accuracy: 0.5590Epoch 9/50\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.0491 - accuracy: 0.9888\n",
      "Epoch 44/50\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 1.0250 - accuracy: 0.5156A: 0s - loss: 1.1204 - accuracy: 0.57\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 0.0965 - accuracy: 0.9688Epoch 42/50\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 1.0627 - accuracy: 0.6004\n",
      "Epoch 3/50\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.0365 - accuracy: 0.9844A: 0s - loss: 1.0530e-04 - accuracy: 1.00\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 0.0770 - accuracy: 0.9821Epoch 23/50\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 1.2933e-04 - accuracy: 1.0000\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.1792 - accuracy: 0.9219\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.0759 - accuracy: 0.9760Epoch 12/50\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.0747 - accuracy: 0.9844\n",
      "Epoch 10/50\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.0791 - accuracy: 0.9754\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.0868 - accuracy: 0.9688Epoch 45/50\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.5417 - accuracy: 0.8638\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 0.0879 - accuracy: 0.9792Epoch 4/50\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 1.0154 - accuracy: 0.5223\n",
      "Epoch 43/50\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0340 - accuracy: 0.9866\n",
      "Epoch 24/50\n",
      " 8/14 [================>.............] - ETA: 0s - loss: 0.0767 - accuracy: 0.9805"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:27:49.454060: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-01-09 14:27:49.477738: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 31ms/step - loss: 0.0052 - accuracy: 1.0000\n",
      " 8/14 [================>.............] - ETA: 0s - loss: 0.2202 - accuracy: 0.9570[CV 2/5] END ...epochs=50, layers=2, neurons=40;, score=1.000 total time=  24.7s\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.0617 - accuracy: 0.9821\n",
      "Epoch 11/50\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.0735 - accuracy: 0.9777\n",
      "Epoch 46/50\n",
      "14/14 [==============================] - 1s 36ms/step - loss: 0.1726 - accuracy: 0.9129\n",
      "Epoch 13/50\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 1.0513 - accuracy: 0.5022\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.1936 - accuracy: 0.9567Epoch 44/50\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.0132 - accuracy: 0.9978\n",
      "14/14 [==============================]Epoch 25/50\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.1887 - accuracy: 0.9554\n",
      "Epoch 5/50\n",
      "14/14 [==============================] - 2s 38ms/step - loss: 1.8778 - accuracy: 0.3371- loss: 0.0549 - accuracy: 0.9832 - ETA: 0s - loss: 1.0565 - accuracy: 0.50\n",
      "Epoch 2/50\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.0581 - accuracy: 0.9821\n",
      "Epoch 47/50\n",
      "14/14 [==============================] - 1s 36ms/step - loss: 0.0601 - accuracy: 0.9821\n",
      " 3/14 [=====>........................]Epoch 12/50\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.1452 - accuracy: 0.9241\n",
      "11/14 [======================>.......] - ETA: 0s - loss: 0.0931 - accuracy: 0.9773Epoch 14/50\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.0342 - accuracy: 0.9821\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 1.0354 - accuracy: 0.5156\n",
      "Epoch 26/50\n",
      "Epoch 45/50\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.0832 - accuracy: 0.9821\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 1.2578 - accuracy: 0.5312Epoch 6/50\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.0402 - accuracy: 0.9844\n",
      "Epoch 48/50\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 1.1719 - accuracy: 0.5848\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.0279 - accuracy: 0.9896Epoch 3/50\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.0470 - accuracy: 0.9888\n",
      "12/14 [========================>.....] - ETA: 0s - loss: 0.1341 - accuracy: 0.9245Epoch 13/50\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.1363 - accuracy: 0.9219\n",
      "Epoch 15/50\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.0225 - accuracy: 0.9933\n",
      "Epoch 27/50\n",
      "14/14 [============================= - 0s 28ms/step - loss: 0.0498 - accuracy: 0.9866\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 1.1185 - accuracy: 0.4821\n",
      " 8/14 [================>.............] - ETA: 0s - loss: 0.0523 - accuracy: 0.9805Epoch 7/50\n",
      "Epoch 46/50\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0543 - accuracy: 0.9866\n",
      " 6/14 [===========>..................] - ETA: 0s - loss: 0.0402 - accuracy: 1.0000Epoch 49/50\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.7970 - accuracy: 0.7188\n",
      "12/14 [========================>.....] - ETA: 0s - loss: 0.0210 - accuracy: 0.9974Epoch 4/50\n",
      " - 0s 28ms/step - loss: 0.1595 - accuracy: 0.9085- loss: 0.0220 - accuracy: 0.9987\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.0220 - accuracy: 0.9955\n",
      " 5/14 [=========>....................] - ETA: 0s - loss: 0.0467 - accuracy: 0.9875Epoch 14/50\n",
      "Epoch 16/50\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.0214 - accuracy: 0.9933- loss: 0.1400 - accuracy: 0.9375 - ETA: 0s - loss: 0.0166 - accuracy: 1.00\n",
      "Epoch 28/50\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 1.8365 - accuracy: 0.2567\n",
      "Epoch 47/50\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.0274 - accuracy: 1.0000A: 0s - loss: 0.0274 - accuracy: 1.00\n",
      "Epoch 8/50\n",
      " 5/14 [=========>....................] - ETA: 0s - loss: 1.7070 - accuracy: 0.1813Epoch 1/50s: 0.0107 - accuracy: 1.0000 - ETA: 0s - loss: 0.1221 - accuracy: 0.94\n",
      " 7/14 [==============>...............] - 0s 36ms/step - loss: 0.0514 - accuracy: 0.9844- loss: 0.0089 - accuracy: 1.0000 - ETA: 0s - loss: 0.0105 - accuracy: 1.00\n",
      " - ETA: 0s - loss: 1.7037 - accuracy: 0.1652Epoch 50/50\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.1309 - accuracy: 0.9420\n",
      "12/14 [========================>.....] - ETA: 0s - loss: 0.0262 - accuracy: 0.9948Epoch 17/50\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.5698 - accuracy: 0.8237\n",
      "Epoch 5/50\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.0244 - accuracy: 0.9955\n",
      "Epoch 15/50\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.0177 - accuracy: 0.9955A: 0s - loss: 1.7092 - accuracy: 0.1731\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 1.7093 - accuracy: 0.1786\n",
      "Epoch 29/50\n",
      "Epoch 48/50\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0104 - accuracy: 1.0000\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.0033 - accuracy: 1.0000Epoch 9/50\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.0566 - accuracy: 0.9866A: 0s - loss: 1.7149 - accuracy: 0.17\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.1294 - accuracy: 0.9375\n",
      "Epoch 18/50\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.2935 - accuracy: 0.9129\n",
      "Epoch 6/50\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.0346 - accuracy: 0.9933\n",
      "Epoch 16/50\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.0253 - accuracy: 0.9933\n",
      "Epoch 30/50\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.0162 - accuracy: 0.9955\n",
      " 1/14 [=>............................]Epoch 10/50\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 1.6978 - accuracy: 0.1786\n",
      "Epoch 49/50\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.0341 - accuracy: 0.9888\n",
      "11/14 [======================>.......] - ETA: 0s - loss: 0.0239 - accuracy: 0.9915Epoch 17/50\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.1789 - accuracy: 0.9442\n",
      "Epoch 7/50\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.1099 - accuracy: 0.9598\n",
      "Epoch 19/50\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.0249 - accuracy: 0.9911\n",
      "Epoch 31/50\n",
      "14/14 [==============================] - 0s 36ms/step - loss: 0.0285 - accuracy: 0.9933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:27:52.636012: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-01-09 14:27:52.638359: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/14 [=>............................] - ETA: 0s - loss: 0.0466 - accuracy: 0.9688Epoch 11/50\n",
      "14/14 [==============================] - 1s 36ms/step - loss: 1.6855 - accuracy: 0.1786\n",
      "Epoch 50/50\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.0132 - accuracy: 0.9911\n",
      " 5/14 [=========>....................] - ETA: 0s - loss: 0.0914 - accuracy: 0.9625[CV 4/5] END ...epochs=50, layers=2, neurons=40;, score=0.991 total time=  19.9s\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.0978 - accuracy: 0.9754==========>...............] - ETA: 0s - loss: 0.0952 - accuracy: 0.9821 - ETA: 0s - loss: 1.6600 - accuracy: 0.1979 - ETA: 0s - loss: 0.0302 - accuracy: 1.\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0285 - accuracy: 0.9866Epoch 8/50\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0285 - accuracy: 0.9866\n",
      "Epoch 32/50\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.0151 - accuracy: 0.9978\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 0.0209 - accuracy: 0.9896Epoch 12/50\n",
      "14/14 [==============================]14/14 [==============================] - 1s 45ms/step - loss: 0.0283 - accuracy: 0.9933\n",
      " - 1s 39ms/step - loss: 0.1223 - accuracy: 0.9643\n",
      "Epoch 18/50\n",
      "Epoch 20/50\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 1.6749 - accuracy: 0.1786\n",
      "14/14 [==============================] - 2s 41ms/step - loss: 1.8293 - accuracy: 0.3058A: 0s - loss: 1.8603 - accuracy: 0.29\n",
      "Epoch 2/50\n",
      "14/14 [==============================] - 0s 36ms/step - loss: 0.0248 - accuracy: 0.9866A: 0s - loss: 0.1199 - accuracy: 0.\n",
      "Epoch 33/50\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.1079 - accuracy: 0.9688\n",
      "Epoch 9/50\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.0068 - accuracy: 1.0000\n",
      "Epoch 13/50\n",
      "14/14 [==============================] - 1s 36ms/step - loss: 0.1258 - accuracy: 0.9598\n",
      "Epoch 21/50\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.0220 - accuracy: 0.9933\n",
      " 4/14 [=======>......................] - ETA: 0s - loss: 0.1009 - accuracy: 0.9688Epoch 19/50\n",
      " - ETA: 0s - loss: 0.0389 - accuracy: 1.000014/14 [==============================] - 0s 36ms/step - loss: 1.2148 - accuracy: 0.4866\n",
      "Epoch 3/50\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.1223 - accuracy: 0.9549 - ETA: 0s - loss: 0.0979 - accuracy: 0.9563"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:27:53.802922: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 26ms/step - loss: 0.0947 - accuracy: 0.9643A: 0s - loss: 0.0255 - accuracy: 0.99\n",
      "Epoch 10/50\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 1.6385 - accuracy: 0.1964\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.0671 - accuracy: 1.0000[CV 3/5] END ...epochs=50, layers=2, neurons=40;, score=0.196 total time=  25.5s\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.0235 - accuracy: 0.9978\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.0246 - accuracy: 1.0000Epoch 34/50\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.0101 - accuracy: 0.9955\n",
      "11/14 [======================>.......] - ETA: 0s - loss: 0.0217 - accuracy: 1.0000Epoch 14/50\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.1281 - accuracy: 0.9531\n",
      "Epoch 22/50\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.1603 - accuracy: 0.9688Epoch 1/50\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.0183 - accuracy: 1.0000\n",
      "Epoch 20/50\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.6397 - accuracy: 0.8281\n",
      "Epoch 4/50\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.0800 - accuracy: 0.9643\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0148 - accuracy: 0.9955\n",
      "Epoch 35/50\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 0.0125 - accuracy: 0.9955Epoch 11/50\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.1761 - accuracy: 0.9464\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.0074 - accuracy: 1.0000\n",
      "Epoch 23/50\n",
      "Epoch 15/50\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.3752 - accuracy: 0.9062"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:27:54.527504: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 32ms/step - loss: 0.0153 - accuracy: 0.9933\n",
      "Epoch 21/50\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.3199 - accuracy: 0.9241\n",
      "Epoch 5/50\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.0398 - accuracy: 0.9888\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 0.2100 - accuracy: 0.9375Epoch 36/50\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0720 - accuracy: 0.9777\n",
      " 5/14 [=========>....................] - ETA: 0s - loss: 0.0073 - accuracy: 1.0000Epoch 12/50\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0038 - accuracy: 1.0000\n",
      "Epoch 16/50\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.1164 - accuracy: 0.9643\n",
      "Epoch 24/50\n",
      "14/14 [==============================] 9/14 [==================>...........] - 0s 33ms/step - loss: 0.0135 - accuracy: 0.9955\n",
      " - ETA: 0s - loss: 0.0773 - accuracy: 0.9931Epoch 22/50\n",
      "14/14 [==============================] - 1s 36ms/step - loss: 1.5346 - accuracy: 0.3304\n",
      " 5/14 [=========>....................] - ETA: 0s - loss: 0.0062 - accuracy: 1.0000 - ETA: 0s - loss: 0.0729 - accuracy: 0.9938Epoch 2/50\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.1357 - accuracy: 0.9732\n",
      "Epoch 6/50\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.0794 - accuracy: 0.9904Epoch 1/50\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.0290 - accuracy: 0.9866\n",
      "Epoch 37/50\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.0784 - accuracy: 0.9911\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.0076 - accuracy: 1.0000Epoch 13/50\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.0048 - accuracy: 1.0000\n",
      "Epoch 17/50\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.0908 - accuracy: 0.9821A: 0s - loss: 0.0380 - accuracy: 0.9792\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 0.0350 - accuracy: 1.0000Epoch 25/50\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 1.4696 - accuracy: 0.3817\n",
      "Epoch 3/50\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.0637 - accuracy: 0.9799\n",
      "Epoch 23/50\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.0670 - accuracy: 0.9911\n",
      "Epoch 7/50\n",
      " 6/14 [===========>..................] - ETA: 0s - loss: 1.4352 - accuracy: 0.322914/14 [==============================] - 0s 27ms/step - loss: 0.0437 - accuracy: 0.9933\n",
      " 5/14 [=========>....................] - ETA: 0s - loss: 0.0546 - accuracy: 0.9875Epoch 14/50\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.8862 - accuracy: 0.8080\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.0072 - accuracy: 1.0000Epoch 38/50\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.0069 - accuracy: 1.0000\n",
      "Epoch 18/50\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.1008 - accuracy: 0.9665\n",
      "Epoch 26/50\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 1.3158 - accuracy: 0.4353\n",
      "Epoch 4/50\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.0627 - accuracy: 0.9821\n",
      "Epoch 24/50\n",
      " 5/14 [=========>....................] - ETA: 0s - loss: 0.1170 - accuracy: 0.9750"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:27:56.039528: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 32ms/step - loss: 0.0414 - accuracy: 0.9911\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.0648 - accuracy: 0.9688Epoch 8/50\n",
      "14/14 [==============================] - 0s 24ms/step - loss: 1.0650 - accuracy: 0.6830\n",
      "Epoch 39/50\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0356 - accuracy: 0.9955\n",
      "Epoch 15/50\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.0423 - accuracy: 0.9799- loss: 0.0423 - accuracy: 0.9799 - ETA: 0s - loss: 0.1199 - accuracy: 0.96\n",
      "Epoch 19/50\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.1099 - accuracy: 0.9732A: 0s - loss: 0.0304 - accuracy: 1.00\n",
      "Epoch 27/50\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 1.0330 - accuracy: 0.6228 [==============>...............] - ETA: 0s - loss: 0.0373 - accuracy: 1.00\n",
      " 8/14 [================>.............] - ETA: 0s - loss: 0.5807 - accuracy: 0.8242Epoch 5/50\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 0.0547 - accuracy: 0.9866\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.0333 - accuracy: 1.0000Epoch 25/50\n",
      "14/14 [==============================] - 1s 50ms/step - loss: 0.0300 - accuracy: 0.9978- loss: 0.4702 - accuracy: 0.8551 - ETA: 0s - loss: 0.1129 - accuracy: 0.\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.4357 - accuracy: 0.8654Epoch 9/50\n",
      "14/14 [==============================] - 1s 51ms/step - loss: 0.4225 - accuracy: 0.8705\n",
      "11/14 [======================>.......] - ETA: 0s - loss: 0.6567 - accuracy: 0.8636Epoch 40/50\n",
      "14/14 [==============================] - 1s 51ms/step - loss: 0.0364 - accuracy: 0.9978\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.1033 - accuracy: 0.9653Epoch 16/50\n",
      "14/14 [==============================] - 1s 51ms/step - loss: 0.6036 - accuracy: 0.8616- loss: 0.0209 - accuracy: 0.9896 - ETA: 0s - loss: 0.1063 - accuracy: 0.96\n",
      "Epoch 20/50\n",
      "14/14 [==============================] - 1s 51ms/step - loss: 0.1155 - accuracy: 0.9598A: 0s - loss: 0.0710 - accuracy: 0.98\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 0.0171 - accuracy: 0.9955 - ETA: 0s - loss: 0.0202 - accuracy: 0.9896Epoch 28/50\n",
      "14/14 [==============================] - 1s 50ms/step - loss: 0.7499 - accuracy: 0.6920- loss: 0.1524 - accuracy: 1.0000 - ETA: 0s - loss: 0.3135 - accuracy: 0.90\n",
      "Epoch 6/50\n",
      "14/14 [==============================] - 1s 43ms/step - loss: 0.0150 - accuracy: 0.9933\n",
      "Epoch 26/50\n",
      "14/14 [==============================] - 2s 72ms/step - loss: 1.5553 - accuracy: 0.3616\n",
      "11/14 [======================>.......] - ETA: 0s - loss: 0.1146 - accuracy: 0.9574Epoch 2/50\n",
      "14/14 [==============================] - 1s 44ms/step - loss: 0.0194 - accuracy: 0.9978\n",
      "Epoch 10/50\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.0660 - accuracy: 0.9821\n",
      "Epoch 17/50\n",
      "14/14 [==============================] - 1s 44ms/step - loss: 0.1140 - accuracy: 0.9576\n",
      "Epoch 41/50\n",
      "14/14 [==============================] - 1s 59ms/step - loss: 0.3371 - accuracy: 0.8996- loss: 0.0965 - accuracy: 0.9688 - ETA: 0s - loss: 0.5417 - accuracy: 0.75\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 0.5525 - accuracy: 0.7500Epoch 21/50\n",
      "14/14 [==============================] - 1s 50ms/step - loss: 0.0727 - accuracy: 0.9866A: 0s - loss: 0.0225 - accuracy: 0.99\n",
      " 8/14 [================>.............] - ETA: 0s - loss: 0.0334 - accuracy: 0.9922Epoch 29/50\n",
      "14/14 [==============================] - 1s 57ms/step - loss: 0.5768 - accuracy: 0.7321\n",
      " 5/14 [=========>....................] - ETA: 0s - loss: 0.2552 - accuracy: 0.9438Epoch 7/50\n",
      "14/14 [==============================] - 1s 55ms/step - loss: 1.4861 - accuracy: 0.3996\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 0.2319 - accuracy: 0.9509Epoch 3/50\n",
      "14/14 [==============================] - 1s 58ms/step - loss: 0.0329 - accuracy: 0.9888\n",
      " 4/14 [=======>......................] - ETA: 0s - loss: 0.0608 - accuracy: 0.9766Epoch 27/50\n",
      "14/14 [==============================] - 1s 62ms/step - loss: 0.0209 - accuracy: 0.9955A: 0s - loss: 0.2356 - accuracy: 0.94\n",
      " - 1s 62ms/step - loss: 0.0374 - accuracy: 0.9888\n",
      " 4/14 [=======>......................] - ETA: 0s - loss: 0.5258 - accuracy: 0.7500Epoch 18/50\n",
      " 2/14 [===>..........................] - ETA: 0s - loss: 0.0114 - accuracy: 1.0000Epoch 11/50\n",
      "14/14 [==============================] - 1s 57ms/step - loss: 0.0726 - accuracy: 0.9844A: 0s - loss: 0.0726 - accuracy: 0.98\n",
      "Epoch 42/50\n",
      "14/14 [==============================] - 1s 61ms/step - loss: 0.2137 - accuracy: 0.9442A: 0s - loss: 0.0438 - accuracy: 0.\n",
      " 3/14 [=====>........................] - ETA: 1s - loss: 0.0345 - accuracy: 0.9896Epoch 22/50\n",
      "14/14 [==============================] - 1s 59ms/step - loss: 0.0508 - accuracy: 0.9844A: 0s - loss: 1.4479 - accuracy: 0.\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 0.0800 - accuracy: 0.9732Epoch 30/50\n",
      "14/14 [==============================] - 1s 64ms/step - loss: 0.4886 - accuracy: 0.7701\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.0322 - accuracy: 0.9896Epoch 8/50\n",
      "14/14 [==============================] - 1s 66ms/step - loss: 0.0058 - accuracy: 1.0000\n",
      " 4/14 [=======>......................] - ETA: 0s - loss: 0.0498 - accuracy: 1.0000Epoch 28/50\n",
      "14/14 [==============================] - 1s 64ms/step - loss: 1.3947 - accuracy: 0.3996\n",
      " 4/14 [=======>......................] - ETA: 0s - loss: 0.4292 - accuracy: 0.8203Epoch 4/50\n",
      "14/14 [==============================] - 1s 58ms/step - loss: 0.0466 - accuracy: 0.9821\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 1.1325 - accuracy: 0.5000Epoch 43/50\n",
      "14/14 [==============================] - 1s 66ms/step - loss: 0.0639 - accuracy: 0.9844\n",
      "14/14 [==============================] - 1s 61ms/step - loss: 0.0288 - accuracy: 0.9933\n",
      "Epoch 19/50\n",
      "Epoch 12/50\n",
      "14/14 [==============================] - 1s 55ms/step - loss: 0.1202 - accuracy: 0.9688A: 0s - loss: 0.0593 - accuracy: 0.99\n",
      "12/14 [========================>.....] - ETA: 0s - loss: 0.4190 - accuracy: 0.8229 - ETA: 0s - loss: 0.0688 - accuracy: 0.9844Epoch 23/50\n",
      "14/14 [==============================] - 1s 46ms/step - loss: 0.0732 - accuracy: 0.9821A: 0s - loss: 0.0214 - accuracy: 0.98\n",
      "Epoch 31/50\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.4074 - accuracy: 0.8237A: 0s - loss: 0.0832 - accuracy: 0.97\n",
      "Epoch 9/50\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 0.0218 - accuracy: 0.9888\n",
      "11/14 [======================>.......] - ETA: 0s - loss: 0.0144 - accuracy: 1.0000Epoch 29/50\n",
      "14/14 [==============================] - 1s 43ms/step - loss: 1.2152 - accuracy: 0.4777\n",
      "Epoch 5/50\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.0574 - accuracy: 0.9821\n",
      "14/14 [==============================] - 1s 43ms/step - loss: 0.0565 - accuracy: 0.9844\n",
      " 1/14 [=>............................]Epoch 20/50\n",
      " - ETA: 0s - loss: 0.9505 - accuracy: 0.5625Epoch 44/50\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.1580 - accuracy: 0.9479 - 1s 42ms/step - loss: 0.0140 - accuracy: 1.0000\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.0892 - accuracy: 0.9719Epoch 13/50\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 0.0747 - accuracy: 0.9754A: 0s - loss: 0.0776 - accuracy: 0.\n",
      "Epoch 24/50\n",
      "14/14 [==============================] - 1s 47ms/step - loss: 0.3589 - accuracy: 0.8371\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 1.0949 - accuracy: 0.4866Epoch 10/50\n",
      "14/14 [==============================] - 1s 50ms/step - loss: 0.0797 - accuracy: 0.9665\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.0355 - accuracy: 0.9965Epoch 32/50\n",
      "14/14 [==============================] - 1s 46ms/step - loss: 0.1364 - accuracy: 0.9509\n",
      "11/14 [======================>.......] - ETA: 0s - loss: 1.0237 - accuracy: 0.5284Epoch 30/50\n",
      "14/14 [==============================] - 1s 46ms/step - loss: 0.0654 - accuracy: 0.9799\n",
      "Epoch 45/50\n",
      "14/14 [==============================] - 1s 52ms/step - loss: 0.9882 - accuracy: 0.5603\n",
      "Epoch 6/50\n",
      "14/14 [==============================] - 1s 48ms/step - loss: 0.0120 - accuracy: 0.9978\n",
      "14/14 [==============================] - 1s 51ms/step - loss: 0.0410 - accuracy: 0.9933\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.1476 - accuracy: 0.9375Epoch 21/50\n",
      "Epoch 14/50\n",
      "14/14 [==============================] - 1s 43ms/step - loss: 0.0495 - accuracy: 0.9955A: 0s - loss: 0.0495 - accuracy: 0.99\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.1130 - accuracy: 0.9625Epoch 25/50\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.1084 - accuracy: 0.9643A: 0s - loss: 0.8985 - accuracy: 0.61TA: 0s - loss: 0.3020 - accuracy: 0.89\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.3460 - accuracy: 0.8482\n",
      "Epoch 33/50\n",
      "Epoch 11/50\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.0579 - accuracy: 0.9777\n",
      "Epoch 46/50\n",
      "14/14 [==============================] - 1s 44ms/step - loss: 0.2366 - accuracy: 0.9152\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.0524 - accuracy: 0.9688Epoch 31/50\n",
      "11/14 [======================>.......]14/14 [==============================] - ETA: 0s - loss: 0.0450 - accuracy: 0.9972 - 1s 40ms/step - loss: 0.0542 - accuracy: 0.9955\n",
      "12/14 [========================>.....] - ETA: 0s - loss: 0.8337 - accuracy: 0.6302Epoch 22/50\n",
      "14/14 [==============================] - 1s 49ms/step - loss: 0.0066 - accuracy: 1.0000\n",
      "Epoch 15/50\n",
      "14/14 [==============================] - 1s 51ms/step - loss: 0.8193 - accuracy: 0.6339\n",
      " - ETA: 0s - loss: 0.0487 - accuracy: 0.982612/14 [========================>.....] - ETA: 0s - loss: 0.0425 - accuracy: 0.9974Epoch 7/50\n",
      "14/14 [==============================] - 1s 47ms/step - loss: 0.0383 - accuracy: 0.9978\n",
      "Epoch 26/50\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.2465 - accuracy: 0.8795\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 0.0599 - accuracy: 1.0000Epoch 12/50\n",
      "14/14 [==============================] - 1s 43ms/step - loss: 0.0654 - accuracy: 0.9777\n",
      "Epoch 34/50\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 0.0387 - accuracy: 0.9821\n",
      "Epoch 47/50\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.2026 - accuracy: 0.9397\n",
      "Epoch 32/50\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.0509 - accuracy: 0.9821\n",
      "Epoch 23/50\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.6979 - accuracy: 0.6741\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.0505 - accuracy: 0.9928Epoch 8/50\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.0055 - accuracy: 1.0000\n",
      "Epoch 16/50\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.0505 - accuracy: 0.9933\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.6398 - accuracy: 0.7188Epoch 27/50\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.0588 - accuracy: 0.9754A: 0s - loss: 0.0568 - accuracy: 0.97TA: 0s - loss: 0.0711 - accuracy: 0.\n",
      " 8/14 [================>.............] - ETA: 0s - loss: 0.0708 - accuracy: 0.9922 - 0s 36ms/step - loss: 0.2303 - accuracy: 0.8929\n",
      "Epoch 35/50\n",
      "Epoch 13/50\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.0449 - accuracy: 0.9821A: 0s - loss: 0.0919 - accuracy: 0.98\n",
      "Epoch 48/50\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.0738 - accuracy: 0.9866\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.1676 - accuracy: 0.9353\n",
      "Epoch 33/50\n",
      "Epoch 24/50\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.0436 - accuracy: 0.9955\n",
      "Epoch 28/50\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.0035 - accuracy: 1.0000\n",
      "Epoch 17/50\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.6182 - accuracy: 0.7076\n",
      "Epoch 9/50\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.5712 - accuracy: 0.7812 - 0s 25ms/step - loss: 0.2490 - accuracy: 0.8862\n",
      "Epoch 14/50\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.0330 - accuracy: 0.9911\n",
      " 9/14 [==================>...........]Epoch 49/50\n",
      "14/14 [==============================] - 1s 46ms/step - loss: 0.0752 - accuracy: 0.9799\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.0901 - accuracy: 0.9656Epoch 36/50\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.0844 - accuracy: 0.9665\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.0277 - accuracy: 0.9976Epoch 34/50\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 0.0786 - accuracy: 0.9688\n",
      "12/14 [========================>.....] - ETA: 0s - loss: 0.2294 - accuracy: 0.9193 8/14 [================>.............]Epoch 25/50\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0451 - accuracy: 0.9688 - 1s 39ms/step - loss: 0.0263 - accuracy: 0.9978\n",
      " 5/14 [=========>....................] - ETA: 0s - loss: 0.0694 - accuracy: 0.9750Epoch 29/50\n",
      "14/14 [==============================] - 0s 36ms/step - loss: 0.2266 - accuracy: 0.9152\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 0.0317 - accuracy: 0.9896Epoch 15/50\n",
      "14/14 [==============================] - 1s 45ms/step - loss: 0.0018 - accuracy: 1.0000- loss: 0.0019 - accuracy: 1.0000 - ETA: 0s - loss: 0.0683 - accuracy: 0.97\n",
      "Epoch 18/50\n",
      "14/14 [==============================] - 1s 52ms/step - loss: 0.6012 - accuracy: 0.6942- loss: 0.0420 - accuracy: 0.9844 - ETA: 0s - loss: 0.6121 - accuracy: 0.\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 0.0459 - accuracy: 0.9911Epoch 10/50\n",
      "14/14 [==============================] - 0s 36ms/step - loss: 0.0404 - accuracy: 0.9844\n",
      "Epoch 50/50\n",
      "14/14 [==============================] - 1s 36ms/step - loss: 0.0854 - accuracy: 0.9710\n",
      "Epoch 37/50\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.0344 - accuracy: 0.9888- loss: 0.0270 - accuracy: 0.9896 - ETA: 0s - loss: 0.0455 - accuracy: 0.\n",
      " 5/14 [=========>....................] - ETA: 0s - loss: 0.0760 - accuracy: 0.9625Epoch 35/50\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.0418 - accuracy: 0.9978\n",
      "Epoch 30/50\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 19/50\n",
      "14/14 [==============================] - 1s 46ms/step - loss: 0.0370 - accuracy: 0.9955\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 0.5506 - accuracy: 0.7411Epoch 26/50\n",
      "14/14 [==============================] - 1s 48ms/step - loss: 0.2015 - accuracy: 0.9196\n",
      "12/14 [========================>.....] - ETA: 0s - loss: 0.0759 - accuracy: 0.9688Epoch 16/50\n",
      "14/14 [==============================] - 1s 33ms/step - loss: 0.0324 - accuracy: 0.9888\n",
      "14/14 [==============================] - 1s 36ms/step - loss: 0.0728 - accuracy: 0.9710\n",
      " 5/14 [=========>....................] - ETA: 0s - loss: 0.0013 - accuracy: 1.0000Epoch 38/50\n",
      " - ETA: 0s - loss: 0.0302 - accuracy: 0.988614/14 [==============================] - 1s 51ms/step - loss: 0.5328 - accuracy: 0.7589\n",
      "Epoch 11/50\n",
      "14/14 [==============================] - 0s 36ms/step - loss: 0.0316 - accuracy: 1.0000\n",
      "Epoch 31/50\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.0296 - accuracy: 0.9911\n",
      " 6/14 [===========>..................] - ETA: 0s - loss: 0.0735 - accuracy: 0.9792Epoch 36/50\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.0225 - accuracy: 0.9978\n",
      "Epoch 27/50\n",
      "14/14 [==============================] - 1s 43ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 20/50\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 0.0021 - accuracy: 1.0000    4 [=========>....................] - ETA: 0s - loss: 0.0050 - accuracy: 1.00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:28:03.865501: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 1s 42ms/step - loss: 0.1660 - accuracy: 0.9531\n",
      "Epoch 17/50\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.0645 - accuracy: 0.9821\n",
      "Epoch 39/50\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.0236 - accuracy: 0.9978\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 0.1034 - accuracy: 0.9792Epoch 32/50\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.4623 - accuracy: 0.8080\n",
      "Epoch 12/50\n",
      "4/4 [==============================] - 1s 62ms/step - loss: 0.0194 - accuracy: 1.0000\n",
      "[CV 5/5] END ...epochs=50, layers=2, neurons=40;, score=1.000 total time=  25.7s\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.0310 - accuracy: 0.9888\n",
      " 6/14 [===========>..................] - ETA: 0s - loss: 0.1098 - accuracy: 0.9740Epoch 37/50\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.0331 - accuracy: 0.9955\n",
      "Epoch 28/50\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.0017 - accuracy: 1.0000A: 0s - loss: 0.0715 - accuracy: 0.98\n",
      "Epoch 21/50\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.1123 - accuracy: 0.9665\n",
      "Epoch 18/50\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.1049 - accuracy: 0.9576\n",
      "Epoch 40/50\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.4281 - accuracy: 0.8214\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.0162 - accuracy: 1.0000Epoch 13/50\n",
      "14/14 [==============================] 9/14 [==================>...........] - 1s 38ms/step - loss: 0.0401 - accuracy: 1.0000\n",
      " - ETA: 0s - loss: 0.0016 - accuracy: 1.0000Epoch 33/50\n",
      "14/14 [==============================] - 0s 36ms/step - loss: 0.0251 - accuracy: 0.9955\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.1049 - accuracy: 0.9722Epoch 38/50\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.0160 - accuracy: 0.9978\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.0014 - accuracy: 1.0000Epoch 29/50\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.1181 - accuracy: 0.9625Epoch 22/50\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.1150 - accuracy: 0.9688\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.0015 - accuracy: 1.0000Epoch 19/50\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.1606 - accuracy: 0.9531\n",
      "Epoch 41/50\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.3875 - accuracy: 0.8281\n",
      "11/14 [======================>.......] - ETA: 0s - loss: 0.0105 - accuracy: 1.0000Epoch 14/50\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.0084 - accuracy: 0.9978\n",
      "Epoch 39/50\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.0202 - accuracy: 0.9978\n",
      "Epoch 34/50\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.0101 - accuracy: 1.0000\n",
      "Epoch 30/50\n",
      "11/14 [======================>.......] 6/14 [===========>..................] - ETA: 0s - loss: 0.0011 - accuracy: 1.0000 - ETA: 0s - loss: 0.2783 - accuracy: 0.9323Epoch 1/50\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.1166 - accuracy: 0.9643\n",
      "Epoch 20/50\n",
      "14/14 [==============================] - 1s 36ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 23/50\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.2308 - accuracy: 0.9308A: 1s - loss: 0.0015 - accuracy: 1.00\n",
      "Epoch 42/50\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0293 - accuracy: 0.9978A: 0s - loss: 0.0293 - accuracy: 0.99\n",
      "Epoch 35/50\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.0089 - accuracy: 1.0000\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.0157 - accuracy: 0.9978\n",
      "Epoch 31/50\n",
      "Epoch 40/50\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.1243 - accuracy: 0.9598\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.0105 - accuracy: 1.0000Epoch 21/50\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.3879 - accuracy: 0.8326\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.0469 - accuracy: 1.0000Epoch 15/50\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.0013 - accuracy: 1.0000- ETA: 0s - loss: 0.4455 - accuracy: 0.76\n",
      "Epoch 24/50\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0303 - accuracy: 0.9978A: 0s - loss: 0.1532 - accuracy: 0.94\n",
      "Epoch 36/50\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.4002 - accuracy: 0.9152\n",
      "Epoch 43/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:28:05.821958: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 32ms/step - loss: 0.0206 - accuracy: 0.9955\n",
      "Epoch 41/50\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.1157 - accuracy: 0.9576\n",
      "Epoch 22/50\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.3372 - accuracy: 0.8281\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 0.0184 - accuracy: 1.0000    Epoch 16/50\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.0299 - accuracy: 1.0000\n",
      "Epoch 32/50\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.0018 - accuracy: 1.0000- loss: 0.0817 - accuracy: 0.9609 - ETA: 0s - loss: 0.0178 - accuracy: 0.\n",
      "Epoch 25/50\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.0343 - accuracy: 0.9978\n",
      "Epoch 37/50\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.7285 - accuracy: 0.7969\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0807 - accuracy: 0.9732\n",
      "Epoch 23/50\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 0.0172 - accuracy: 1.0000\n",
      "Epoch 33/50\n",
      "Epoch 44/50\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.2736 - accuracy: 0.8683\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 0.0553 - accuracy: 0.9896Epoch 17/50\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.0141 - accuracy: 0.9933A: 0s - loss: 0.3824 - accuracy: 0.87\n",
      " 5/14 [=========>....................] - ETA: 0s - loss: 0.0209 - accuracy: 1.0000Epoch 42/50\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 1.5590 - accuracy: 0.3348\n",
      "Epoch 2/50\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.0139 - accuracy: 0.9933A: 0s - loss: 0.0432 - accuracy: 0.98\n",
      "Epoch 26/50\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0946 - accuracy: 0.9509A: 0s - loss: 0.0077 - accuracy: 1.\n",
      "Epoch 24/50\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.0333 - accuracy: 1.0000\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.0409 - accuracy: 1.0000Epoch 38/50\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.0304 - accuracy: 0.9911\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.3829 - accuracy: 0.9038Epoch 34/50\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.3841 - accuracy: 0.9063\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.2856 - accuracy: 0.8482\n",
      "Epoch 45/50\n",
      "Epoch 18/50\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.0213 - accuracy: 0.9978\n",
      "Epoch 43/50\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 1.5030 - accuracy: 0.3817\n",
      "12/14 [========================>.....] - ETA: 0s - loss: 0.0104 - accuracy: 0.9974Epoch 3/50\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.0102 - accuracy: 0.9978A: 0s - loss: 0.0200 - accuracy: 1.00\n",
      "Epoch 27/50\n",
      "14/14 [==============================] - 0s 23ms/step - loss: 0.0762 - accuracy: 0.9688\n",
      " 5/14 [=========>....................] - ETA: 0s - loss: 0.2809 - accuracy: 0.8750Epoch 25/50\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.0324 - accuracy: 0.9978- loss: 0.0281 - accuracy: 0.9976 - ETA: 0s - loss: 0.0112 - accuracy: 0.99\n",
      "Epoch 39/50\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0099 - accuracy: 0.9978\n",
      "Epoch 35/50\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.2847 - accuracy: 0.8571- loss: 0.0105 - accuracy: 1.0000 - ETA: 0s - loss: 0.3444 - accuracy: 0.\n",
      "Epoch 19/50\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 1.4141 - accuracy: 0.3973\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.3358 - accuracy: 0.9509\n",
      " 5/14 [=========>....................] - ETA: 0s - loss: 0.0222 - accuracy: 0.9875Epoch 46/50\n",
      "Epoch 4/50\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.0516 - accuracy: 0.9888\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.2865 - accuracy: 1.0000Epoch 26/50\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.0143 - accuracy: 1.0000- loss: 0.0143 - accuracy: 1.0000 - ETA: 0s - loss: 0.3175 - accuracy: 0.83\n",
      "Epoch 44/50\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.0031 - accuracy: 1.0000\n",
      "Epoch 28/50\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.0368 - accuracy: 1.0000\n",
      " 8/14 [================>.............] - ETA: 0s - loss: 0.0468 - accuracy: 0.9805Epoch 40/50\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.0238 - accuracy: 0.9955\n",
      " 8/14 [================>.............] - ETA: 0s - loss: 0.3205 - accuracy: 0.8398Epoch 36/50\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0428 - accuracy: 0.9844A: 0s - loss: 0.2932 - accuracy: 0.85\n",
      "Epoch 27/50\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.2850 - accuracy: 0.8571\n",
      " 5/14 [=========>....................] - ETA: 0s - loss: 0.0365 - accuracy: 1.0000Epoch 20/50\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 1.2291 - accuracy: 0.5201\n",
      "Epoch 5/50\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.0053 - accuracy: 0.9978\n",
      "Epoch 45/50\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.2585 - accuracy: 0.9754\n",
      "Epoch 47/50\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.0118 - accuracy: 0.9933\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.0323 - accuracy: 1.0000Epoch 29/50\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.0360 - accuracy: 0.9978\n",
      "Epoch 37/50\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.0310 - accuracy: 1.0000\n",
      "Epoch 41/50\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.0444 - accuracy: 0.9911\n",
      "Epoch 28/50\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.9611 - accuracy: 0.5312A: 0s - loss: 0.2233 - accuracy: 0.9688\n",
      "Epoch 6/50\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.2529 - accuracy: 0.8616\n",
      "Epoch 21/50\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.0041 - accuracy: 1.0000\n",
      "11/14 [======================>.......] - ETA: 0s - loss: 0.0018 - accuracy: 1.0000 - ETA: 0s - loss: 0.0209 - accuracy: 1.0000Epoch 30/50\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.2481 - accuracy: 0.9710\n",
      "Epoch 48/50\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 46/50\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.0250 - accuracy: 0.9978\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 0.2695 - accuracy: 0.8795Epoch 38/50\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.0249 - accuracy: 0.9978\n",
      "Epoch 42/50\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0274 - accuracy: 0.9955\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.2696 - accuracy: 0.8854Epoch 29/50\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.7862 - accuracy: 0.5670\n",
      "Epoch 7/50\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.2642 - accuracy: 0.8951\n",
      " 6/14 [===========>..................] - ETA: 0s - loss: 0.0351 - accuracy: 0.9948Epoch 22/50\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.2530 - accuracy: 0.9621\n",
      "Epoch 49/50\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.0275 - accuracy: 1.0000Epoch 31/50\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0128 - accuracy: 1.0000\n",
      "12/14 [========================>.....] - ETA: 0s - loss: 0.0356 - accuracy: 0.9922Epoch 39/50\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.0294 - accuracy: 0.9933\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0287 - accuracy: 1.0000Epoch 47/50\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.0287 - accuracy: 1.0000\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.0010 - accuracy: 1.0000Epoch 43/50\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0373 - accuracy: 0.9888\n",
      "Epoch 30/50\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.7087 - accuracy: 0.5737A: 0s - loss: 0.0013 - accuracy: 1.0000  \n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 0.0310 - accuracy: 1.0000Epoch 8/50\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.2627 - accuracy: 0.8728\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.2424 - accuracy: 0.9567Epoch 23/50\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.2455 - accuracy: 0.9554\n",
      "Epoch 50/50\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0083 - accuracy: 1.0000\n",
      "Epoch 40/50\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 0.0382 - accuracy: 0.9844\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 0.2004 - accuracy: 0.9583Epoch 31/50\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 6.6489e-04 - accuracy: 1.0000\n",
      "12/14 [========================>.....] - ETA: 0s - loss: 0.6523 - accuracy: 0.6458Epoch 32/50\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.0080 - accuracy: 1.0000\n",
      "Epoch 48/50\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.6537 - accuracy: 0.6429\n",
      "Epoch 9/50\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.0140 - accuracy: 1.0000\n",
      "Epoch 44/50\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.3098 - accuracy: 0.8862\n",
      "Epoch 24/50\n",
      "14/14 [==============================] - 0s 23ms/step - loss: 0.0296 - accuracy: 0.9888\n",
      " 5/14 [=========>....................] - ETA: 0s - loss: 0.0190 - accuracy: 1.0000Epoch 32/50\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.2334 - accuracy: 0.9598\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.0161 - accuracy: 1.0000\n",
      "11/14 [======================>.......] - ETA: 0s - loss: 0.5865 - accuracy: 0.7330Epoch 41/50\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.5744 - accuracy: 0.7522A: 0s - loss: 0.0592 - accuracy: 0.96\n",
      "Epoch 10/50\n",
      " 7/14 [==============>...............] - 0s 34ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      " - ETA: 0s - loss: 0.0657 - accuracy: 0.9643Epoch 33/50\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.0116 - accuracy: 0.9955\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.0194 - accuracy: 1.0000\n",
      "Epoch 49/50\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.0661 - accuracy: 0.9656Epoch 45/50\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 0.0670 - accuracy: 0.9688\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 0.0691 - accuracy: 1.0000Epoch 33/50\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.2173 - accuracy: 0.8839\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 5.3602e-04 - accuracy: 1.0000Epoch 25/50\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 4.4574e-04 - accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:28:10.307501: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 32ms/step - loss: 0.0333 - accuracy: 0.9978A: 0s - loss: 0.0340 - accuracy: 0.98\n",
      "11/14 [======================>.......] - ETA: 0s - loss: 4.5754e-04 - accuracy: 1.0000Epoch 42/50\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.5181 - accuracy: 0.7746\n",
      "Epoch 11/50\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.0273 - accuracy: 1.0000\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 4.4876e-04 - accuracy: 1.0000\n",
      "Epoch 46/50\n",
      "Epoch 34/50\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 50/50\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.5643 - accuracy: 0.8021 - 0s 28ms/step - loss: 0.0297 - accuracy: 0.9933\n",
      "Epoch 34/50\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 0.1741 - accuracy: 0.99110\n",
      "11/14 [======================>.......] - ETA: 0s - loss: 0.2160 - accuracy: 0.9062[CV 1/5] END ...epochs=50, layers=2, neurons=60;, score=0.991 total time=  28.5s\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0419 - accuracy: 0.9812 - 0s 33ms/step - loss: 0.2230 - accuracy: 0.9107\n",
      "Epoch 26/50\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.0240 - accuracy: 0.9978\n",
      "Epoch 43/50\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.5032 - accuracy: 0.8281- loss: 0.0065 - accuracy: 0.9961 - ETA: 0s - loss: 0.0700 - accuracy: 0.96\n",
      "Epoch 12/50\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 2.8586e-04 - accuracy: 1.0000A: 0s - loss: 0.0131 - accuracy: 1.00\n",
      "Epoch 35/50\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.0312 - accuracy: 0.9888- loss: 0.0317 - accuracy: 0.9880 - ETA: 0s - loss: 0.4756 - accuracy: 0.85\n",
      "Epoch 35/50\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0074 - accuracy: 0.9978\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.0125 - accuracy: 1.0000\n",
      "Epoch 47/50\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0472 - accuracy: 0.9844\n",
      "Epoch 44/50\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.4708 - accuracy: 0.8549\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.3527 - accuracy: 0.8438Epoch 13/50\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 0.1973 - accuracy: 0.8951\n",
      "Epoch 27/50\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 3.3069e-04 - accuracy: 1.0000\n",
      "11/14 [======================>.......] - ETA: 0s - loss: 0.0149 - accuracy: 1.0000Epoch 36/50\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.0229 - accuracy: 1.0000\n",
      "Epoch 48/50\n",
      "14/14 [==============================] - 0s 36ms/step - loss: 0.0258 - accuracy: 0.9866\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.0015 - accuracy: 1.0000Epoch 36/50\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 0.0889 - accuracy: 0.9665\n",
      "Epoch 45/50\n",
      " 8/14 [================>.............] - ETA: 0s - loss: 1.7755e-04 - accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:28:11.490645: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 27ms/step - loss: 0.4648 - accuracy: 0.8683\n",
      "Epoch 14/50\n",
      " - ETA: 0s - loss: 0.0125 - accuracy: 0.997214/14 [==============================] - 0s 27ms/step - loss: 1.6421e-04 - accuracy: 1.0000\n",
      "Epoch 37/50\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.2585 - accuracy: 0.8594\n",
      "4/4 [==============================]Epoch 28/50\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 7.6396e-05 - accuracy: 1.0000 - 0s 68ms/step - loss: 0.0065 - accuracy: 0.9911\n",
      "[CV 2/5] END ...epochs=50, layers=2, neurons=60;, score=0.991 total time=  28.3s\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 0.0130 - accuracy: 0.9955- ETA: 0s - loss: 0.4487 - accuracy: 0.83\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.0280 - accuracy: 0.9976Epoch 37/50\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0288 - accuracy: 0.9978\n",
      "Epoch 49/50\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 0.4601 - accuracy: 0.8460\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 1.2729e-04 - accuracy: 1.0000Epoch 15/50\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.2055 - accuracy: 0.8817A: 0s - loss: 0.3774 - accuracy: 0.92\n",
      "Epoch 29/50\n",
      "11/14 [======================>.......] - ETA: 0s - loss: 0.0113 - accuracy: 1.0000Epoch 1/50\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.0115 - accuracy: 0.9955\n",
      "Epoch 38/50\n",
      "14/14 [==============================] - 1s 54ms/step - loss: 0.0762 - accuracy: 0.9799\n",
      "Epoch 46/50\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.0145 - accuracy: 1.0000\n",
      "Epoch 50/50\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 1.1758e-04 - accuracy: 1.0000\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 0.0379 - accuracy: 0.9792Epoch 38/50- loss: 0.1879 - accuracy: 0.93\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.4432 - accuracy: 0.8728\n",
      " 6/14 [===========>..................] - ETA: 0s - loss: 0.0374 - accuracy: 0.9792Epoch 16/50\n",
      "14/14 [==============================] - 0s 23ms/step - loss: 0.0312 - accuracy: 0.9844\n",
      "11/14 [======================>.......] - ETA: 0s - loss: 0.0987 - accuracy: 0.9773Epoch 39/50\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.1915 - accuracy: 0.9330\n",
      "11/14 [======================>.......] - ETA: 0s - loss: 1.6111e-04 - accuracy: 1.0000Epoch 30/50\n",
      "14/14 [==============================] - 0s 24ms/step - loss: 0.0953 - accuracy: 0.9754\n",
      "Epoch 47/50\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 1.4868e-04 - accuracy: 1.0000\n",
      "Epoch 39/50\n",
      "14/14 [==============================] - 0s 22ms/step - loss: 0.4422 - accuracy: 0.8438\n",
      "Epoch 17/50\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.0256 - accuracy: 0.9978\n",
      "14/14 [==============================] - 0s 23ms/step - loss: 0.0286 - accuracy: 0.9844\n",
      "12/14 [========================>.....] - ETA: 0s - loss: 0.0510 - accuracy: 0.9896Epoch 40/50\n",
      "14/14 [==============================] - 0s 24ms/step - loss: 0.0460 - accuracy: 0.9911\n",
      "Epoch 48/50\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.1905 - accuracy: 0.9085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:28:12.870411: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-01-09 14:28:13.016627: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/50\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 1.2314e-04 - accuracy: 1.0000\n",
      "Epoch 40/50\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.4504 - accuracy: 0.8192\n",
      "Epoch 18/50\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.0766e-04 - accuracy: 1.0000Epoch 1/50\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 1.7940e-04 - accuracy: 1.0000\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 1.0006e-04 - accuracy: 1.0000[CV 3/5] END ...epochs=50, layers=2, neurons=60;, score=1.000 total time=  26.9s\n",
      "14/14 [==============================] - 1s 36ms/step - loss: 0.0297 - accuracy: 0.9911\n",
      "Epoch 41/50\n",
      "14/14 [==============================] - 0s 36ms/step - loss: 0.0843 - accuracy: 0.9777A: 0s - loss: 0.0843 - accuracy: 0.97\n",
      "Epoch 49/50\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.2261 - accuracy: 0.9152\n",
      "Epoch 32/50\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 8.7291e-05 - accuracy: 1.0000\n",
      "Epoch 41/50\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.4385 - accuracy: 0.8571\n",
      "Epoch 19/50\n",
      "14/14 [==============================] - 1s 32ms/step - loss: 1.5368 - accuracy: 0.3237\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 0.3540 - accuracy: 0.8661Epoch 2/50\n",
      "14/14 [==============================] - 0s 23ms/step - loss: 0.0317 - accuracy: 0.9911\n",
      "Epoch 42/50\n",
      "14/14 [==============================] - 0s 23ms/step - loss: 0.0469 - accuracy: 0.9821\n",
      "Epoch 50/50\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0830 - accuracy: 0.9583 - 0s 24ms/step - loss: 0.4221 - accuracy: 0.8504\n",
      "Epoch 20/50\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.3460 - accuracy: 0.8884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:28:13.771496: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 26ms/step - loss: 8.9884e-05 - accuracy: 1.0000\n",
      "Epoch 33/50\n",
      "Epoch 42/50\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 1.4921 - accuracy: 0.3728- ETA: 0s - loss: 0.3773 - accuracy: 0.8571\n",
      "Epoch 3/50\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.0487 - accuracy: 0.9754\n",
      "Epoch 43/50\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0208 - accuracy: 1.0000\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 1.7744e-04 - accuracy: 1.0000\n",
      " 5/14 [=========>....................] - ETA: 0s - loss: 1.4312 - accuracy: 0.4062Epoch 43/50\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.3801 - accuracy: 0.8549\n",
      "Epoch 34/50\n",
      "14/14 [==============================] - 0s 36ms/step - loss: 0.3735 - accuracy: 0.8661\n",
      "Epoch 21/50\n",
      " 8/14 [================>.............] - ETA: 0s - loss: 1.5477 - accuracy: 0.3320Epoch 1/50 - loss: 0.0388 - accuracy: 0.98\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0340 - accuracy: 0.9911A: 0s - loss: 1.3766 - accuracy: 0.\n",
      "Epoch 44/50\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 1.3580 - accuracy: 0.4330\n",
      "Epoch 4/50\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 1.5446 - accuracy: 0.3594\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 6.4583e-05 - accuracy: 1.0000Epoch 2/50\n",
      "11/14 [======================>.......] - ETA: 0s - loss: 0.3347 - accuracy: 0.858000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:28:14.578122: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 29ms/step - loss: 9.7038e-05 - accuracy: 1.0000s - loss: 2.3182e-04 - accuracy: 1.00\n",
      "Epoch 44/50\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.3104 - accuracy: 0.8683\n",
      "Epoch 22/50\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.2536 - accuracy: 0.8996- ETA: 0s - loss: 0.2536 - accuracy: 0.89\n",
      "Epoch 35/50\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.0624 - accuracy: 0.9777- loss: 1.5094 - accuracy: 0.4063 - ETA: 0s - loss: 6.8700e-05 - accuracy: 1.\n",
      "Epoch 45/50\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 0.0328 - accuracy: 0.9911\n",
      " 5/14 [=========>....................] - ETA: 0s - loss: 6.1796e-05 - accuracy: 1.0000[CV 4/5] END ...epochs=50, layers=2, neurons=60;, score=0.991 total time=  27.5s\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 1.4946 - accuracy: 0.3884- loss: 0.1970 - accuracy: 0.9336 - ETA: 0s - loss: 1.5017 - accuracy: 0.38\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 1.1403 - accuracy: 0.5379\n",
      "Epoch 3/50\n",
      "Epoch 5/50\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 7.2518e-05 - accuracy: 1.0000s - loss: 7.2518e-05 - accuracy: 1.00\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.2573 - accuracy: 0.8683\n",
      "Epoch 45/50\n",
      "Epoch 23/50\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.1982 - accuracy: 0.9129\n",
      "Epoch 36/50\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0292 - accuracy: 0.9799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:28:15.153090: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/50\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 1.4359 - accuracy: 0.3862- ETA: 0s - loss: 1.5901 - accuracy: 0.28\n",
      "Epoch 4/50\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.9312 - accuracy: 0.5781\n",
      "Epoch 6/50\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.2620 - accuracy: 0.8616\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 1.5578 - accuracy: 0.3080Epoch 24/50\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.0156 - accuracy: 0.9978A: 0s - loss: 0.6708 - accuracy: 0.7188\n",
      "Epoch 47/50\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.1617 - accuracy: 0.9487\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 0.8208 - accuracy: 0.6042Epoch 37/50\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 1.5501e-04 - accuracy: 1.0000\n",
      " 5/14 [=========>....................] - ETA: 0s - loss: 0.2554 - accuracy: 0.8562Epoch 46/50\n",
      "14/14 [==============================] - 1s 31ms/step - loss: 1.5526 - accuracy: 0.3214\n",
      "Epoch 2/50\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 1.4566 - accuracy: 0.3438Epoch 1/50\n",
      "14/14 [==============================] - 0s 23ms/step - loss: 0.0174 - accuracy: 0.9933- loss: 0.2452 - accuracy: 0.8620 - ETA: 0s - loss: 1.4985 - accuracy: 0.36\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.2353 - accuracy: 0.8705\n",
      "Epoch 48/50\n",
      "Epoch 25/50\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.7416 - accuracy: 0.6607\n",
      "Epoch 7/50\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 1.3072 - accuracy: 0.3862\n",
      "Epoch 5/50\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.1475 - accuracy: 0.9509- loss: 8.5770e-05 - accuracy: 1.0000 - ETA: 0s - loss: 0.1475 - accuracy: 0.94\n",
      "11/14 [======================>.......] - ETA: 0s - loss: 1.5040 - accuracy: 0.3580Epoch 38/50\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 8.3991e-05 - accuracy: 1.0000\n",
      "Epoch 47/50\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 1.4959 - accuracy: 0.3616\n",
      "Epoch 3/50\n",
      "14/14 [==============================] - 0s 24ms/step - loss: 0.0085 - accuracy: 0.9978\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 1.0667 - accuracy: 0.4236Epoch 49/50\n",
      " - ETA: 0s - loss: 0.6304 - accuracy: 0.710214/14 [==============================] - 0s 27ms/step - loss: 0.2274 - accuracy: 0.8750\n",
      "Epoch 26/50\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.6258 - accuracy: 0.7254\n",
      "Epoch 8/50\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 1.0408 - accuracy: 0.4442\n",
      "Epoch 6/50\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.1352 - accuracy: 0.9487\n",
      "Epoch 39/50\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 1.1360e-04 - accuracy: 1.0000\n",
      "Epoch 48/50\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 1.3599 - accuracy: 0.4509\n",
      "Epoch 4/50\n",
      "13/14 [==========================>...]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:28:16.629376: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 24ms/step - loss: 0.2143 - accuracy: 0.9375- ETA: 0s - loss: 1.0956 - accuracy: 0.6875 - ETA: 0s - loss: 0.8094 - accuracy: 0.66\n",
      "Epoch 27/50\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0097 - accuracy: 0.9955\n",
      "Epoch 50/50\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.5008 - accuracy: 0.8192\n",
      "Epoch 9/50\n",
      "11/14 [======================>.......] - 0s 35ms/step - loss: 0.1238 - accuracy: 0.9554\n",
      " - ETA: 0s - loss: 1.0999 - accuracy: 0.5568Epoch 40/50\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.7340 - accuracy: 0.6875\n",
      "Epoch 7/50\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 9.5026e-05 - accuracy: 1.0000ss: 0.0049 - accuracy: 1.0000 - ETA: 0s - loss: 0.0965 - accuracy: 0.\n",
      "Epoch 49/50\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 1.0766 - accuracy: 0.5536\n",
      "Epoch 5/50\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.0082 - accuracy: 0.9978- loss: 0.3960 - accuracy: 0.8177 - ETA: 0s - loss: 5.6994e-05 - accuracy: 1.00\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.1958 - accuracy: 0.9643A: 0s - loss: 0.1385 - accuracy: 0.96\n",
      "Epoch 28/50\n",
      "14/14 [==============================] - 2s 37ms/step - loss: 1.5105 - accuracy: 0.3460\n",
      "11/14 [======================>.......] - ETA: 0s - loss: 7.3968e-05 - accuracy: 1.0000Epoch 2/50\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.3488 - accuracy: 0.8683\n",
      "11/14 [======================>.......] - ETA: 0s - loss: 0.5496 - accuracy: 0.7244Epoch 10/50\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 9.1409e-05 - accuracy: 1.0000\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.8421 - accuracy: 0.6138\n",
      "Epoch 50/50\n",
      "Epoch 6/50\n",
      "14/14 [==============================] - 1s 35ms/step - loss: 0.5491 - accuracy: 0.7299\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 0.2422 - accuracy: 0.9353\n",
      "Epoch 8/50\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.1336 - accuracy: 0.9621\n",
      "Epoch 41/50\n",
      "Epoch 29/50\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 1.3126 - accuracy: 0.44100000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:28:17.670617: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 42ms/step - loss: 9.5799e-05 - accuracy: 1.0000============================] - ETA: 0s - loss: 9.5799e-05 - accuracy: 1.00\n",
      "[CV 1/5] END ...epochs=50, layers=3, neurons=20;, score=1.000 total time=  24.4s\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 1.2412 - accuracy: 0.4888\n",
      "Epoch 3/50\n",
      "14/14 [==============================] - 0s 22ms/step - loss: 0.2155 - accuracy: 0.9531\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.2881 - accuracy: 0.9351Epoch 30/50\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.5817 - accuracy: 0.7254A: 0s - loss: 0.1246 - accuracy: 1.00\n",
      "Epoch 7/50\n",
      "14/14 [==============================] - 1s 35ms/step - loss: 0.3031 - accuracy: 0.9353\n",
      "Epoch 11/50\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 9.0648e-05 - accuracy: 1.0000\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.4734 - accuracy: 0.7723\n",
      " 5/14 [=========>....................] - ETA: 0s - loss: 0.9704 - accuracy: 0.6188Epoch 9/50\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.1275 - accuracy: 0.9598\n",
      "Epoch 42/50\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.2469 - accuracy: 0.9420\n",
      "Epoch 31/50\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.3804 - accuracy: 0.8438\n",
      " 8/14 [================>.............] - ETA: 0s - loss: 0.3941 - accuracy: 0.8359Epoch 8/50\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.2956 - accuracy: 0.9308\n",
      "14/14 [==============================] - 1s 33ms/step - loss: 0.8474 - accuracy: 0.6585\n",
      "Epoch 12/50\n",
      "Epoch 4/50\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.0042 - accuracy: 1.0000\n",
      "[CV 5/5] END ...epochs=50, layers=2, neurons=60;, score=1.000 total time=  28.4s\n",
      " 5/14 [=========>....................] - ETA: 0s - loss: 0.5801 - accuracy: 0.7750"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:28:18.414520: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 1s 37ms/step - loss: 0.3811 - accuracy: 0.8460\n",
      "11/14 [======================>.......] - ETA: 0s - loss: 0.2585 - accuracy: 0.9517Epoch 10/50\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.1132 - accuracy: 0.9665\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.2301 - accuracy: 0.9167Epoch 43/50\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.2331 - accuracy: 0.9554\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.1565 - accuracy: 0.9375Epoch 32/50\n",
      "14/14 [==============================] - 0s 36ms/step - loss: 0.2222 - accuracy: 0.9196- loss: 0.5016 - accuracy: 0.8040 - ETA: 0s - loss: 0.3181 - accuracy: 0.88\n",
      "Epoch 9/50\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.4534 - accuracy: 0.8326\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 0.1076 - accuracy: 0.9688Epoch 5/50\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.2805 - accuracy: 0.8438Epoch 1/50\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.3297 - accuracy: 0.9174\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.1074 - accuracy: 0.9688Epoch 13/50\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0984 - accuracy: 0.9732\n",
      "Epoch 44/50\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.2164 - accuracy: 0.9442\n",
      " - ETA: 0s - loss: 0.3054 - accuracy: 0.8984Epoch 33/50\n",
      " - 1s 40ms/step - loss: 0.3067 - accuracy: 0.8705\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.3149 - accuracy: 0.9375Epoch 11/50\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.2637 - accuracy: 0.9129A: 0s - loss: 0.1236 - accuracy: 0.95\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.1505 - accuracy: 0.9554\n",
      "Epoch 6/50\n",
      " 4/14 [=======>......................] - ETA: 0s - loss: 0.3469 - accuracy: 0.8281Epoch 10/50\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.3076 - accuracy: 0.9107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:28:19.409480: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/14 [======================>.......] - ETA: 0s - loss: 0.1372 - accuracy: 0.9403Epoch 14/50\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.4604 - accuracy: 0.8750Epoch 1/50\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.1990 - accuracy: 0.9509\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.2783 - accuracy: 0.8688Epoch 34/50\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.1441 - accuracy: 0.9353\n",
      " 8/14 [================>.............] - ETA: 0s - loss: 0.1193 - accuracy: 0.9570Epoch 45/50\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.2805 - accuracy: 0.8683\n",
      " 1/14 [=>............................] - ETA: 10s - loss: 1.6094 - accuracy: 0.1562Epoch 12/50\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.1176 - accuracy: 0.9621\n",
      "Epoch 11/50\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.1426 - accuracy: 0.9621\n",
      "Epoch 7/50\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.2867 - accuracy: 0.9263\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 1.5874 - accuracy: 0.3125Epoch 15/50\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.1745 - accuracy: 0.9665\n",
      "Epoch 35/50\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.1172 - accuracy: 0.9665\n",
      "Epoch 46/50\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 0.2578 - accuracy: 0.9271"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:28:19.979613: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 1s 30ms/step - loss: 1.5147 - accuracy: 0.3571\n",
      " 8/14 [================>.............] - ETA: 0s - loss: 0.1118 - accuracy: 0.9766 - ETA: 0s - loss: 0.1103 - accuracy: 1.0000Epoch 2/50\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0800 - accuracy: 0.9777\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.2199 - accuracy: 0.9063\n",
      "Epoch 12/50\n",
      "Epoch 13/50\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.0920 - accuracy: 0.9844A: 0s - loss: 0.1836 - accuracy: 0.95\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 0.2396 - accuracy: 0.8958Epoch 8/50\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.1619 - accuracy: 0.9665- loss: 0.2673 - accuracy: 0.9303 - ETA: 0s - loss: 0.0670 - accuracy: 0.97\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.2767 - accuracy: 0.9263\n",
      " 4/14 [=======>......................] - ETA: 0s - loss: 1.5880 - accuracy: 0.2656Epoch 36/50\n",
      "Epoch 16/50\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.1014 - accuracy: 0.9732\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 1.3508 - accuracy: 0.4464\n",
      "Epoch 47/50\n",
      "Epoch 3/50\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.0794 - accuracy: 0.9710\n",
      "Epoch 13/50\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.2153 - accuracy: 0.9420\n",
      "Epoch 14/50\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.0451 - accuracy: 0.9844\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 0.0793 - accuracy: 0.9792Epoch 9/50\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 1.5078 - accuracy: 0.3460\n",
      "Epoch 2/50\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.1593 - accuracy: 0.9665\n",
      "11/14 [======================>.......] - ETA: 0s - loss: 0.1342 - accuracy: 0.9460Epoch 37/50\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 1.0438 - accuracy: 0.5938\n",
      "Epoch 4/50\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.2640 - accuracy: 0.9487- loss: 0.2338 - accuracy: 0.9313 - ETA: 0s - loss: 0.2716 - accuracy: 0.94\n",
      "Epoch 17/50\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.1310 - accuracy: 0.9509- loss: 0.1329 - accuracy: 0.9471 - ETA: 0s - loss: 0.0295 - accuracy: 1.00\n",
      "Epoch 48/50\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.0577 - accuracy: 0.9821A: 0s - loss: 0.1835 - accuracy: 0.95\n",
      "Epoch 14/50\n",
      "14/14 [==============================] - 1s 35ms/step - loss: 0.2061 - accuracy: 0.9442\n",
      " 2/14 [===>..........................] - ETA: 0s - loss: 0.0919 - accuracy: 0.9375Epoch 15/50\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.0475 - accuracy: 0.9911\n",
      "Epoch 10/50\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.6938 - accuracy: 0.6987\n",
      " - ETA: 0s - loss: 0.0957 - accuracy: 0.9688Epoch 5/50\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.1572 - accuracy: 0.9643\n",
      "Epoch 38/50\n",
      "13/14 [==========================>...]14/14 [==============================] - ETA: 0s - loss: 0.2281 - accuracy: 0.9615 - 1s 38ms/step - loss: 1.2666 - accuracy: 0.5179\n",
      "Epoch 3/50\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.2234 - accuracy: 0.9621\n",
      "Epoch 18/50\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.1026 - accuracy: 0.9621A: 0s - loss: 0.2366 - accuracy: 0.96\n",
      "Epoch 49/50\n",
      " - 0s 33ms/step - loss: 0.0351 - accuracy: 0.9888- loss: 0.0351 - accuracy: 0.98\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.1351 - accuracy: 0.9062Epoch 15/50\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.3314 - accuracy: 0.9330\n",
      "Epoch 6/50\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.1342 - accuracy: 0.9732A: 0s - loss: 0.9117 - accuracy: 0.70\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.0412 - accuracy: 0.9911\n",
      "Epoch 39/50\n",
      "Epoch 11/50\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.1976 - accuracy: 0.9665\n",
      "Epoch 16/50\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.8635 - accuracy: 0.6987\n",
      "Epoch 4/50\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.2052 - accuracy: 0.9688A: 0s - loss: 0.1312 - accuracy: 0.96\n",
      "Epoch 19/50\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.1168 - accuracy: 0.9554A: 0s - loss: 0.1386 - accuracy: 0.97\n",
      "Epoch 50/50\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 0.1317 - accuracy: 0.9754\n",
      "Epoch 40/50\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.1244 - accuracy: 0.9688\n",
      "Epoch 7/50\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.0267 - accuracy: 0.9933\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.1149 - accuracy: 0.9688Epoch 16/50\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.1340 - accuracy: 0.9583 - 0s 32ms/step - loss: 0.0265 - accuracy: 0.9955\n",
      "Epoch 12/50\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.1991 - accuracy: 0.9710- loss: 0.6424 - accuracy: 0.6875 - ETA: 0s - loss: 0.0792 - accuracy: 0.97\n",
      "Epoch 17/50\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.5720 - accuracy: 0.7232A: 0s - loss: 0.1923 - accuracy: 0.98\n",
      "Epoch 5/50\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.1381 - accuracy: 0.9688A: 0s - loss: 0.1931 - accuracy: 0.97\n",
      "Epoch 41/50\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.1836 - accuracy: 0.9754\n",
      "Epoch 20/50\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0869 - accuracy: 0.9777\n",
      "11/14 [======================>.......]12/14 [========================>.....] - ETA: 0s - loss: 0.1071 - accuracy: 0.9574 - ETA: 0s - loss: 0.1090 - accuracy: 0.9557Epoch 8/50\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.1284 - accuracy: 0.9487\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 0.1634 - accuracy: 0.9792Epoch 17/50\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.1159 - accuracy: 0.9554\n",
      "14/14 [==============================] - 0s 36ms/step - loss: 0.0134 - accuracy: 0.9978\n",
      "Epoch 13/50\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.2073 - accuracy: 0.9576\n",
      "Epoch 18/50\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.1116 - accuracy: 0.9821\n",
      "Epoch 42/50\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.4504 - accuracy: 0.7969\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.0347 - accuracy: 0.9933\n",
      "Epoch 6/50\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.1722 - accuracy: 0.9808Epoch 9/50\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.1804 - accuracy: 0.9777\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.0722 - accuracy: 0.9688Epoch 21/50\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.1932 - accuracy: 0.9420A: 0s - loss: 0.2854 - accuracy: 0.91\n",
      "Epoch 18/50\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.0057 - accuracy: 1.0000A: 0s - loss: 0.2801 - accuracy: 0.92\n",
      "Epoch 14/50\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.1850 - accuracy: 0.9644"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:28:23.086569: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 1s 39ms/step - loss: 0.1849 - accuracy: 0.9665\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 0.0032 - accuracy: 1.0000Epoch 19/50\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.0574 - accuracy: 0.9732\n",
      "[CV 2/5] END ...epochs=50, layers=3, neurons=20;, score=0.973 total time=  28.8s\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.1238 - accuracy: 0.9710\n",
      "Epoch 43/50\n",
      " - ETA: 0s - loss: 0.2491 - accuracy: 1.000014/14 [==============================] - 1s 35ms/step - loss: 0.2658 - accuracy: 0.9196\n",
      "Epoch 7/50\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.0607 - accuracy: 0.9821\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.2017 - accuracy: 0.9896Epoch 10/50\n",
      "14/14 [==============================] - 1s 45ms/step - loss: 0.2062 - accuracy: 0.9777- loss: 0.2032 - accuracy: 0.9830 - ETA: 0s - loss: 0.1832 - accuracy: 0.\n",
      " 5/14 [=========>....................] - ETA: 0s - loss: 0.2003 - accuracy: 0.9875Epoch 22/50\n",
      "14/14 [==============================] - 0s 36ms/step - loss: 0.0694 - accuracy: 0.9754\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.0022 - accuracy: 1.0000Epoch 19/50\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.0033 - accuracy: 1.0000\n",
      "Epoch 15/50\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.1042 - accuracy: 0.9799- ETA: 0s - loss: 0.0251 - accuracy: 1.000s - loss: 0.0322 - accuracy: 0.99\n",
      " 6/14 [===========>..................] - ETA: 0s - loss: 0.2443 - accuracy: 0.9583Epoch 44/50\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.1484 - accuracy: 0.9844\n",
      "Epoch 20/50\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.0305 - accuracy: 0.9933\n",
      "Epoch 11/50\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.1695 - accuracy: 0.9442\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.0104 - accuracy: 1.0000Epoch 8/50\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.0196 - accuracy: 0.9978\n",
      "Epoch 20/50\n",
      "14/14 [==============================] - 1s 46ms/step - loss: 0.1934 - accuracy: 0.9710 [=====>........................] - ETA: 0s - loss: 0.1844 - accuracy: 0.9844 - ETA: 0s - loss: 0.0865 - accuracy: 0.98\n",
      "Epoch 23/50\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.0026 - accuracy: 1.0000A: 0s - loss: 0.0073 - accuracy: 1.00\n",
      "11/14 [======================>.......] - ETA: 0s - loss: 0.1506 - accuracy: 0.9545Epoch 16/50\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.0088 - accuracy: 1.0000A: 0s - loss: 0.0020 - accuracy: 1.0000: 0s - loss: 0.0093 - accuracy: 1.\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 0.0025 - accuracy: 1.0000Epoch 12/50\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.1470 - accuracy: 0.9554\n",
      "Epoch 45/50\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.1751 - accuracy: 0.9844\n",
      " 5/14 [=========>....................] - ETA: 0s - loss: 0.0027 - accuracy: 1.0000Epoch 21/50\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.1078 - accuracy: 0.9732\n",
      "Epoch 9/50\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.0205 - accuracy: 0.9955\n",
      " 2/14 [===>..........................] - ETA: 0s - loss: 0.1153 - accuracy: 0.9531Epoch 21/50\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.1798 - accuracy: 0.9754\n",
      "Epoch 24/50\n",
      "14/14 [==============================] - 1s 36ms/step - loss: 0.0071 - accuracy: 1.0000\n",
      " 5/14 [=========>....................] - ETA: 0s - loss: 0.0174 - accuracy: 1.0000Epoch 17/50\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.0173 - accuracy: 0.9933\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.0029 - accuracy: 1.0000Epoch 13/50\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.1158 - accuracy: 0.9665\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.0124 - accuracy: 1.0000Epoch 46/50\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 0.1668 - accuracy: 0.9866Epoch 1/50\n",
      "14/14 [==============================] - 1s 36ms/step - loss: 0.1480 - accuracy: 0.9777\n",
      " 5/14 [=========>....................] - ETA: 0s - loss: 0.0099 - accuracy: 1.0000Epoch 22/50\n",
      "14/14 [==============================] - 1s 33ms/step - loss: 0.0830 - accuracy: 0.9732\n",
      "Epoch 10/50\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.0147 - accuracy: 1.0000\n",
      "Epoch 22/50\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.1750 - accuracy: 0.9754\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 0.0049 - accuracy: 1.0000Epoch 25/50\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0092 - accuracy: 1.0000\n",
      "Epoch 14/50\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.0097 - accuracy: 0.9978\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 0.1297 - accuracy: 0.9896Epoch 18/50\n",
      " 5/14 [=========>....................] - ETA: 0s - loss: 0.1566 - accuracy: 0.9812 - ETA: 0s - loss: 0.0113 - accuracy: 1.00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:28:25.209743: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 35ms/step - loss: 0.1063 - accuracy: 0.9732\n",
      "Epoch 47/50\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.1326 - accuracy: 0.9933 [=>............................] - ETA: 0s - loss: 0.0697 - accuracy: 1.00\n",
      " 1/14 [=>............................] - ETA: 7s - loss: 1.6368 - accuracy: 0.1562Epoch 23/50\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.0034 - accuracy: 1.0000\n",
      "Epoch 23/50\n",
      "14/14 [==============================] - 1s 36ms/step - loss: 0.0468 - accuracy: 0.9888\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.1254 - accuracy: 1.0000Epoch 11/50\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.0075 - accuracy: 1.0000\n",
      "Epoch 15/50\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.1678 - accuracy: 0.9732- loss: 0.0024 - accuracy: 1.0000 - ETA: 0s - loss: 0.0992 - accuracy: 0.97\n",
      "Epoch 26/50\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.0327 - accuracy: 0.9866\n",
      "Epoch 19/50\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.1090 - accuracy: 0.9710\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.0098 - accuracy: 1.0000Epoch 48/50\n",
      "14/14 [==============================] - 0s 22ms/step - loss: 0.0026 - accuracy: 1.0000- loss: 0.0986 - accuracy: 0.9911 - ETA: 0s - loss: 1.5697 - accuracy: 0.30\n",
      "Epoch 16/50\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.1291 - accuracy: 0.9844\n",
      "Epoch 24/50\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.0327 - accuracy: 0.9888- loss: 1.5532 - accuracy: 0.3177 - ETA: 0s - loss: 0.0327 - accuracy: 0.98\n",
      "11/14 [======================>.......] - ETA: 0s - loss: 0.1182 - accuracy: 0.9631Epoch 12/50\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.0035 - accuracy: 1.0000\n",
      "Epoch 24/50\n",
      "14/14 [==============================] - 1s 43ms/step - loss: 1.5644 - accuracy: 0.3170- ETA: 0s - loss: 1.5644 - accuracy: 0.31\n",
      "Epoch 2/50\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 0.1202 - accuracy: 0.9621\n",
      " - ETA: 0s - loss: 0.0326 - accuracy: 0.992811/14 [======================>.......] - ETA: 0s - loss: 0.1377 - accuracy: 0.9886Epoch 49/50\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.0309 - accuracy: 0.9933\n",
      "Epoch 20/50\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.1454 - accuracy: 0.9888\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 0.1210 - accuracy: 0.9866Epoch 27/50- loss: 1.4361 - accuracy: 0.41\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.0339 - accuracy: 0.9866\n",
      "12/14 [========================>.....] - ETA: 0s - loss: 0.0021 - accuracy: 1.0000Epoch 17/50\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 25/50\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.1063 - accuracy: 0.9911\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.0423 - accuracy: 0.9821\n",
      "Epoch 25/50\n",
      "Epoch 13/50\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.0886 - accuracy: 0.9777\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 1.4550 - accuracy: 0.3846Epoch 50/50\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0418 - accuracy: 0.9821\n",
      "Epoch 21/50\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 1.4542 - accuracy: 0.3862\n",
      "Epoch 3/50\n",
      "14/14 [==============================] - 0s 24ms/step - loss: 0.0729 - accuracy: 0.9621\n",
      " 6/14 [===========>..................]Epoch 18/50\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0037 - accuracy: 1.0000 - 0s 36ms/step - loss: 0.1505 - accuracy: 0.9821\n",
      " 8/14 [================>.............] - ETA: 0s - loss: 0.0971 - accuracy: 0.9727Epoch 28/50\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.0030 - accuracy: 1.0000A: 0s - loss: 0.0543 - accuracy: 0.98\n",
      "11/14 [======================>.......] - ETA: 0s - loss: 0.0343 - accuracy: 0.9943Epoch 26/50\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.1097 - accuracy: 0.9643\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.0384 - accuracy: 0.9911\n",
      "Epoch 14/50\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 0.1483 - accuracy: 0.9777 - 0s 21ms/step - loss: 0.1173 - accuracy: 0.9576\n",
      "Epoch 19/50\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.0421 - accuracy: 0.9866\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 1.3155 - accuracy: 0.3884\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.1033 - accuracy: 0.9911\n",
      "Epoch 22/50\n",
      "Epoch 4/50Epoch 26/50\n",
      "\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.1409 - accuracy: 0.9799\n",
      " 6/14 [===========>..................] - ETA: 0s - loss: 1.1189 - accuracy: 0.4271Epoch 29/50\n",
      "14/14 [==============================] - 0s 21ms/step - loss: 0.1019 - accuracy: 0.9688\n",
      "Epoch 20/50\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.0020 - accuracy: 1.0000A: 0s - loss: 0.0020 - accuracy: 1.00\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 0.1266 - accuracy: 0.9792Epoch 27/50\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.0491 - accuracy: 0.9866A: 0s - loss: 0.1323 - accuracy: 0.97\n",
      "Epoch 15/50\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.0144 - accuracy: 1.0000\n",
      "[CV 3/5] END ...epochs=50, layers=3, neurons=20;, score=1.000 total time=  22.8s\n",
      " 4/14 [=======>......................] - ETA: 0s - loss: 0.0016 - accuracy: 1.0000  \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:28:27.245682: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 35ms/step - loss: 0.0212 - accuracy: 0.9955\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.0939 - accuracy: 0.9933\n",
      "Epoch 23/50\n",
      "Epoch 27/50\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 1.0890 - accuracy: 0.4621\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 0.0346 - accuracy: 1.0000Epoch 5/50\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.0230 - accuracy: 0.9978\n",
      "Epoch 21/50\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.1498 - accuracy: 0.9710\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.0401 - accuracy: 0.9931Epoch 30/50\n",
      "14/14 [==============================] 4/14 [=======>......................] - 0s 30ms/step - loss: 0.0020 - accuracy: 1.0000\n",
      " - ETA: 0s - loss: 0.0079 - accuracy: 1.0000Epoch 28/50\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.0394 - accuracy: 0.9888A: 0s - loss: 0.0050 - accuracy: 1.00\n",
      " 5/14 [=========>....................] - ETA: 0s - loss: 7.3944e-04 - accuracy: 1.0000Epoch 16/50\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.0187 - accuracy: 0.9978\n",
      "Epoch 24/50\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.1127 - accuracy: 0.9821\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.0037 - accuracy: 1.0000\n",
      "Epoch 28/50\n",
      "Epoch 22/50\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.8697 - accuracy: 0.6094\n",
      "Epoch 6/50\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 8.3526e-04 - accuracy: 1.0000s - loss: 0.0167 - accuracy: 0.99\n",
      "Epoch 29/50\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.1391 - accuracy: 0.9554\n",
      "Epoch 31/\n",
      " 8/14 [================>.............] - ETA: 0s - loss: 0.1757 - accuracy: 0.9570Epoch 1/50 - loss: 0.0981 - accuracy: 0.9688: 0s - loss: 0.1623 - accuracy: 0.\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.0198 - accuracy: 0.9955\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 0.0014 - accuracy: 1.0000Epoch 17/50\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.0127 - accuracy: 0.9955\n",
      "Epoch 23/50\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.0342 - accuracy: 0.9955\n",
      "Epoch 25/50\n",
      " 1/14 [=>............................] - 0s 33ms/step - loss: 0.1759 - accuracy: 0.9576\n",
      " - ETA: 0s - loss: 0.0012 - accuracy: 1.0000Epoch 29/50\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.6514 - accuracy: 0.7612\n",
      " 8/14 [================>.............] - ETA: 0s - loss: 0.1138 - accuracy: 0.9492Epoch 7/50\n",
      " 4/14 [=======>......................] - 0s 28ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      " - ETA: 0s - loss: 0.0046 - accuracy: 1.0000Epoch 30/50\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.1128 - accuracy: 0.9643A: 0s - loss: 0.1461 - accuracy: 0.\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 0.0088 - accuracy: 1.0000Epoch 32/50\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.0101 - accuracy: 0.9978- loss: 0.0111 - accuracy: 0.9972 - ETA: 0s - loss: 0.0030 - accuracy: 1.0000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 18/50\n",
      "Epoch 24/50\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.1881 - accuracy: 0.9576\n",
      "Epoch 30/50\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      " 5/14 [=========>....................] - ETA: 0s - loss: 0.0253 - accuracy: 0.9938Epoch 31/50\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.0268 - accuracy: 0.9888\n",
      "Epoch 26/50\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.4385 - accuracy: 0.8348\n",
      "Epoch 8/50\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.0015 - accuracy: 1.0000A: 0s - loss: 0.0840 - accuracy: 0.97\n",
      "Epoch 25/50\n",
      "14/14 [==============================] - 1s 36ms/step - loss: 0.0958 - accuracy: 0.9688\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.0015 - accuracy: 1.0000Epoch 33/50\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.0652 - accuracy: 0.9844\n",
      "Epoch 19/50\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0040 - accuracy: 1.0000\n",
      "Epoch 32/50\n",
      "13/14 [==========================>...]14/14 [==============================] - ETA: 0s - loss: 0.1573 - accuracy: 0.9495 - 0s 31ms/step - loss: 0.0089 - accuracy: 0.9978\n",
      "Epoch 27/50\n",
      "14/14 [==============================] - 0s 36ms/step - loss: 0.1568 - accuracy: 0.9509\n",
      "12/14 [========================>.....] - ETA: 0s - loss: 0.0012 - accuracy: 1.0000Epoch 31/50\n",
      " 6/14 [===========>..................] - ETA: 0s - loss: 0.0396 - accuracy: 0.9740"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:28:29.470515: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 25ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.3404 - accuracy: 0.8534Epoch 26/50\n",
      "14/14 [==============================] - 0s 36ms/step - loss: 0.3389 - accuracy: 0.8527\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 4.8000e-04 - accuracy: 1.0000Epoch 9/50\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 0.0770 - accuracy: 0.9777- loss: 0.1459 - accuracy: 0.9554 - ETA: 0s - loss: 0.0018 - accuracy: 1.\n",
      " 8/14 [================>.............] - ETA: 0s - loss: 0.0080 - accuracy: 0.9961Epoch 34/50\n",
      " 7/14 [==============>...............] - 1s 40ms/step - loss: 0.0335 - accuracy: 0.9844\n",
      "11/14 [======================>.......] - ETA: 0s - loss: 0.1378 - accuracy: 0.9602Epoch 20/50\n",
      "14/14 [==============================] - 1s 44ms/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 33/50\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 27/50\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.1374 - accuracy: 0.9621\n",
      "Epoch 32/50\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 0.0088 - accuracy: 0.9955\n",
      "Epoch 28/50\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.2586 - accuracy: 0.8884\n",
      "Epoch 10/50\n",
      "14/14 [==============================] - 2s 36ms/step - loss: 1.5080 - accuracy: 0.3571\n",
      "Epoch 2/50\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.0119 - accuracy: 0.9978A: 0s - loss: 0.0012 - accuracy: 1.00\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 0.1812 - accuracy: 0.9107Epoch 21/50\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.0683 - accuracy: 0.9777\n",
      "Epoch 35/50\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.0017 - accuracy: 1.0000- loss: 0.0285 - accuracy: 1.0000 - ETA: 0s - loss: 0.0017 - accuracy: 1.00\n",
      "11/14 [======================>.......] - ETA: 0s - loss: 0.1163 - accuracy: 0.9716Epoch 34/50\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 28/50\n",
      "14/14 [==============================] - 1s 36ms/step - loss: 0.1115 - accuracy: 0.9732\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 5.5229e-04 - accuracy: 1.0000Epoch 33/50\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.1950 - accuracy: 0.9174\n",
      "Epoch 11/50\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 1.0996 - accuracy: 0.5580\n",
      " 8/14 [================>.............] - ETA: 0s - loss: 0.0059 - accuracy: 1.0000Epoch 3/50\n",
      "14/14 [==============================] - 1s 50ms/step - loss: 0.0016 - accuracy: 1.0000A: 0s - loss: 0.0567 - accuracy: 0.97\n",
      "Epoch 29/50\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.0043 - accuracy: 1.0000\n",
      "Epoch 22/50\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.0026 - accuracy: 1.0000\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0537 - accuracy: 0.9777Epoch 35/\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.0537 - accuracy: 0.9777\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 5.7674e-04 - accuracy: 1.0000Epoch 36/50\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 6.5123e-04 - accuracy: 1.0000\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.0690 - accuracy: 1.0000Epoch 29/50\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.6548 - accuracy: 0.7098\n",
      "Epoch 4/50\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.1899 - accuracy: 0.9308\n",
      "Epoch 12/50\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.0876 - accuracy: 0.9799\n",
      "Epoch 34/50\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 3.5988e-04 - accuracy: 1.0000\n",
      "14/14 [==============================] - 0s 36ms/step - loss: 0.0041 - accuracy: 1.0000\n",
      "Epoch 30/50\n",
      "Epoch 30/50\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 23/50\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.0474 - accuracy: 0.9799\n",
      "Epoch 37/50\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.3416 - accuracy: 0.8839- loss: 0.1104 - accuracy: 0.9688 - ETA: 0s - loss: 0.0439 - accuracy: 0.98\n",
      "14/14 [==============================] - 1s 46ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 36/50\n",
      "Epoch 5/50\n",
      "14/14 [==============================] - 0s 36ms/step - loss: 0.1236 - accuracy: 0.9554\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 3.7937e-04 - accuracy: 1.0000Epoch 13/50\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 0.0210 - accuracy: 0.9911\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.1065 - accuracy: 0.9665\n",
      "Epoch 35/50\n",
      "Epoch 31/50\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 3.5976e-04 - accuracy: 1.0000\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 0.1202 - accuracy: 0.9583Epoch 31/50\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.0371 - accuracy: 0.9821\n",
      "12/14 [========================>.....] - ETA: 0s - loss: 0.1644 - accuracy: 0.9427Epoch 38/50\n",
      "14/14 [==============================] - 1s 44ms/step - loss: 0.0066 - accuracy: 0.9978\n",
      "Epoch 24/50\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 37/50\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.1524 - accuracy: 0.9464\n",
      "Epoch 6/50\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.0841 - accuracy: 0.9732\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 3.5559e-04 - accuracy: 1.0000\n",
      "Epoch 14/50\n",
      "Epoch 32/50\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.0343 - accuracy: 0.9888\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 0.0089 - accuracy: 1.0000Epoch 32/50\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.1010 - accuracy: 0.9732\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 0.0562 - accuracy: 0.9777Epoch 36/50\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.0062 - accuracy: 1.0000\n",
      "Epoch 25/50\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.0571 - accuracy: 0.9754\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.1087 - accuracy: 0.9688Epoch 39/50\n",
      "14/14 [==============================] - 1s 36ms/step - loss: 0.1062 - accuracy: 0.9643- loss: 0.0306 - accuracy: 0.9896 - ETA: 0s - loss: 8.3151e-04 - accuracy: 1.0000\n",
      "Epoch 7/50\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 8.3186e-04 - accuracy: 1.0000\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.1182 - accuracy: 0.9688Epoch 38/50\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 4.1744e-04 - accuracy: 1.0000\n",
      "Epoch 33/50\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.0597 - accuracy: 0.9844\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 0.0798 - accuracy: 0.9688Epoch 33/50\n",
      "14/14 [==============================] - 0s 36ms/step - loss: 0.2324 - accuracy: 0.9375\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 0.0114 - accuracy: 0.9955Epoch 37/50\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.0860 - accuracy: 0.9777\n",
      "Epoch 15/50\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.0651 - accuracy: 0.9799 [====================>.........] - ETA: 0s - loss: 0.0593 - accuracy: 0.98\n",
      "Epoch 40/50\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.0607 - accuracy: 0.9821\n",
      "Epoch 8/50\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 39/50\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 2.7850e-04 - accuracy: 1.0000\n",
      "Epoch 34/50\n",
      "14/14 [==============================] - 1s 50ms/step - loss: 0.0067 - accuracy: 0.9978\n",
      "Epoch 26/50\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.9530 - accuracy: 0.8058\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.0014 - accuracy: 1.0000Epoch 34/50\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.2145 - accuracy: 0.9375\n",
      "Epoch 38/50\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.1286 - accuracy: 0.9531\n",
      "Epoch 16/50\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.0481 - accuracy: 0.9821A: 0s - loss: 0.0954 - accuracy: 0.97TA: 0s - loss: 0.4979 - accuracy: 0.78\n",
      " 5/14 [=========>....................] - ETA: 0s - loss: 0.0866 - accuracy: 0.9875Epoch 41/50\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.0552 - accuracy: 0.9866\n",
      "Epoch 9/50\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.0014 - accuracy: 1.0000- loss: 0.0172 - accuracy: 1.0000 - ETA: 0s - loss: 0.5549 - accuracy: 0.81\n",
      "Epoch 40/50\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 27/50\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.5346 - accuracy: 0.8237\n",
      " 4/14 [=======>......................] - ETA: 0s - loss: 0.0024 - accuracy: 1.0000Epoch 35/50\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 2.4929e-04 - accuracy: 1.0000\n",
      "Epoch 35/50\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.0920 - accuracy: 0.9799\n",
      "Epoch 39/50\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.1120 - accuracy: 0.9688\n",
      "Epoch 17/50\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.0020 - accuracy: 1.0000\n",
      "14/14 [==============================] - ETA: 0s - loss: 2.0845e-04 - accuracy: 1.0000Epoch 41/50\n",
      "14/14 [==============================] - 0s 19ms/step - loss: 2.0845e-04 - accuracy: 1.0000\n",
      "Epoch 36/50\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.0238 - accuracy: 0.9955\n",
      " 4/14 [=======>......................] - ETA: 0s - loss: 0.0596 - accuracy: 0.9766Epoch 10/50\n",
      "14/14 [==============================] - 0s 36ms/step - loss: 0.0384 - accuracy: 0.9888\n",
      "Epoch 42/50\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.0014 - accuracy: 1.0000- ETA: 0s - loss: 0.0879 - accuracy: 0.\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 0.0511 - accuracy: 0.9896Epoch 28/50\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.3081 - accuracy: 0.8839\n",
      "11/14 [======================>.......]Epoch 36/50\n",
      " - 0s 33ms/step - loss: 0.0628 - accuracy: 0.9821- loss: 4.0402e-04 - accuracy: 1.0000TA: 0s - loss: 0.1329 - accuracy: 0.\n",
      "11/14 [======================>.......] - ETA: 0s - loss: 0.0016 - accuracy: 1.0000Epoch 18/50\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.0662 - accuracy: 0.9821\n",
      "Epoch 40/50\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.1093 - accuracy: 0.9598- loss: 0.1682 - accuracy: 0.9271 - ETA: 0s - loss: 0.0189 - accuracy: 1.00: 1.00\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 4.2409e-04 - accuracy: 1.0000Epoch 11/50\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 42/50\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.0526 - accuracy: 0.9866\n",
      " 5/14 [=========>....................] - ETA: 0s - loss: 0.0865 - accuracy: 0.9812Epoch 43/50\n",
      "14/14 [==============================] - 1s 44ms/step - loss: 1.2713e-04 - accuracy: 1.0000 [======================>.......] - ETA: 0s - loss: 7.0678e-04 - accuracy: 1.00\n",
      "Epoch 37/50\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 9.4887e-04 - accuracy: 1.0000ss: 0.1049 - accuracy: 0.9583 - ETA: 0s - loss: 8.7360e-04 - accuracy: 1.00\n",
      "Epoch 29/50\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.1484 - accuracy: 0.9353\n",
      "Epoch 37/50\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.0221 - accuracy: 0.9955\n",
      "Epoch 19/50\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.0845 - accuracy: 0.9777\n",
      "Epoch 41/50\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 0.0147 - accuracy: 1.0000Epoch 43/50\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 2.0648e-04 - accuracy: 1.0000\n",
      "Epoch 38/50\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.0882 - accuracy: 0.9643\n",
      "Epoch 12/50\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.0533 - accuracy: 0.9799\n",
      " 6/14 [===========>..................] - ETA: 0s - loss: 0.0855 - accuracy: 0.9635Epoch 44/50\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 9.3414e-04 - accuracy: 1.0000\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.1522 - accuracy: 0.9135Epoch 30/50\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.1586 - accuracy: 0.9107\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.0133 - accuracy: 1.0000Epoch 38/50\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.0514 - accuracy: 0.9799\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 2.7679e-04 - accuracy: 1.0000Epoch 13/50\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 2.8267e-04 - accuracy: 1.0000\n",
      "Epoch 39/50\n",
      "14/14 [==============================] - 1s 36ms/step - loss: 0.0110 - accuracy: 1.0000\n",
      "Epoch 20/50\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.1194 - accuracy: 0.9621\n",
      "Epoch 42/50\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.0337 - accuracy: 0.9844Epoch 44/50\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.0329 - accuracy: 0.9866A: 0s - loss: 0.1494 - accuracy: 0.\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 7.2828e-04 - accuracy: 1.0000Epoch 45/50\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.1339 - accuracy: 0.9308\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 6.7171e-04 - accuracy: 1.0000Epoch 39/50\n",
      " - 1s 38ms/step - loss: 6.4074e-04 - accuracy: 1.0000ss: 0.2642 - accuracy: 0.841.0000\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 3.3293e-04 - accuracy: 1.0000\n",
      "Epoch 31/50\n",
      "Epoch 40/50\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0139 - accuracy: 0.9978\n",
      "Epoch 14/50\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.2181 - accuracy: 0.9509- loss: 0.1409 - accuracy: 0.9187 - ETA: 0s - loss: 0.0270 - accuracy: 0.98\n",
      "Epoch 43/50\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.0107 - accuracy: 1.0000\n",
      "Epoch 21/50\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 45/50\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.0346 - accuracy: 0.9844\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.0012 - accuracy: 1.0000Epoch 46/50\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 1.4193e-04 - accuracy: 1.0000\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 4.9380e-04 - accuracy: 1.0000Epoch 41/50ss: 0.0795 - accuracy: 0.98\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.1363 - accuracy: 0.9152\n",
      "Epoch 40/50\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.0062 - accuracy: 1.0000A: 0s - loss: 0.0939 - accuracy: 0.930.\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 9.3750e-04 - accuracy: 1.0000\n",
      "Epoch 15/50\n",
      "Epoch 32/50\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.0038 - accuracy: 1.0000A: 0s - loss: 3.7818e-04 - accuracy: 1.00\n",
      "Epoch 22/50\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 7.3083e-04 - accuracy: 1.0000\n",
      "Epoch 46/50\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.1166 - accuracy: 0.9688\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 9.5244e-04 - accuracy: 1.0000Epoch 44/50\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 2.6554e-04 - accuracy: 1.0000\n",
      "Epoch 42/50\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.1284 - accuracy: 0.9219- ETA: 0s - loss: 0.0193 - accuracy: 1.00\n",
      "Epoch 41/50\n",
      "14/14 [==============================] - 1s 36ms/step - loss: 0.0425 - accuracy: 0.9888\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 1.1482e-04 - accuracy: 1.0000Epoch 47/50\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.0208 - accuracy: 0.9888- ETA: 0s - loss: 0.0212 - accuracy: 0.98\n",
      " 6/14 [===========>..................] - ETA: 0s - loss: 1.4733e-04 - accuracy: 1.0000Epoch 16/50\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 8.2325e-04 - accuracy: 1.0000\n",
      " 8/14 [================>.............] - ETA: 0s - loss: 8.3225e-04 - accuracy: 1.0000Epoch 33/50\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 0.0058 - accuracy: 0.9978\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 43/50\n",
      "Epoch 23/50\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0686 - accuracy: 0.9777\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.0129 - accuracy: 0.9965Epoch 47/50\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.1494 - accuracy: 0.9219\n",
      "14/14 [==============================] - 1s 36ms/step - loss: 0.1225 - accuracy: 0.9754\n",
      "Epoch 42/50\n",
      "Epoch 45/50\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 0.0336 - accuracy: 0.9911\n",
      "Epoch 17/50\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.0448 - accuracy: 0.9866 [=========>....................] - ETA: 0s - loss: 0.0081 - accuracy: 0.99\n",
      "Epoch 48/50\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.0016 - accuracy: 1.0000- loss: 0.0066 - accuracy: 0.9955 - ETA: 0s - loss: 0.0123 - accuracy: 1.00\n",
      "Epoch 34/50\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 0.0050 - accuracy: 1.0000- loss: 0.0894 - accuracy: 0.9438 - ETA: 0s - loss: 0.0606 - accuracy: 0.98\n",
      " 5/14 [=========>....................] - ETA: 0s - loss: 0.1032 - accuracy: 0.9750Epoch 44/50\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 0.0713 - accuracy: 0.9754\n",
      "Epoch 48/50 1/14 [=>............................]\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.0049 - accuracy: 0.9978A: 0s - loss: 0.1129 - accuracy: 0.94\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 0.0830 - accuracy: 0.9479Epoch 24/50\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.1212 - accuracy: 0.9643\n",
      "Epoch 18/50\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.1402 - accuracy: 0.9263\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.0647 - accuracy: 0.9688Epoch 43/50\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.1111 - accuracy: 0.9732\n",
      "Epoch 46/50\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.1422 - accuracy: 0.9576\n",
      "12/14 [========================>.....] - ETA: 0s - loss: 0.0010 - accuracy: 1.0000Epoch 49/50\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.0218 - accuracy: 0.9911\n",
      " 5/14 [=========>....................] - ETA: 0s - loss: 0.1537 - accuracy: 0.9250Epoch 45/50\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 35/50\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.0407 - accuracy: 0.9821\n",
      "Epoch 49/50\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.0345 - accuracy: 0.9888\n",
      "Epoch 19/50\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.0057 - accuracy: 1.0000\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.0896 - accuracy: 0.9757Epoch 25/50\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.1223 - accuracy: 0.9442A: 0s - loss: 0.0563 - accuracy: 0.97\n",
      "Epoch 44/50\n",
      "14/14 [==============================] - 0s 23ms/step - loss: 0.1274 - accuracy: 0.9665\n",
      "Epoch 46/50\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.0978 - accuracy: 0.9665A: 0s - loss: 0.0774 - accuracy: 0.96\n",
      "Epoch 47/50\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 5.0338e-04 - accuracy: 1.0000\n",
      "Epoch 36/50\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.0828 - accuracy: 0.9665\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.1627 - accuracy: 0.9420\n",
      "Epoch 50/50\n",
      " 8/14 [================>.............] - ETA: 0s - loss: 0.0706 - accuracy: 0.9805Epoch 50/50\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0064 - accuracy: 1.0000A: 0s - loss: 0.1325 - accuracy: 0.9500\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 0.0125 - accuracy: 1.0000Epoch 20/50\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.0021 - accuracy: 1.0000- ETA: 0s - loss: 0.1162 - accuracy: 0.94\n",
      "Epoch 26/50\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 0.0436 - accuracy: 0.9888\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.1318 - accuracy: 0.9464\n",
      "Epoch 47/50\n",
      "Epoch 45/50\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.0829 - accuracy: 0.9732- ETA: 0s - loss: 0.0021 - accuracy: 1.00\n",
      "Epoch 48/50\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.0828 - accuracy: 0.9665\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 3.0506e-04 - accuracy: 1.0000\n",
      "Epoch 37/50\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.0711 - accuracy: 0.9643\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.0113 - accuracy: 0.9955\n",
      "Epoch 21/50\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0050 - accuracy: 1.0000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0988 - accuracy: 0.9509\n",
      "Epoch 48/50\n",
      "Epoch 46/50\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      " 5/14 [=========>....................] - ETA: 0s - loss: 0.0558 - accuracy: 0.9750Epoch 27/50\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.0594 - accuracy: 0.9821A: 0s - loss: 0.0011 - accuracy: 1.00\n",
      "Epoch 49/50\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 4.0325e-04 - accuracy: 1.0000\n",
      "12/14 [========================>.....] - ETA: 0s - loss: 9.6274e-04 - accuracy: 1.0000Epoch 38/50\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 9.3528e-04 - accuracy: 1.0000\n",
      "11/14 [======================>.......]\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.0011 - accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:28:38.673093: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-01-09 14:28:38.694882: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 35ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.0038 - accuracy: 1.0000Epoch 28/50\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.1457 - accuracy: 0.9263\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.0036 - accuracy: 1.0000\n",
      "Epoch 47/50\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.0084 - accuracy: 1.0000Epoch 22/50\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.0261 - accuracy: 0.99110\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.0074 - accuracy: 1.0000\n",
      "[CV 1/5] END ...epochs=50, layers=3, neurons=40;, score=0.991 total time=  25.3s\n",
      "[CV 4/5] END ...epochs=50, layers=3, neurons=20;, score=1.000 total time=  27.9s\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 4.0056e-04 - accuracy: 1.0000\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.0012 - accuracy: 1.0000Epoch 50/50\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.0041 - accuracy: 1.0000\n",
      "Epoch 39/50\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.0614 - accuracy: 0.9777\n",
      "12/14 [========================>.....] - ETA: 0s - loss: 0.1112 - accuracy: 0.9583Epoch 50/50\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0064 - accuracy: 0.9978\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 4.1010e-04 - accuracy: 1.0000Epoch 29/50\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.1098 - accuracy: 0.9576\n",
      "Epoch 48/50\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.0011 - accuracy: 1.0000A: 0s - loss: 0.1105 - accuracy: 0.97\n",
      "Epoch 23/50\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 3.1676e-04 - accuracy: 1.0000\n",
      " - 0s 33ms/step - loss: 0.0035 - accuracy: 1.0000================>.........] - ETA: 0s - loss: 0.0033 - accuracy: 1.0000 - ETA: 0s - loss: 0.1345 - accuracy: 0.94\n",
      "11/14 [======================>.......] - ETA: 0s - loss: 0.0066 - accuracy: 1.0000Epoch 40/50\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.0715 - accuracy: 0.9821\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.1250 - accuracy: 0.9531\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 8.5896e-04 - accuracy: 1.0000\n",
      "Epoch 49/50\n",
      "Epoch 24/50\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.0103 - accuracy: 0.9955\n",
      "Epoch 30/50\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.3183 - accuracy: 0.9308A: 0s - loss: 4.3125e-04 - accuracy: 1.\n",
      "Epoch 41/50\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 5.6448e-04 - accuracy: 1.0000\n",
      "Epoch 25/50\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.0082 - accuracy: 0.9955\n",
      "14/14 [==============================] - 0s 36ms/step - loss: 0.0819 - accuracy: 0.9710\n",
      "Epoch 50/50\n",
      "Epoch 31/50\n",
      " 8/14 [================>.............] - ETA: 0s - loss: 4.8436e-04 - accuracy: 1.0000 - loss: 0.0672 - accuracy: 1.0000 - ETA: 0s - loss: 0.3639 - accuracy: 0.87"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:28:40.329293: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-01-09 14:28:40.366712: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 35ms/step - loss: 0.2889 - accuracy: 0.8951\n",
      "Epoch 42/50\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 5.6933e-04 - accuracy: 1.0000\n",
      "Epoch 26/50\n",
      "4/4 [==============================] - 1s 51ms/step - loss: 0.0499 - accuracy: 0.9911\n",
      "[CV 5/5] END ...epochs=50, layers=3, neurons=20;, score=0.991 total time=  28.5s\n",
      "4/4 [==============================] - 1s 66ms/step - loss: 2.4683e-05 - accuracy: 1.0000\n",
      "[CV 3/5] END ...epochs=50, layers=3, neurons=40;, score=1.000 total time=  22.4s\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.0120 - accuracy: 0.9955\n",
      " 5/14 [=========>....................] - ETA: 0s - loss: 0.2103 - accuracy: 0.9250Epoch 32/50\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.0579 - accuracy: 0.9844\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 0.1309 - accuracy: 0.9554\n",
      "Epoch 43/50\n",
      "14/14 [==============================] - 0s 22ms/step - loss: 8.1077e-04 - accuracy: 1.0000\n",
      "Epoch 27/50\n",
      "14/14 [==============================] - 0s 23ms/step - loss: 0.0031 - accuracy: 1.0000\n",
      "Epoch 33/50\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 6.3997e-04 - accuracy: 1.0000Epoch 1/50\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 6.0082e-04 - accuracy: 1.0000\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 0.0035 - accuracy: 1.0000    Epoch 28/50\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.0505 - accuracy: 0.9799\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.0028 - accuracy: 1.0000Epoch 44/50\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.0028 - accuracy: 1.000000Epoch 1/50\n",
      "14/14 [==============================] - 1s 47ms/step - loss: 0.0026 - accuracy: 1.0000\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 4.7447e-04 - accuracy: 1.0000Epoch 34/50\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 8.7234e-04 - accuracy: 1.0000\n",
      "Epoch 29/50\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 0.0095 - accuracy: 0.995500"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:28:41.918229: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-01-09 14:28:41.984016: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 1s 50ms/step - loss: 0.0172 - accuracy: 0.9955\n",
      "Epoch 45/50\n",
      "14/14 [==============================] - 1s 44ms/step - loss: 0.0092 - accuracy: 0.9978\n",
      "Epoch 35/50\n",
      "4/4 [==============================] - 1s 62ms/step - loss: 0.0638 - accuracy: 0.9911ETA: 0s - loss: 8.6532e-04 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 43ms/step - loss: 8.1105e-04 - accuracy: 1.0000\n",
      "Epoch 30/50\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.0144 - accuracy: 0.9933\n",
      " 4/14 [=======>......................] - ETA: 0s - loss: 5.5578e-04 - accuracy: 1.0000Epoch 46/50\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.0123 - accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:28:42.460438: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 8/14 [================>.............] - ETA: 0s - loss: 1.5434 - accuracy: 0.3516[CV 2/5] END ...epochs=50, layers=3, neurons=40;, score=0.991 total time=  27.4s\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.0111 - accuracy: 0.9978\n",
      "Epoch 36/50\n",
      "14/14 [==============================] - 2s 38ms/step - loss: 1.4968 - accuracy: 0.3705\n",
      "12/14 [========================>.....] - ETA: 0s - loss: 7.3207e-04 - accuracy: 1.0000Epoch 2/50\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 6.5511e-04 - accuracy: 1.0000\n",
      "Epoch 31/50\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.0155 - accuracy: 0.9955A: 0s - loss: 0.0412 - accuracy: 0.98\n",
      "12/14 [========================>.....] - ETA: 0s - loss: 0.0319 - accuracy: 0.9896Epoch 1/50\n",
      "Epoch 47/50\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.0023 - accuracy: 1.0000Epoch 1/50\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.0291 - accuracy: 0.9911\n",
      "Epoch 37/50\n",
      "14/14 [==============================] - 2s 34ms/step - loss: 1.5486 - accuracy: 0.3549- ETA: 0s - loss: 1.3499 - accuracy: 0.\n",
      "Epoch 2/50\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 1.2824 - accuracy: 0.4710\n",
      "Epoch 3/50\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 5.4276e-04 - accuracy: 1.0000\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 1.0921 - accuracy: 0.6562Epoch 32/50\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.0047 - accuracy: 1.0000ETA: 0s - loss: 0.0546 - accuracy: 0.97\n",
      " 8/14 [================>.............] - ETA: 0s - loss: 0.9028 - accuracy: 0.7109Epoch 48/50\n",
      " 8/14 [================>.............] - ETA: 0s - loss: 4.6009e-04 - accuracy: 1.0000\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:28:43.535722: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-01-09 14:28:43.559932: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 1s 36ms/step - loss: 0.0433 - accuracy: 0.9799\n",
      "Epoch 38/50\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 1.3339 - accuracy: 0.4018\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.7947 - accuracy: 0.7254\n",
      "Epoch 3/50\n",
      "Epoch 4/50\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 4.2319e-04 - accuracy: 1.0000A: 0s - loss: 0.0222 - accuracy: 0.99\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 1.0753 - accuracy: 0.6250Epoch 33/50\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.0030 - accuracy: 1.0000 [===========>..................] - ETA: 0s - loss: 1.5479 - accuracy: 0.\n",
      " 8/14 [================>.............] - ETA: 0s - loss: 4.7525e-04 - accuracy: 1.0000Epoch 49/50\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.0323 - accuracy: 0.9888\n",
      "Epoch 39/50..........................] - ETA: 0s - loss: 0.0024 - accuracy: 1.00\n",
      "Epoch 1/75>..........................] - ETA: 0s - loss: 0.0019 - accuracy: 1.0000   ETA: 0s - loss: 0.3634 - accuracy: 0.86\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.8303 - accuracy: 0.6987\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.3393 - accuracy: 0.8817\n",
      "Epoch 4/50\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 0.1124 - accuracy: 0.9583Epoch 5/50\n",
      "14/14 [==============================] - 1s 35ms/step - loss: 0.0010 - accuracy: 1.0000\n",
      " 5/14 [=========>....................] - ETA: 0s - loss: 0.0018 - accuracy: 1.0000Epoch 34/50\n",
      "14/14 [==============================] - 1s 51ms/step - loss: 1.4750 - accuracy: 0.3661\n",
      "Epoch 2/50\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 1.5626 - accuracy: 0.3237\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 0.2631 - accuracy: 0.9375Epoch 2/50\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.0014 - accuracy: 1.0000A: 0s - loss: 0.1775 - accuracy: 0.95\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.0720 - accuracy: 0.9808Epoch 50/50\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.0692 - accuracy: 0.9821\n",
      "11/14 [======================>.......] - ETA: 0s - loss: 1.4232 - accuracy: 0.4091Epoch 40/50\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.1609 - accuracy: 0.9621\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 35/50\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.3655 - accuracy: 0.8996\n",
      "Epoch 6/50\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.0012 - accuracy: 1.0000Epoch 5/50\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 1.4160 - accuracy: 0.4107\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 1.1216 - accuracy: 0.6034Epoch 3/50\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 1.1040 - accuracy: 0.6138\n",
      "Epoch 3/50\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.0017 - accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:28:45.114139: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 31ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0761 - accuracy: 0.9799\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 1.0796 - accuracy: 0.5781\n",
      "Epoch 41/50\n",
      "Epoch 4/50\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 9.3297e-04 - accuracy: 1.0000\n",
      "Epoch 36/50\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.5035 - accuracy: 0.8594\n",
      "Epoch 4/50\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.0840 - accuracy: 0.9799\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.2095 - accuracy: 0.9375\n",
      "Epoch 7/50\n",
      "Epoch 6/50\n",
      " 8/14 [================>.............] - ETA: 0s - loss: 0.0953 - accuracy: 0.96880000TA: 0s - loss: 0.4705 - accuracy: 0.80"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:28:45.576992: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 30ms/step - loss: 0.0791 - accuracy: 0.9665A: 0s - loss: 0.3104 - accuracy: 0.88\n",
      "Epoch 42/50\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.6715 - accuracy: 0.7634\n",
      "Epoch 5/50\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 8.1360e-04 - accuracy: 1.0000\n",
      "Epoch 37/50\n",
      "10/14 [====================>.........]14/14 [==============================] - 0s 29ms/step - loss: 0.0877 - accuracy: 0.9710\n",
      " - ETA: 0s - loss: 1.5634 - accuracy: 0.3281Epoch 7/50\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.0470 - accuracy: 0.9888A: 0s - loss: 1.8965e-04 - accuracy: 1.00\n",
      "Epoch 8/50\n",
      "14/14 [==============================] - 1s 45ms/step - loss: 0.2409 - accuracy: 0.9063A: 0s - loss: 1.5273 - accuracy: 0.34\n",
      "14/14 [==============================] - 2s 31ms/step - loss: 1.5273 - accuracy: 0.3482\n",
      "Epoch 5/50\n",
      "4/4 [==============================]Epoch 2/75\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 0.0027 - accuracy: 1.0000\n",
      "[CV 4/5] END ...epochs=50, layers=3, neurons=40;, score=1.000 total time=  27.0s\n",
      "14/14 [==============================] - 0s 23ms/step - loss: 0.4055 - accuracy: 0.8571A: 0s - loss: 0.4055 - accuracy: 0.8571\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 4.3766e-04 - accuracy: 1.0000Epoch 6/50\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.2324 - accuracy: 0.9196\n",
      "Epoch 43/50\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 4.7669e-04 - accuracy: 1.0000\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.0355 - accuracy: 0.9938Epoch 38/50\n",
      "14/14 [==============================] 3/14 [=====>........................] - 0s 31ms/step - loss: 0.0814 - accuracy: 0.9710\n",
      "12/14 [========================>.....] - ETA: 0s - loss: 0.0333 - accuracy: 0.9948Epoch 8/50\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0301 - accuracy: 0.9955\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 0.3543 - accuracy: 0.8527Epoch 9/50\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.1314 - accuracy: 0.9643\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 0.0188 - accuracy: 1.0000Epoch 6/50\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 1.3644 - accuracy: 0.4152\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 6.3645e-04 - accuracy: 1.0000 - ETA: 0s - loss: 0.3189 - accuracy: 0.8672Epoch 3/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.3089 - accuracy: 0.8750A: 0s - loss: 0.4574 - accuracy: 0.84\n",
      "Epoch 7/50\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 4.8447e-04 - accuracy: 1.0000\n",
      "Epoch 39/50\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.3449 - accuracy: 0.8728\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 0.2150 - accuracy: 0.9107Epoch 44/50\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.0579 - accuracy: 0.9821\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.0692 - accuracy: 0.9757Epoch 9/50\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.1213 - accuracy: 0.9554\n",
      "Epoch 10/50\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 0.2203 - accuracy: 0.9241\n",
      "Epoch 8/50\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0637 - accuracy: 0.9777\n",
      " 5/14 [=========>....................] - ETA: 0s - loss: 0.0367 - accuracy: 0.9875Epoch 7/50\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 1.1210 - accuracy: 0.4487\n",
      " 6/14 [===========>..................] - ETA: 0s - loss: 0.1395 - accuracy: 0.9375Epoch 4/75\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 3.3010e-04 - accuracy: 1.0000s - loss: 2.6602e-04 - accuracy: 1.00\n",
      "Epoch 40/50\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.0942 - accuracy: 0.9598A: 0s - loss: 7.8906e-04 - accuracy: 1.00\n",
      "Epoch 45/50\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.0525 - accuracy: 0.9844\n",
      "Epoch 10/50\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.3516 - accuracy: 0.8862 - 0s 28ms/step - loss: 0.1663 - accuracy: 0.9397\n",
      "14/14 [==============================] - 0s 36ms/step - loss: 0.3516 - accuracy: 0.8862\n",
      "Epoch 11/50\n",
      "11/14 [======================>.......] - ETA: 0s - loss: 0.8652 - accuracy: 0.5398Epoch 9/50\n",
      "Epoch 1/75\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.8701 - accuracy: 0.5513A: 0s - loss: 0.2822 - accuracy: 0.84\n",
      "Epoch 5/75\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.0353 - accuracy: 0.9933\n",
      "Epoch 8/50\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 9.2423e-04 - accuracy: 1.0000\n",
      "Epoch 41/50\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.0403 - accuracy: 0.9866\n",
      " 5/14 [=========>....................] - ETA: 0s - loss: 0.0233 - accuracy: 0.9938Epoch 46/50\n",
      "14/14 [==============================] - 0s 24ms/step - loss: 0.1368 - accuracy: 0.9509\n",
      " 4/14 [=======>......................] - ETA: 0s - loss: 0.0472 - accuracy: 0.9844Epoch 10/50\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.0487 - accuracy: 0.9821\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 1.5401e-04 - accuracy: 1.0000Epoch 11/50\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.1390 - accuracy: 0.9308\n",
      " 4/14 [=======>......................] - ETA: 0s - loss: 0.1053 - accuracy: 0.9688Epoch 12/50\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.7403 - accuracy: 0.6562\n",
      " 8/14 [================>.............] - ETA: 0s - loss: 0.0284 - accuracy: 0.9922Epoch 6/75\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0111 - accuracy: 0.9978\n",
      "Epoch 9/50\n",
      " - 0s 29ms/step - loss: 1.5049e-04 - accuracy: 1.0000\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.0273 - accuracy: 0.9938Epoch 42/50\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.0242 - accuracy: 0.9933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:28:47.866132: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/50\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.0913 - accuracy: 0.9688- loss: 0.0913 - accuracy: 0.9688 - ETA: 0s - loss: 4.2798e-04 - accuracy: 1.00\n",
      "Epoch 12/50\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 3.7022e-04 - accuracy: 1.0000s - loss: 0.0069 - accuracy: 1.000.\n",
      "Epoch 43/50\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0038 - accuracy: 1.0000\n",
      "Epoch 10/50\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.1049 - accuracy: 0.9621\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 1.2272e-04 - accuracy: 1.0000Epoch 11/50\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.0422 - accuracy: 0.9911- ETA: 11s - loss: 1.6834 - accuracy: 0.1562\n",
      "Epoch 13/50\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.6294 - accuracy: 0.7299- loss: 0.0082 - accuracy: 1.0000 - ETA: 0s - loss: 0.6340 - accuracy: 0.72\n",
      "Epoch 7/75\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.0073 - accuracy: 1.0000\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 0.0061 - accuracy: 1.0000Epoch 48/50\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.0357 - accuracy: 0.9933\n",
      "Epoch 13/50\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 1.8045e-04 - accuracy: 1.0000==============>.............] - ETA: 0s - loss: 1.6568 - accuracy: 0.27\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.1082 - accuracy: 0.9643\n",
      "Epoch 44/50\n",
      "Epoch 12/50\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.0077 - accuracy: 1.0000A: 0s - loss: 0.1084 - accuracy: 0.9375 - ETA: 0s - loss: 1.6509 - accuracy: 0.29\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 1.5783e-04 - accuracy: 1.0000Epoch 11/50\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.0144 - accuracy: 0.9955\n",
      "Epoch 14/50\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.5164 - accuracy: 0.7879A: 0s - loss: 0.5243 - accuracy: 0.78\n",
      "Epoch 8/75\n",
      "14/14 [==============================] - 2s 53ms/step - loss: 1.6348 - accuracy: 0.2969\n",
      "11/14 [======================>.......] - ETA: 0s - loss: 0.0113 - accuracy: 1.0000Epoch 2/75\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.0063 - accuracy: 1.0000\n",
      "Epoch 49/50\n",
      "14/14 [==============================] - 0s 36ms/step - loss: 0.0096 - accuracy: 1.0000\n",
      "Epoch 14/50\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 1.6224e-04 - accuracy: 1.0000s - loss: 0.0450 - accuracy: 1.00\n",
      "Epoch 45/50\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.0787 - accuracy: 0.9688 [================>.............] - ETA: 0s - loss: 0.0069 - accuracy: 1.0000\n",
      "Epoch 13/50\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.0268 - accuracy: 0.9933A: 0s - loss: 0.0063 - accuracy: 1.00\n",
      "Epoch 12/50\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.0062 - accuracy: 1.0000- loss: 0.0099 - accuracy: 1.0000 - ETA: 0s - loss: 0.0055 - accuracy: 1.00\n",
      "Epoch 15/50\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.3907 - accuracy: 0.8482\n",
      " - 0s 35ms/step - loss: 0.0051 - accuracy: 1.0000\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 1.5609e-04 - accuracy: 1.0000Epoch 50/50Epoch 9/75\n",
      "\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 1.5216 - accuracy: 0.3304\n",
      "Epoch 3/75\n",
      "14/14 [==============================] - 1s 43ms/step - loss: 0.0070 - accuracy: 1.0000- ETA: 0s - loss: 0.0083 - accuracy: 1.\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 1.4880 - accuracy: 0.3958Epoch 15/50\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 2.3299e-04 - accuracy: 1.0000s - loss: 2.3299e-04 - accuracy: 1.00\n",
      "Epoch 46/50\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.0979 - accuracy: 0.9509\n",
      "Epoch 14/50\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.2559 - accuracy: 0.9286\n",
      "Epoch 13/50\n",
      "14/14 [==============================] - 1s 46ms/step - loss: 0.0037 - accuracy: 1.0000\n",
      "Epoch 16/50\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.3538 - accuracy: 0.8929\n",
      "Epoch 10/75\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 1.4629 - accuracy: 0.3772\n",
      "Epoch 4/75\n",
      "14/14 [==============================] - 1s 49ms/step - loss: 0.0040 - accuracy: 1.0000\n",
      "14/14 [==============================] - 0s 36ms/step - loss: 1.1416e-04 - accuracy: 1.0000ss: 1.4787 - accuracy: 0.3281 - ETA: 0s - loss: 0.0830 - accuracy: 0.96\n",
      "Epoch 47/50\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.0020 - accuracy: 1.0000\n",
      " 5/14 [=========>....................] - ETA: 0s - loss: 0.3862 - accuracy: 0.8750Epoch 16/50\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.0790 - accuracy: 0.9665ETA: 0s - loss: 0.0026 - accuracy: 1.00\n",
      " 6/14 [===========>..................]Epoch 15/50\n",
      " 8/14 [================>.............] - ETA: 0s - loss: 0.0029 - accuracy: 1.000000 ETA: 0s - loss: 0.0024 - accuracy: 1.00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:28:50.362495: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 1s 38ms/step - loss: 0.1763 - accuracy: 0.9353\n",
      "Epoch 14/50\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.3433 - accuracy: 0.937514/14 [==============================] - 1s 37ms/step - loss: 0.3551 - accuracy: 0.8884\n",
      " - 1s 39ms/step - loss: 0.0048 - accuracy: 0.9978\n",
      "Epoch 17/50\n",
      "Epoch 11/75\n",
      "14/14 [==============================] - 0s 36ms/step - loss: 1.3866 - accuracy: 0.3594\n",
      "Epoch 5/75\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 1.3334e-04 - accuracy: 1.0000\n",
      "Epoch 48/50\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.0042 - accuracy: 1.0000\n",
      " 5/14 [=========>....................] - ETA: 0s - loss: 0.0380 - accuracy: 0.9875Epoch 17/50\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.1270 - accuracy: 0.9732\n",
      "[CV 5/5] END ...epochs=50, layers=3, neurons=40;, score=0.973 total time=  26.6s\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0649 - accuracy: 0.9710\n",
      "Epoch 16/50\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.0261 - accuracy: 0.9911\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.3452 - accuracy: 0.8894Epoch 15/50\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.3440 - accuracy: 0.8951A: 0s - loss: 2.3754e-04 - accuracy: 1.00\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.0334 - accuracy: 1.0000Epoch 12/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 2.1055e-04 - accuracy: 1.0000\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.0930 - accuracy: 0.9653Epoch 49/50\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.0034 - accuracy: 1.0000\n",
      "Epoch 18/50\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.0043 - accuracy: 1.0000\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 1.2893 - accuracy: 0.3705\n",
      "Epoch 18/50\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 2.1671e-04 - accuracy: 1.0000Epoch 6/75\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.0849 - accuracy: 0.9665\n",
      "Epoch 17/50\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.3141 - accuracy: 0.8996\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 1.2292 - accuracy: 0.4250Epoch 13/75\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.0242 - accuracy: 0.9933\n",
      "Epoch 16/50\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 9.2411e-05 - accuracy: 1.0000s - loss: 0.0020 - accuracy: 1.00\n",
      "Epoch 50/50\n",
      "14/14 [==============================] - 0s 24ms/step - loss: 0.0566 - accuracy: 0.9732\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.0024 - accuracy: 1.0000\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 1.2213 - accuracy: 0.4375\n",
      "Epoch 18/50\n",
      "Epoch 19/50\n",
      "Epoch 7/75\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.0033 - accuracy: 1.0000- ETA: 0s - loss: 0.0694 - accuracy: 0.9688\n",
      "Epoch 19/50\n",
      " 5/14 [=========>....................] - ETA: 0s - loss: 0.0193 - accuracy: 0.9938Epoch 1/75: 0s - loss: 0.2873 - accuracy: 0.88\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.3174 - accuracy: 0.8973\n",
      "Epoch 14/75\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "14/14 [==============================] - 1s 36ms/step - loss: 0.0175 - accuracy: 0.9955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:28:51.746871: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 17/50\n",
      "Epoch 20/50\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.0574 - accuracy: 0.9754\n",
      "Epoch 19/50\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 1.1495 - accuracy: 0.4866\n",
      "12/14 [========================>.....] - ETA: 0s - loss: 0.0025 - accuracy: 1.0000Epoch 8/75\n",
      "14/14 [==============================] 3/14 [=====>........................] - 0s 36ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      " - ETA: 0s - loss: 5.9631e-04 - accuracy: 1.0000Epoch 20/50\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 0.0455 - accuracy: 0.9844\n",
      "Epoch 20/50\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.2618 - accuracy: 0.9308\n",
      "11/14 [======================>.......] - ETA: 0s - loss: 0.0110 - accuracy: 0.9972Epoch 15/75\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 1.6392 - accuracy: 0.3281"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:28:52.136063: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 31ms/step - loss: 6.3898e-05 - accuracy: 1.0000 0s - loss: 6.3898e-05 - accuracy: 1.00\n",
      "[CV 1/5] END ...epochs=50, layers=3, neurons=60;, score=1.000 total time=  24.6s\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 1.1072 - accuracy: 0.4933\n",
      "Epoch 9/75\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.0015 - accuracy: 1.0000- loss: 1.6092 - accuracy: 0.3464 - ETA: 0s - loss: 1.0227 - accuracy: 0.50\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.0118 - accuracy: 0.9955\n",
      "Epoch 21/50\n",
      "Epoch 18/50\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 1.5924 - accuracy: 0.3504\n",
      "Epoch 2/75\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 21/50\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.0657 - accuracy: 0.9688A: 0s - loss: 0.2739 - accuracy: 0.92\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 1.1458 - accuracy: 0.4583Epoch 21/50\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.2771 - accuracy: 0.9241A: 0s - loss: 1.1506 - accuracy: 0.46\n",
      "Epoch 16/75\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 8.4581e-04 - accuracy: 1.0000\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.0022 - accuracy: 1.0000Epoch 22/50\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 1.1497 - accuracy: 0.4554\n",
      "Epoch 10/75\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.0101 - accuracy: 0.9978\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 1.4256 - accuracy: 0.4094Epoch 19/50\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.0029 - accuracy: 1.0000\n",
      "Epoch 22/50\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 1.4174 - accuracy: 0.3973\n",
      "Epoch 3/75\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.0542 - accuracy: 0.9754\n",
      "Epoch 22/50\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.2331 - accuracy: 0.9464\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.0033 - accuracy: 1.0000Epoch 17/75\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 1.1384 - accuracy: 0.4509\n",
      "14/14 [==============================] - 1s 36ms/step - loss: 8.6160e-04 - accuracy: 1.0000\n",
      "Epoch 23/50\n",
      "Epoch 11/75\n",
      "Epoch 1/75 - loss: 0.2298 - accuracy: 0.9479 1/14 [=>............................] - ETA: 0s - loss: 0.0038 - accuracy: 1.0000\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.0025 - accuracy: 1.0000013/14 [==========================>...] - ETA: 0s - loss: 0.0018 - accuracy: 1.00\n",
      "Epoch 20/50\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 1.2195 - accuracy: 0.4710\n",
      "Epoch 4/75\n",
      "14/14 [==============================] - 0s 36ms/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 23/50\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.0625 - accuracy: 0.9754\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 1.2007 - accuracy: 0.4375Epoch 23/50\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.2637 - accuracy: 0.9330- ETA: 0s - loss: 0.2753 - accuracy: 0.93\n",
      "Epoch 18/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 6.2089e-04 - accuracy: 1.0000\n",
      "Epoch 24/50\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 1.1238 - accuracy: 0.4554\n",
      "Epoch 12/75\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.0020 - accuracy: 1.0000\n",
      " - ETA: 0s - loss: 5.1808e-04 - accuracy: 1.0000Epoch 21/50\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.0752 - accuracy: 0.9643\n",
      "12/14 [========================>.....] - ETA: 0s - loss: 0.0011 - accuracy: 1.0000Epoch 24/50\n",
      "14/14 [==============================] - 1s 36ms/step - loss: 1.0582 - accuracy: 0.5670\n",
      "Epoch 5/75\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 24/50\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 4.9045e-04 - accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:28:53.941309: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 32ms/step - loss: 0.2249 - accuracy: 0.9487\n",
      "Epoch 19/75\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 4.9917e-04 - accuracy: 1.0000s - loss: 9.3901e-04 - accuracy: 1.00\n",
      "Epoch 25/50\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0722 - accuracy: 0.9665\n",
      "Epoch 25/50\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 1.1039 - accuracy: 0.4688A: 0s - loss: 0.2080 - accuracy: 0.95\n",
      "12/14 [========================>.....] - ETA: 0s - loss: 0.0011 - accuracy: 1.0000    Epoch 13/75\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.0010 - accuracy: 1.0000- loss: 2.2048e-04 - accuracy: 1.0000 - ETA: 0s - loss: 1.0721 - accuracy: 0.50\n",
      " 5/14 [=========>....................] - ETA: 0s - loss: 1.6444 - accuracy: 0.2000Epoch 22/50\n",
      "14/14 [==============================] - 0s 36ms/step - loss: 0.9811 - accuracy: 0.5871\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 0.9926 - accuracy: 0.5208Epoch 6/75\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.0012 - accuracy: 1.0000- ETA: 0s - loss: 0.2386 - accuracy: 0.9444\n",
      "Epoch 25/50\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.2280 - accuracy: 0.9442- loss: 9.5425e-04 - accuracy: 1.0000 - ETA: 0s - loss: 0.2338 - accuracy: 0.9423\n",
      "Epoch 20/75\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 5.1487e-04 - accuracy: 1.0000ss: 0.9600 - accuracy: 0.5491 - ETA: 0s - loss: 0.0375 - accuracy: 0.98\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 1.5616 - accuracy: 0.3214\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0420 - accuracy: 0.9777\n",
      "Epoch 2/75\n",
      "Epoch 26/50\n",
      "Epoch 26/50\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 1.0753 - accuracy: 0.4777\n",
      "Epoch 14/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.9082 - accuracy: 0.5960\n",
      "Epoch 7/75\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 23/50\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.0036 - accuracy: 0.9978\n",
      "Epoch 26/50\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.2594 - accuracy: 0.9263A: 0s - loss: 0.9454 - accuracy: 0.62\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 5.7607e-04 - accuracy: 1.0000Epoch 21/75\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.0416 - accuracy: 0.9732\n",
      "Epoch 27/50\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 1.4668 - accuracy: 0.3817\n",
      " 4/14 [=======>......................] - ETA: 0s - loss: 0.0024 - accuracy: 1.0000    Epoch 3/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 4.5817e-04 - accuracy: 1.0000\n",
      "Epoch 27/50\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 1.0760 - accuracy: 0.4732- loss: 0.0020 - accuracy: 1.0000 - ETA: 0s - loss: 1.3928 - accuracy: 0.\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.8768 - accuracy: 0.6429\n",
      "Epoch 8/75\n",
      "12/14 [========================>.....] - ETA: 0s - loss: 3.4110e-04 - accuracy: 1.0000Epoch 15/75\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.0514 - accuracy: 0.9710\n",
      "14/14 [==============================] - 1s 35ms/step - loss: 4.0111e-04 - accuracy: 1.0000\n",
      "Epoch 28/50\n",
      "Epoch 24/50\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 1.3488 - accuracy: 0.3750\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.2262 - accuracy: 0.9423Epoch 4/75\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.0040 - accuracy: 1.0000\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 5.8330e-04 - accuracy: 1.0000Epoch 27/50\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.2330 - accuracy: 0.9375\n",
      "Epoch 22/75\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 5.7085e-04 - accuracy: 1.0000\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.3091 - accuracy: 0.9062Epoch 28/50\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 0.1374 - accuracy: 0.9397A: 0s - loss: 5.1911e-04 - accuracy: 1.00\n",
      "Epoch 29/50\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.8137 - accuracy: 0.6808\n",
      "Epoch 9/75\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 1.0793 - accuracy: 0.4710\n",
      "11/14 [======================>.......] - ETA: 0s - loss: 1.1964 - accuracy: 0.3636Epoch 16/75\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 4.3676e-04 - accuracy: 1.0000\n",
      "11/14 [======================>.......] - ETA: 0s - loss: 3.4094e-04 - accuracy: 1.0000Epoch 25/50\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 1.1684 - accuracy: 0.3862A: 0s - loss: 0.7545 - accuracy: 0.7812 - ETA: 0s - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 5/75\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 3.3519e-04 - accuracy: 1.0000\n",
      "Epoch 29/50\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 28/50\n",
      "14/14 [==============================] - 0s 36ms/step - loss: 0.2456 - accuracy: 0.9286\n",
      "Epoch 23/75\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.1560 - accuracy: 0.9353\n",
      " 6/14 [===========>..................] - ETA: 0s - loss: 1.5535e-04 - accuracy: 1.0000Epoch 30/50\n",
      "14/14 [==============================] - 0s 23ms/step - loss: 1.0090 - accuracy: 0.4152\n",
      "Epoch 6/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.7733 - accuracy: 0.7098\n",
      "Epoch 10/75\n",
      "14/14 [==============================] - 0s 36ms/step - loss: 1.0645 - accuracy: 0.4754\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.2283 - accuracy: 0.9438Epoch 17/75\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 5.2490e-04 - accuracy: 1.0000\n",
      "11/14 [======================>.......] - ETA: 0s - loss: 0.0014 - accuracy: 1.0000Epoch 26/50\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 2.0402e-04 - accuracy: 1.0000\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.0616 - accuracy: 0.9719Epoch 30/50\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.2227 - accuracy: 0.9397\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.0014 - accuracy: 1.0000Epoch 24/75\n",
      "14/14 [==============================] - 0s 21ms/step - loss: 0.0653 - accuracy: 0.9665\n",
      "Epoch 31/50\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 29/50\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.9132 - accuracy: 0.4799\n",
      "11/14 [======================>.......] - ETA: 0s - loss: 0.7905 - accuracy: 0.6903Epoch 7/75\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.7795 - accuracy: 0.7143\n",
      "Epoch 11/75\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 1.0460 - accuracy: 0.4866\n",
      "Epoch 18/75\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 2.6975e-04 - accuracy: 1.0000\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.2302 - accuracy: 0.9447Epoch 31/50\n",
      "14/14 [==============================] - 0s 23ms/step - loss: 0.0625 - accuracy: 0.9665\n",
      "Epoch 32/50\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 3.7454e-04 - accuracy: 1.0000\n",
      "Epoch 27/50\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.2304 - accuracy: 0.9464- loss: 1.0706 - accuracy: 0.4688 - ETA: 0s - loss: 2.3583e-05 - accuracy: 1.00\n",
      "Epoch 25/75\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 8.6844e-04 - accuracy: 1.0000\n",
      "Epoch 30/50\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.8573 - accuracy: 0.6138\n",
      "Epoch 8/75\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 1.0607 - accuracy: 0.4688\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 5.1949e-04 - accuracy: 1.0000Epoch 19/75\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 0.0406 - accuracy: 0.9821\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.7088 - accuracy: 0.7344\n",
      "Epoch 33/50\n",
      "Epoch 12/75\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.2452 - accuracy: 0.9219\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 5.2741e-04 - accuracy: 1.0000Epoch 26/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 3.5944e-04 - accuracy: 1.0000\n",
      "Epoch 32/50\n",
      "14/14 [==============================] - 0s 36ms/step - loss: 5.3540e-04 - accuracy: 1.0000\n",
      " 6/14 [===========>..................] - ETA: 0s - loss: 0.0391 - accuracy: 0.9792Epoch 28/50\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 5.1446e-04 - accuracy: 1.0000\n",
      "Epoch 31/50\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.8162 - accuracy: 0.5893A: 0s - loss: 0.1773 - accuracy: 0.95\n",
      "Epoch 9/75\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.0407 - accuracy: 0.9777\n",
      "Epoch 34/50\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 1.0760 - accuracy: 0.4554\n",
      "Epoch 20/75\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.1892 - accuracy: 0.9576\n",
      "Epoch 27/75\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.7135 - accuracy: 0.7522\n",
      "Epoch 13/75\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 1.6450e-04 - accuracy: 1.0000\n",
      "Epoch 33/50\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 3.9754e-04 - accuracy: 1.0000\n",
      "Epoch 29/50\n",
      "14/14 [==============================]14/14 [==============================] - 0s 24ms/step - loss: 0.0521 - accuracy: 0.9799\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 0.7628 - accuracy: 0.5960\n",
      "Epoch 35/50\n",
      "Epoch 10/75\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 3.3161e-04 - accuracy: 1.0000\n",
      "Epoch 32/50=====>....................] - ETA: 0s - loss: 3.1424e-04 - accuracy: 1.00\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 1.1587 - accuracy: 0.4464- loss: 0.0029 - accuracy: 1.0000 - ETA: 0s - loss: 0.7012 - accuracy: 0.77\n",
      " 6/14 [===========>..................] - ETA: 0s - loss: 0.0522 - accuracy: 0.9688Epoch 21/75\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.2362 - accuracy: 0.9308\n",
      "Epoch 28/75\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 2.6311e-04 - accuracy: 1.0000\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 1.6262 - accuracy: 0.1250Epoch 34/50\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.7032 - accuracy: 0.7790\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 1.6236 - accuracy: 0.1667Epoch 14/75\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0531 - accuracy: 0.9710\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.7580 - accuracy: 0.6004\n",
      "Epoch 36/50\n",
      "Epoch 11/75\n",
      "14/14 [==============================] - 1s 36ms/step - loss: 3.4801e-04 - accuracy: 1.0000\n",
      "Epoch 30/50\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 6.7907e-04 - accuracy: 1.0000s - loss: 1.5044e-04 - accuracy: 1.00\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 1.5162e-04 - accuracy: 1.0000\n",
      "Epoch 33/50\n",
      "Epoch 35/50\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.2323 - accuracy: 0.9241\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.6862 - accuracy: 0.6458Epoch 29/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 1.6303 - accuracy: 0.1741\n",
      "Epoch 22/75\n",
      "14/14 [==============================] - 0s 23ms/step - loss: 0.0463 - accuracy: 0.9754\n",
      "Epoch 37/50\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 0.6831 - accuracy: 0.6384\n",
      "Epoch 12/75\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.6658 - accuracy: 0.7768\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 2.5277e-04 - accuracy: 1.0000Epoch 15/75\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 2.4065e-04 - accuracy: 1.0000s - loss: 1.6254 - accuracy: 0.21\n",
      "Epoch 31/50\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 3.7368e-04 - accuracy: 1.0000\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.2133 - accuracy: 0.9323 - ETA: 0s - loss: 1.6226 - accuracy: 0.1938Epoch 36/50\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.2245 - accuracy: 0.9330\n",
      "Epoch 30/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 3.3331e-04 - accuracy: 1.0000\n",
      " 8/14 [================>.............] - ETA: 0s - loss: 0.6362 - accuracy: 0.7891Epoch 34/50\n",
      "14/14 [==============================] - 0s 23ms/step - loss: 0.0377 - accuracy: 0.9799- loss: 0.2156 - accuracy: 0.9375 - ETA: 0s - loss: 0.0377 - accuracy: 0.97\n",
      "Epoch 38/50\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 1.6252 - accuracy: 0.1741\n",
      "Epoch 23/75\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.6927 - accuracy: 0.6183\n",
      "Epoch 13/75\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.6333 - accuracy: 0.7879\n",
      "Epoch 16/75\n",
      "14/14 [==============================] - ETA: 0s - loss: 1.6189 - accuracy: 0.1906 - 0s 33ms/step - loss: 2.6330e-04 - accuracy: 1.0000\n",
      "Epoch 32/50\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 3.3615e-04 - accuracy: 1.0000\n",
      "Epoch 37/50\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 0.0383 - accuracy: 0.9732\n",
      "Epoch 39/50\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 1.6183 - accuracy: 0.1741\n",
      "Epoch 24/75\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.2152 - accuracy: 0.9397\n",
      "Epoch 31/75\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 3.4930e-04 - accuracy: 1.0000ss: 0.6076 - accuracy: 0.8304 - ETA: 0s - loss: 1.2975e-04 - accuracy: 1.00\n",
      "Epoch 35/50\n",
      "14/14 [==============================] - 0s 24ms/step - loss: 0.7117 - accuracy: 0.6518\n",
      "Epoch 14/75\n",
      "14/14 [==============================] - 0s 24ms/step - loss: 0.0320 - accuracy: 0.9799\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.6087 - accuracy: 0.8259\n",
      "Epoch 40/50\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 1.8183e-04 - accuracy: 1.0000\n",
      "Epoch 17/75\n",
      "Epoch 38/50\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.1994 - accuracy: 0.9442\n",
      "11/14 [======================>.......] - ETA: 0s - loss: 5.2200e-04 - accuracy: 1.0000Epoch 32/75\n",
      "14/14 [==============================] - 0s 24ms/step - loss: 0.6636 - accuracy: 0.6295\n",
      "Epoch 15/75\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 2.6874e-04 - accuracy: 1.0000\n",
      "Epoch 33/50\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 1.6122 - accuracy: 0.1741\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.0676 - accuracy: 1.0000Epoch 25/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 4.5584e-04 - accuracy: 1.0000\n",
      "Epoch 36/50\n",
      "14/14 [==============================] - 0s 24ms/step - loss: 0.0426 - accuracy: 0.9754- ETA: 0s - loss: 0.7048 - accuracy: 0.59\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 0.6482 - accuracy: 0.6339Epoch 41/50\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.6484 - accuracy: 0.7746- ETA: 0s - loss: 0.2877 - accuracy: 0.\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 2.5582e-04 - accuracy: 1.0000\n",
      "Epoch 18/75\n",
      "Epoch 39/50\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.6513 - accuracy: 0.6406\n",
      "Epoch 16/75\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.2351 - accuracy: 0.9353\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 1.6063 - accuracy: 0.1741\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 4.3930e-04 - accuracy: 1.0000 - ETA: 0s - loss: 0.6397 - accuracy: 0.8438Epoch 33/75\n",
      "Epoch 26/75\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 1.7066e-04 - accuracy: 1.0000ss: 0.6416 - accuracy: 0.6250 - ETA: 0s - loss: 1.7066e-04 - accuracy: 1.00\n",
      "Epoch 34/50\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 3.9235e-04 - accuracy: 1.0000\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 2.0408e-04 - accuracy: 1.0000Epoch 37/50\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0518 - accuracy: 0.9754\n",
      "Epoch 42/50\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 2.7668e-04 - accuracy: 1.0000\n",
      "Epoch 40/50\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.6332 - accuracy: 0.6473\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.0334 - accuracy: 0.9750Epoch 17/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.2169 - accuracy: 0.9308\n",
      "Epoch 34/75\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 1.4720e-04 - accuracy: 1.0000\n",
      "Epoch 35/50\n",
      "14/14 [==============================] - 1s 44ms/step - loss: 0.6291 - accuracy: 0.8170\n",
      "11/14 [======================>.......] - ETA: 0s - loss: 3.3162e-04 - accuracy: 1.0000Epoch 19/75\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 1.6010 - accuracy: 0.1741\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 1.8272e-04 - accuracy: 1.0000Epoch 27/75\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.0400 - accuracy: 0.9732\n",
      "Epoch 43/50\n",
      "14/14 [==============================] - 0s 24ms/step - loss: 1.6364e-04 - accuracy: 1.0000\n",
      "14/14 [==============================] - 0s 36ms/step - loss: 3.6819e-04 - accuracy: 1.0000\n",
      " 6/14 [===========>..................] - ETA: 0s - loss: 0.3672 - accuracy: 0.8854Epoch 38/50\n",
      "Epoch 41/50\n",
      " - ETA: 0s - loss: 0.4023 - accuracy: 0.888414/14 [==============================] - 0s 30ms/step - loss: 0.6615 - accuracy: 0.6473 0s - loss: 0.6014 - accuracy: 0.\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.4023 - accuracy: 0.8884\n",
      "Epoch 18/75\n",
      "Epoch 35/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 1.6325e-04 - accuracy: 1.0000\n",
      "Epoch 36/50\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.0393 - accuracy: 0.9777- loss: 0.0393 - accuracy: 0.9777 - ETA: 0s - loss: 1.5953 - accuracy: 0.17\n",
      " 4/14 [=======>......................] - ETA: 0s - loss: 0.6171 - accuracy: 0.6328Epoch 44/50\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 2.2177e-04 - accuracy: 1.0000\n",
      "Epoch 42/50\n",
      "14/14 [==============================] - 0s 36ms/step - loss: 1.5955 - accuracy: 0.1741\n",
      " 5/14 [=========>....................] - ETA: 0s - loss: 0.4842 - accuracy: 0.8625Epoch 28/75\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.5998 - accuracy: 0.8259\n",
      "Epoch 39/50\n",
      "Epoch 20/75\n",
      "14/14 [==============================] - 0s 23ms/step - loss: 0.6411 - accuracy: 0.6295\n",
      "Epoch 19/75\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.4291 - accuracy: 0.8571A: 0s - loss: 4.6994e-04 - accuracy: 1.00\n",
      "Epoch 36/75\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 0.0434 - accuracy: 0.9754\n",
      "11/14 [======================>.......] - ETA: 0s - loss: 2.3270e-04 - accuracy: 1.0000Epoch 45/50\n",
      "14/14 [============================= - 0s 31ms/step - loss: 1.3734e-04 - accuracy: 1.0000\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 2.0697e-04 - accuracy: 1.0000Epoch 37/50\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 2.0099e-04 - accuracy: 1.0000\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 3.7210e-04 - accuracy: 1.0000Epoch 43/50\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 5.3805e-04 - accuracy: 1.0000\n",
      "Epoch 40/50\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 1.5901 - accuracy: 0.1741\n",
      "Epoch 29/75\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.5985 - accuracy: 0.6607\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.6197 - accuracy: 0.8080\n",
      "Epoch 21/75\n",
      "Epoch 20/75\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.0553 - accuracy: 0.9621\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 1.5865 - accuracy: 0.1920Epoch 46/50\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.3429 - accuracy: 0.8996\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 1.9753e-04 - accuracy: 1.0000\n",
      "Epoch 37/75\n",
      "Epoch 44/50\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 1.4859e-04 - accuracy: 1.0000\n",
      "Epoch 38/50\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 1.5855 - accuracy: 0.1741\n",
      "Epoch 30/75\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.5957 - accuracy: 0.6763\n",
      "Epoch 21/75\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.5842 - accuracy: 0.8103\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.6604 - accuracy: 0.7812Epoch 22/75\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 4.0556e-04 - accuracy: 1.0000\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 3.4075e-04 - accuracy: 1.0000Epoch 41/50\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.0442 - accuracy: 0.9777- ETA: 0s - loss: 0.0442 - accuracy: 0.97\n",
      "11/14 [======================>.......] - ETA: 0s - loss: 0.2733 - accuracy: 0.9091Epoch 47/50\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 2.4978e-04 - accuracy: 1.0000ss: 7.8838e-04 - accuracy: 1.0000 - ETA: 0s - loss: 1.4084e-04 - accuracy: 1.00\n",
      "Epoch 45/50\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.2660 - accuracy: 0.9107\n",
      "Epoch 38/75\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.6383 - accuracy: 0.6585\n",
      "Epoch 22/75\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 1.4492e-04 - accuracy: 1.0000\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.5375 - accuracy: 0.6562Epoch 39/50\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 1.5811 - accuracy: 0.2232- ETA: 0s - loss: 0.6044 - accuracy: 0.79\n",
      "Epoch 31/75\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.6133 - accuracy: 0.7991\n",
      "Epoch 23/75\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0390 - accuracy: 0.9688\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 4.3303e-04 - accuracy: 1.0000\n",
      "Epoch 42/50\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.6070 - accuracy: 0.6813Epoch 48/50\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 1.9927e-04 - accuracy: 1.0000s - loss: 7.1653e-05 - accuracy: 1.00\n",
      "Epoch 46/50\n",
      "14/14 [==============================] - 0s 24ms/step - loss: 0.6004 - accuracy: 0.6808\n",
      "Epoch 23/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.2217 - accuracy: 0.9286\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.5546 - accuracy: 0.5938Epoch 39/75\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 1.3293e-04 - accuracy: 1.0000\n",
      " 6/14 [===========>..................] - ETA: 0s - loss: 0.1815 - accuracy: 0.9375Epoch 40/50\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 1.5765 - accuracy: 0.3661\n",
      "Epoch 32/75\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.5925 - accuracy: 0.8058\n",
      "Epoch 24/75\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0427 - accuracy: 0.9688\n",
      "Epoch 49/50\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 3.0781e-04 - accuracy: 1.0000\n",
      "Epoch 43/50\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.5910 - accuracy: 0.6629\n",
      "Epoch 24/75\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 1.2402e-04 - accuracy: 1.0000\n",
      "Epoch 47/50\n",
      "14/14 [==============================] - 1s 36ms/step - loss: 0.1763 - accuracy: 0.9509\n",
      "Epoch 40/75\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 1.5720 - accuracy: 0.3750- ETA: 0s - loss: 0.0717 - accuracy: 1.\n",
      "Epoch 33/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 1.4480e-04 - accuracy: 1.0000\n",
      "Epoch 41/50\n",
      " 6/14 [===========>..................] - ETA: 0s - loss: 0.1821 - accuracy: 0.9479 - 0s 27ms/step - loss: 0.0319 - accuracy: 0.9754\n",
      "Epoch 50/50\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.5919 - accuracy: 0.8103\n",
      "Epoch 25/75\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.0012 - accuracy: 1.0000- loss: 0.1906 - accuracy: 0.9438 - ETA: 0s - loss: 1.1377e-04 - accuracy: 1.00\n",
      "Epoch 44/50\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.6056 - accuracy: 0.6853\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 2.5321e-04 - accuracy: 1.0000Epoch 25/75\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 1.1383e-04 - accuracy: 1.0000\n",
      "Epoch 48/50\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.1946 - accuracy: 0.9420\n",
      "Epoch 41/75\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.0291 - accuracy: 0.9799A: 0s - loss: 0.5565 - accuracy: 0.\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 1.5573e-04 - accuracy: 1.0000\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 0.2315 - accuracy: 0.9167Epoch 42/50\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 1.5682 - accuracy: 0.3750A: 0s - loss: 0.0033 - accuracy: 1.00\n",
      "Epoch 34/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.5518 - accuracy: 0.8281\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 1.1118e-04 - accuracy: 1.0000Epoch 26/75\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.5818 - accuracy: 0.6741\n",
      "Epoch 26/75\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 1.7642e-04 - accuracy: 1.0000s - loss: 0.5788 - accuracy: 0.84\n",
      "Epoch 49/50\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.0040 - accuracy: 1.0000\n",
      "Epoch 45/50\n",
      "14/14 [==============================] - 1s 34ms/step - loss: 0.1889 - accuracy: 0.9420\n",
      "Epoch 42/75\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 1.5641 - accuracy: 0.3750\n",
      "Epoch 35/75\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 0.0140 - accuracy: 0.99\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:29:04.398195: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 1s 38ms/step - loss: 7.2151e-05 - accuracy: 1.0000\n",
      "Epoch 43/50\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.5716 - accuracy: 0.6763\n",
      "Epoch 27/75\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 1.0054e-04 - accuracy: 1.0000\n",
      " - ETA: 0s - loss: 0.1432 - accuracy: 0.9609Epoch 50/50\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.5916 - accuracy: 0.8036\n",
      "Epoch 27/75\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.0344 - accuracy: 0.9911\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.0130 - accuracy: 0.9978\n",
      "[CV 4/5] END ...epochs=50, layers=3, neurons=60;, score=0.991 total time=  22.7s\n",
      "Epoch 46/50\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.1735 - accuracy: 0.9487- loss: 0.0167 - accuracy: 1.0000 - ETA: 0s - loss: 0.5413 - accuracy: 0.76\n",
      "Epoch 43/75\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 1.5604 - accuracy: 0.3750\n",
      " 9/14 [==================>...........]Epoch 36/75- loss: 0.5407 - accuracy: 0.731.00\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.5305 - accuracy: 0.7366\n",
      "Epoch 28/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 1.2547e-04 - accuracy: 1.0000\n",
      "Epoch 44/50\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 1.2979e-04 - accuracy: 1.0000\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.5749 - accuracy: 0.8192ETA: 0s - loss: 0.5615 - accuracy: 0.68\n",
      " - ETA: 0s - loss: 0.2329 - accuracy: 0.9306Epoch 28/75\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.0085 - accuracy: 1.0000\n",
      "Epoch 47/50\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.2145 - accuracy: 0.9330\n",
      "Epoch 44/75\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.5507 - accuracy: 0.7188\n",
      "Epoch 29/75\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 1.5578 - accuracy: 0.3750\n",
      "Epoch 37/75\n",
      "11/14 [======================>.......] - ETA: 0s - loss: 0.5750 - accuracy: 0.8239: 0s - loss: 0.0015 - accuracy: 1.0000 - ETA: 0s - loss: 0.1811 - accuracy: 0.95"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:29:05.542965: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 1s 39ms/step - loss: 2.1896e-04 - accuracy: 1.0000\n",
      " 8/14 [================>.............] - ETA: 0s - loss: 0.0012 - accuracy: 1.0000Epoch 45/50\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.5805 - accuracy: 0.8147\n",
      "11/14 [======================>.......] - ETA: 0s - loss: 0.0013 - accuracy: 1.0000Epoch 29/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 48/50\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 3.4246e-05 - accuracy: 1.0000\n",
      "[CV 3/5] END ...epochs=50, layers=3, neurons=60;, score=1.000 total time=  25.8s\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.1744 - accuracy: 0.9487\n",
      "12/14 [========================>.....] - ETA: 0s - loss: 1.5551 - accuracy: 0.3672Epoch 45/75\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.5464 - accuracy: 0.7121\n",
      "Epoch 30/75\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 1.5536 - accuracy: 0.3750\n",
      "Epoch 38/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 1.0872e-04 - accuracy: 1.0000s - loss: 0.5962 - accuracy: 0.72\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 4.1700e-04 - accuracy: 1.0000Epoch 46/50\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.5684 - accuracy: 0.8237A: 0s - loss: 0.5714 - accuracy: 0.72\n",
      "Epoch 30/75\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.5592 - accuracy: 0.7366\n",
      "Epoch 31/75\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 6.0069e-04 - accuracy: 1.0000\n",
      "Epoch 49/50\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.1617 - accuracy: 0.9576\n",
      "11/14 [======================>.......] - ETA: 0s - loss: 1.5475 - accuracy: 0.3722Epoch 46/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 1.5502 - accuracy: 0.3750A: 0s - loss: 0.5773 - accuracy: 0.66\n",
      "Epoch 39/75\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 9.9296e-05 - accuracy: 1.0000\n",
      "Epoch 1/75\n",
      "Epoch 47/50\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.9058 - accuracy: 0.5804\n",
      " 6/14 [===========>..................] - ETA: 0s - loss: 1.5438 - accuracy: 0.3906Epoch 32/75\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.5457 - accuracy: 0.8192\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 3.2992e-05 - accuracy: 1.0000Epoch 31/75\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.1611 - accuracy: 0.9554\n",
      "Epoch 47/75\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 50/50\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 1.5460 - accuracy: 0.3750\n",
      "Epoch 40/75\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 1.1949 - accuracy: 0.4487\n",
      "Epoch 33/75\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 8.9389e-05 - accuracy: 1.0000\n",
      "Epoch 48/50\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.5570 - accuracy: 0.8281\n",
      "Epoch 32/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.1890 - accuracy: 0.9375- ETA: 0s - loss: 0.1918 - accuracy: 0.93\n",
      "Epoch 48/75\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 6.9209e-04 - accuracy: 1.0000\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 1.5445 - accuracy: 0.3750A: 0s - loss: 0.1994 - accuracy: 0.93\n",
      "Epoch 41/75\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.8343 - accuracy: 0.5826\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 1.4936 - accuracy: 0.4375Epoch 34/75\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 0.9631 - accuracy: 0.5625 - ETA: 0s - loss: 0.2017 - accuracy: 0.9375"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:29:07.336017: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 1s 38ms/step - loss: 1.2550e-04 - accuracy: 1.0000\n",
      "Epoch 49/50\n",
      "14/14 [==============================] - 1s 36ms/step - loss: 0.5519 - accuracy: 0.8192A: 0s - loss: 0.8782 - accuracy: 0.\n",
      "Epoch 33/75\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.1640 - accuracy: 0.9509\n",
      "Epoch 49/75\n",
      "12/14 [========================>.....] - ETA: 0s - loss: 0.7727 - accuracy: 0.648400"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:29:07.745498: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 1s 36ms/step - loss: 0.7658 - accuracy: 0.6451\n",
      "Epoch 35/75\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 1.5411 - accuracy: 0.3750\n",
      "Epoch 42/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 7.0530e-05 - accuracy: 1.0000s - loss: 1.6374 - accuracy: 0.2969\n",
      " 8/14 [================>.............] - ETA: 0s - loss: 0.1984 - accuracy: 0.9336Epoch 50/50\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 0.0024 - accuracy: 1.0000\n",
      "[CV 2/5] END ...epochs=50, layers=3, neurons=60;, score=1.000 total time=  28.3s\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.5612 - accuracy: 0.7969A: 0s - loss: 1.6264 - accuracy: 0.30\n",
      "Epoch 34/75\n",
      "14/14 [==============================] - 2s 43ms/step - loss: 1.6092 - accuracy: 0.3326\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.1809 - accuracy: 0.9447Epoch 2/75\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.1799 - accuracy: 0.9464\n",
      "Epoch 50/75\n",
      " 5/14 [=========>....................] - ETA: 0s - loss: 0.5828 - accuracy: 0.7937Epoch 1/75\n",
      "14/14 [==============================] - 1s 35ms/step - loss: 0.6313 - accuracy: 0.7254\n",
      " 5/14 [=========>....................] - ETA: 0s - loss: 0.2285 - accuracy: 0.9250Epoch 36/75\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 1.5381 - accuracy: 0.3750\n",
      "Epoch 43/75\n",
      "14/14 [==============================] - 0s 36ms/step - loss: 9.1835e-05 - accuracy: 1.0000\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.5319 - accuracy: 0.8192\n",
      "Epoch 35/75\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 1.3729 - accuracy: 0.3996\n",
      "Epoch 3/75\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.2283 - accuracy: 0.9152\n",
      "Epoch 51/75\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.5243 - accuracy: 0.7567\n",
      "Epoch 37/75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:29:08.897878: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-01-09 14:29:09.055097: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 1s 36ms/step - loss: 1.5350 - accuracy: 0.3750\n",
      "Epoch 44/75\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.5363 - accuracy: 0.8170\n",
      "Epoch 36/75\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 1.1621 - accuracy: 0.4576\n",
      "Epoch 4/75\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.1765 - accuracy: 0.9442\n",
      "Epoch 52/75\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 2.1788e-04 - accuracy: 1.0000\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 0.9679 - accuracy: 0.5729[CV 5/5] END ...epochs=50, layers=3, neurons=60;, score=1.000 total time=  27.1s\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.5009 - accuracy: 0.7768\n",
      "Epoch 38/75\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 1.5309 - accuracy: 0.3750A: 0s - loss: 0.8951 - accuracy: 0.631\n",
      "Epoch 45/75\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.1850 - accuracy: 0.9444 - ETA: 0s - loss: 0.8799 - accuracy: 0.6562Epoch 1/75\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 0.4894 - accuracy: 0.8393\n",
      "Epoch 37/75\n",
      "14/14 [==============================] - 1s 46ms/step - loss: 0.8768 - accuracy: 0.6652\n",
      "12/14 [========================>.....] - ETA: 0s - loss: 0.1759 - accuracy: 0.9479Epoch 5/75\n",
      "14/14 [==============================] - 1s 45ms/step - loss: 0.1724 - accuracy: 0.9487\n",
      " 2/14 [===>..........................] - ETA: 0s - loss: 0.5678 - accuracy: 0.8281Epoch 53/75\n",
      "14/14 [==============================] - 2s 50ms/step - loss: 1.6746 - accuracy: 0.3460\n",
      " 4/14 [=======>......................] - ETA: 0s - loss: 0.7035 - accuracy: 0.7266Epoch 2/75\n",
      "14/14 [==============================] - ETA: 0s - loss: 1.2902 - accuracy: 0.5938 - 1s 53ms/step - loss: 0.5133 - accuracy: 0.7679\n",
      "Epoch 39/75\n",
      "14/14 [==============================] - 1s 67ms/step - loss: 1.5310 - accuracy: 0.3750A: 0s - loss: 0.5120 - accuracy: 0.82\n",
      "Epoch 46/75\n",
      "14/14 [==============================] - 1s 50ms/step - loss: 0.5528 - accuracy: 0.8080\n",
      " 5/14 [=========>....................] - ETA: 0s - loss: 0.4739 - accuracy: 0.8250Epoch 38/75\n",
      "14/14 [==============================] - 1s 53ms/step - loss: 0.5541 - accuracy: 0.7879\n",
      "Epoch 6/75\n",
      "14/14 [==============================] - 1s 49ms/step - loss: 0.1854 - accuracy: 0.9420\n",
      "Epoch 54/75\n",
      " 5/14 [=========>....................] - ETA: 0s - loss: 1.5330 - accuracy: 0.3625"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:29:10.572189: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 1s 47ms/step - loss: 1.2165 - accuracy: 0.5335\n",
      "Epoch 3/75\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.4837 - accuracy: 0.8013\n",
      " 8/14 [================>.............] - ETA: 0s - loss: 0.3797 - accuracy: 0.8398Epoch 40/75\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 1.5295 - accuracy: 0.3750\n",
      "Epoch 47/75\n",
      "14/14 [==============================] - 1s 43ms/step - loss: 0.5224 - accuracy: 0.8192\n",
      "Epoch 39/75\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.3817 - accuracy: 0.8460\n",
      "Epoch 7/75\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.1711 - accuracy: 0.9464A: 0s - loss: 0.3516 - accuracy: 0.81\n",
      "Epoch 55/75\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.9372 - accuracy: 0.5647- loss: 0.4521 - accuracy: 0.8333 - ETA: 0s - loss: 0.4957 - accuracy: 0.\n",
      "Epoch 4/75\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.4862 - accuracy: 0.7857\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 1.5414 - accuracy: 0.3507Epoch 41/75\n",
      "12/14 [========================>.....] - ETA: 0s - loss: 1.5322 - accuracy: 0.3724Epoch 1/75 - loss: 1.8753 - accuracy: 0.25\n",
      "14/14 [==============================] - 0s 37ms/step - loss: 0.2485 - accuracy: 0.9330\n",
      "12/14 [========================>.....] - ETA: 0s - loss: 1.8159 - accuracy: 0.2656Epoch 8/75\n",
      "14/14 [==============================] - 1s 44ms/step - loss: 1.5270 - accuracy: 0.3750\n",
      "12/14 [========================>.....] - ETA: 0s - loss: 0.1481 - accuracy: 0.9557Epoch 48/\n",
      "14/14 [==============================] - 1s 44ms/step - loss: 0.5324 - accuracy: 0.8147\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 1.5866 - accuracy: 0.3125Epoch 40/75\n",
      "14/14 [==============================] - 2s 44ms/step - loss: 1.7535 - accuracy: 0.2879\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.1421 - accuracy: 0.9576\n",
      "Epoch 2/75\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 0.1681 - accuracy: 0.9583Epoch 56/75\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.7159 - accuracy: 0.6518\n",
      "14/14 [==============================]Epoch 5/75\n",
      " - 1s 37ms/step - loss: 0.4990 - accuracy: 0.7813\n",
      " 6/14 [===========>..................] - ETA: 0s - loss: 0.4981 - accuracy: 0.8333Epoch 42/75\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.1583 - accuracy: 0.9576\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.4946 - accuracy: 0.8313Epoch 9/75\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.5106 - accuracy: 0.8259A: 0s - loss: 0.5991 - accuracy: 0.73\n",
      "Epoch 41/75\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 1.5254 - accuracy: 0.3750\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.1740 - accuracy: 0.9447Epoch 49/75\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.1729 - accuracy: 0.9442\n",
      "Epoch 57/75\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 1.2715 - accuracy: 0.4754\n",
      "Epoch 3/75\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.5706 - accuracy: 0.7500A: 0s - loss: 0.1460 - accuracy: 0.97\n",
      "Epoch 6/75\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.4944 - accuracy: 0.7924\n",
      "Epoch 43/75\n",
      "14/14 [==============================] - 0s 36ms/step - loss: 0.1470 - accuracy: 0.9643\n",
      "Epoch 10/75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:29:12.373700: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 1s 43ms/step - loss: 0.5378 - accuracy: 0.8058\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 1.5233 - accuracy: 0.3750\n",
      "Epoch 50/75\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.5191 - accuracy: 0.7778Epoch 42/75\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 0.1827 - accuracy: 0.9375\n",
      "11/14 [======================>.......] - ETA: 0s - loss: 0.4495 - accuracy: 0.8551Epoch 58/75\n",
      "14/14 [==============================] - 1s 43ms/step - loss: 0.7890 - accuracy: 0.7188A: 0s - loss: 2.2992 - accuracy: 0.2292  - ETA: 0s - loss: 0.7890 - accuracy: 0.71\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.3056 - accuracy: 0.8438Epoch 4/75\n",
      "14/14 [==============================] - 1s 43ms/step - loss: 0.4438 - accuracy: 0.8571\n",
      "Epoch 7/75\n",
      "14/14 [==============================] - 1s 52ms/step - loss: 0.5131 - accuracy: 0.7924\n",
      "Epoch 44/75\n",
      "14/14 [==============================] - 1s 47ms/step - loss: 0.1098 - accuracy: 0.9688\n",
      "Epoch 11/75\n",
      "14/14 [==============================] - 1s 46ms/step - loss: 1.5215 - accuracy: 0.3750A: 0s - loss: 0.5040 - accuracy: 0.\n",
      "Epoch 51/75\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.3892 - accuracy: 0.8795\n",
      " 8/14 [================>.............] - ETA: 0s - loss: 0.4949 - accuracy: 0.8633Epoch 5/75\n",
      "14/14 [==============================] - 1s 47ms/step - loss: 0.4725 - accuracy: 0.8304\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.1810 - accuracy: 0.9375Epoch 43/75\n",
      "14/14 [==============================] - 1s 49ms/step - loss: 0.1809 - accuracy: 0.9375\n",
      "Epoch 59/75\n",
      "14/14 [==============================] - 2s 66ms/step - loss: 1.7306 - accuracy: 0.3058A: 0s - loss: 0.2370 - accuracy: 0.91\n",
      "Epoch 2/75\n",
      "14/14 [==============================] - 1s 49ms/step - loss: 0.3867 - accuracy: 0.8527\n",
      " 5/14 [=========>....................] - ETA: 0s - loss: 0.2562 - accuracy: 0.9125Epoch 8/75\n",
      "14/14 [==============================] - 1s 36ms/step - loss: 0.5016 - accuracy: 0.8460\n",
      "11/14 [======================>.......] - ETA: 0s - loss: 0.1479 - accuracy: 0.9517Epoch 45/75\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.1403 - accuracy: 0.9554A: 0s - loss: 0.1571 - accuracy: 0.95\n",
      " 3/14 [=====>........................] 2/14 [===>..........................] - ETA: 0s - loss: 0.3247 - accuracy: 0.8750 - ETA: 0s - loss: 0.3982 - accuracy: 0.8750Epoch 12/75\n",
      "14/14 [==============================] - 1s 49ms/step - loss: 1.5215 - accuracy: 0.3750\n",
      "12/14 [========================>.....] - ETA: 0s - loss: 0.2099 - accuracy: 0.9375Epoch 52/75\n",
      "14/14 [==============================] - 1s 52ms/step - loss: 0.4888 - accuracy: 0.8259\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 0.1047 - accuracy: 0.9732Epoch 44/75\n",
      "14/14 [==============================] - 1s 57ms/step - loss: 0.2025 - accuracy: 0.9397\n",
      "11/14 [======================>.......] - ETA: 0s - loss: 1.3410 - accuracy: 0.4091Epoch 6/75\n",
      "14/14 [==============================] - 1s 58ms/step - loss: 0.1770 - accuracy: 0.9420\n",
      "Epoch 60/75\n",
      "14/14 [==============================] - 1s 55ms/step - loss: 0.4981 - accuracy: 0.8504\n",
      "14/14 [==============================]14/14 [==============================] - 1s 57ms/step - loss: 0.3090 - accuracy: 0.8750\n",
      " - 1s 62ms/step - loss: 1.3039 - accuracy: 0.4330\n",
      " 4/14 [=======>......................] - ETA: 0s - loss: 0.1811 - accuracy: 0.9141Epoch 46/75\n",
      " 4/14 [=======>......................] - ETA: 0s - loss: 0.5187 - accuracy: 0.7969Epoch 9/75\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 0.1805 - accuracy: 0.9479Epoch 3/75\n",
      "14/14 [==============================] - 1s 56ms/step - loss: 0.1140 - accuracy: 0.9643\n",
      "Epoch 13/75\n",
      "14/14 [==============================] - 1s 66ms/step - loss: 1.5208 - accuracy: 0.3750A: 0s - loss: 0.0850 - accuracy: 0.96TA: 0s - loss: 0.3696 - accuracy: 0.\n",
      "14/14 [==============================] - 1s 52ms/step - loss: 0.1605 - accuracy: 0.9487\n",
      "Epoch 53/75\n",
      "14/14 [==============================] - 1s 60ms/step - loss: 0.5022 - accuracy: 0.8125\n",
      "11/14 [======================>.......] 9/14 [==================>...........] - ETA: 0s - loss: 0.0832 - accuracy: 0.9688 - ETA: 0s - loss: 0.4927 - accuracy: 0.8409Epoch 61/75\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.3461 - accuracy: 0.8781Epoch 45/75\n",
      "14/14 [==============================] - 1s 60ms/step - loss: 0.1200 - accuracy: 0.9576\n",
      "Epoch 7/75\n",
      "14/14 [==============================] - 1s 66ms/step - loss: 0.4912 - accuracy: 0.8393\n",
      " 3/14 [=====>........................] - ETA: 1s - loss: 1.5176 - accuracy: 0.3438Epoch 47/75\n",
      "14/14 [==============================] - 1s 72ms/step - loss: 0.3274 - accuracy: 0.8750\n",
      " 4/14 [=======>......................] - ETA: 1s - loss: 1.5330 - accuracy: 0.3359Epoch 10/75\n",
      "14/14 [==============================] - 1s 64ms/step - loss: 0.0780 - accuracy: 0.9732\n",
      "Epoch 14/75\n",
      "14/14 [==============================] - 1s 76ms/step - loss: 1.0051 - accuracy: 0.5960A: 0s - loss: 0.1536 - accuracy: 0.93\n",
      " 6/14 [===========>..................] - ETA: 0s - loss: 0.1950 - accuracy: 0.9323Epoch 4/75\n",
      "14/14 [==============================] - 1s 53ms/step - loss: 0.1666 - accuracy: 0.9442A: 0s - loss: 0.5364 - accuracy: 0.79TA: 0s - loss: 0.5349 - accuracy: 0.\n",
      "Epoch 62/75\n",
      "14/14 [==============================] - 1s 57ms/step - loss: 1.5184 - accuracy: 0.3750A: 0s - loss: 0.0621 - accuracy: 0.98\n",
      "12/14 [========================>.....] - ETA: 0s - loss: 0.1214 - accuracy: 0.9531Epoch 54/75\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.4647 - accuracy: 0.8460\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.7984 - accuracy: 0.6094Epoch 48/75\n",
      "14/14 [==============================] - 1s 60ms/step - loss: 0.5332 - accuracy: 0.7969\n",
      "Epoch 46/75\n",
      "14/14 [==============================] - 1s 58ms/step - loss: 0.1114 - accuracy: 0.9576\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 0.1684 - accuracy: 0.9375Epoch 8/75\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.7856 - accuracy: 0.6094A: 0s - loss: 0.0544 - accuracy: 0.98\n",
      " 6/14 [===========>..................] - ETA: 0s - loss: 0.1605 - accuracy: 0.9479Epoch 5/75\n",
      "14/14 [==============================] - 1s 54ms/step - loss: 0.2514 - accuracy: 0.8839\n",
      " 6/14 [===========>..................] - ETA: 0s - loss: 0.4411 - accuracy: 0.8385Epoch 11/75\n",
      "14/14 [==============================] - 1s 55ms/step - loss: 0.0637 - accuracy: 0.9799\n",
      " 6/14 [===========>..................] - ETA: 0s - loss: 0.0764 - accuracy: 0.9688Epoch 15/75\n",
      "14/14 [==============================] - 1s 50ms/step - loss: 1.5236 - accuracy: 0.3750A: 0s - loss: 0.0671 - accuracy: 0.96TA: 0s - loss: 0.0490 - accuracy: 0.\n",
      "14/14 [==============================] - 1s 53ms/step - loss: 0.1640 - accuracy: 0.9464\n",
      "14/14 [==============================] - 1s 46ms/step - loss: 0.4740 - accuracy: 0.8460\n",
      "Epoch 55/75\n",
      "Epoch 63/75\n",
      "14/14 [==============================] - 1s 45ms/step - loss: 0.4795 - accuracy: 0.8304\n",
      " 8/14 [================>.............] - ETA: 0s - loss: 0.0634 - accuracy: 0.9688Epoch 47/75\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 1.5507 - accuracy: 0.4375Epoch 49/75\n",
      "14/14 [==============================] - 1s 47ms/step - loss: 0.0811 - accuracy: 0.9688\n",
      "Epoch 9/75\n",
      "14/14 [==============================] - 1s 43ms/step - loss: 0.2778 - accuracy: 0.8839\n",
      "Epoch 12/75\n",
      "14/14 [==============================] - 1s 48ms/step - loss: 0.0565 - accuracy: 0.9777\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.6213 - accuracy: 0.7165Epoch 16/75\n",
      "14/14 [==============================] - 1s 53ms/step - loss: 0.6213 - accuracy: 0.7165\n",
      "Epoch 6/75\n",
      "14/14 [==============================] - 1s 35ms/step - loss: 0.4664 - accuracy: 0.8326\n",
      "Epoch 50/75\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.1481 - accuracy: 0.9531\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 1.5270 - accuracy: 0.3654Epoch 64/75\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.4700 - accuracy: 0.8281\n",
      "12/14 [========================>.....] - ETA: 0s - loss: 0.0837 - accuracy: 0.9688Epoch 48/75\n",
      "14/14 [==============================] - 1s 44ms/step - loss: 1.5205 - accuracy: 0.3750\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 0.5594 - accuracy: 0.7589Epoch 56/75\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.1570 - accuracy: 0.9479 - 1s 39ms/step - loss: 0.0763 - accuracy: 0.9732\n",
      "Epoch 10/75\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0424 - accuracy: 0.9911\n",
      " 5/14 [=========>....................] - ETA: 0s - loss: 0.1375 - accuracy: 0.9563Epoch 17/75\n",
      "14/14 [==============================] - 1s 35ms/step - loss: 0.2321 - accuracy: 0.9085\n",
      "Epoch 13/75\n",
      "14/14 [==============================] - 1s 36ms/step - loss: 0.5332 - accuracy: 0.7790- loss: 0.4844 - accuracy: 0.8281 - ETA: 0s - loss: 0.4631 - accuracy: 0.\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.1444 - accuracy: 0.9514Epoch 7/75\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.4858 - accuracy: 0.8281\n",
      "Epoch 51/75\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.1632 - accuracy: 0.9442\n",
      "Epoch 65/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.4635 - accuracy: 0.8147\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.1893 - accuracy: 0.9375Epoch 49/75\n",
      "14/14 [==============================] - 0s 24ms/step - loss: 0.0356 - accuracy: 0.9821\n",
      "11/14 [======================>.......] - ETA: 0s - loss: 0.2032 - accuracy: 0.9205Epoch 18/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 1.5178 - accuracy: 0.3750\n",
      "Epoch 57/75\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.2132 - accuracy: 0.9152\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.4062 - accuracy: 0.8229Epoch 14/75\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.0557 - accuracy: 0.9821\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.4996 - accuracy: 0.8264Epoch 11/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.4189 - accuracy: 0.8371\n",
      "Epoch 8/75\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.4824 - accuracy: 0.8304\n",
      "11/14 [======================>.......] - ETA: 0s - loss: 0.0472 - accuracy: 0.9886Epoch 52/75\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0551 - accuracy: 0.9888\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 0.0606 - accuracy: 0.9777Epoch 19/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.1832 - accuracy: 0.9420\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.0555 - accuracy: 0.9688Epoch 66/75\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 1.5217 - accuracy: 0.3750\n",
      "Epoch 58/75\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.4633 - accuracy: 0.8348\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 0.4396 - accuracy: 0.8482Epoch 50/75\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.2336 - accuracy: 0.8951\n",
      "Epoch 15/75\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.0521 - accuracy: 0.9866\n",
      "Epoch 12/75\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.4574 - accuracy: 0.8438\n",
      " 4/14 [=======>......................] - ETA: 0s - loss: 0.1549 - accuracy: 0.9297Epoch 53/75\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.3302 - accuracy: 0.8817A: 0s - loss: 0.1540 - accuracy: 0.\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.0295 - accuracy: 0.9952Epoch 9/75\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.0280 - accuracy: 0.9955\n",
      "Epoch 20/75\n",
      "14/14 [==============================] - 1s 46ms/step - loss: 0.1666 - accuracy: 0.9420A: 0s - loss: 0.2520 - accuracy: 0.89TA: 0s - loss: 0.0449 - accuracy: 0.\n",
      "12/14 [========================>.....] - ETA: 0s - loss: 1.5310 - accuracy: 0.3620Epoch 67/75\n",
      "14/14 [==============================] - 1s 51ms/step - loss: 1.5176 - accuracy: 0.3750\n",
      " 6/14 [===========>..................] - ETA: 0s - loss: 0.2639 - accuracy: 0.8958Epoch 59/75\n",
      "14/14 [==============================] - 1s 54ms/step - loss: 0.4767 - accuracy: 0.8237A: 0s - loss: 0.0366 - accuracy: 0.98\n",
      "Epoch 51/75\n",
      "14/14 [==============================] - 1s 53ms/step - loss: 0.1813 - accuracy: 0.9263- loss: 0.4387 - accuracy: 0.8125 - ETA: 0s - loss: 0.0361 - accuracy: 0.98\n",
      "Epoch 16/75\n",
      "14/14 [==============================] - 1s 49ms/step - loss: 0.0345 - accuracy: 0.9888- loss: 0.1879 - accuracy: 0.9062 - ETA: 0s - loss: 0.0345 - accuracy: 0.98\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.2357 - accuracy: 0.9031Epoch 13/75\n",
      "14/14 [==============================] - 1s 51ms/step - loss: 0.4695 - accuracy: 0.8393\n",
      "Epoch 54/75\n",
      "14/14 [==============================] - 1s 46ms/step - loss: 0.2418 - accuracy: 0.8951\n",
      " 5/14 [=========>....................] - ETA: 0s - loss: 0.2050 - accuracy: 0.9375Epoch 10/75\n",
      "14/14 [==============================] - 1s 50ms/step - loss: 0.0308 - accuracy: 0.9888\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 0.2108 - accuracy: 0.9241Epoch 21/75\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.1519 - accuracy: 0.9531\n",
      "Epoch 68/75\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.5157 - accuracy: 0.8013A: 0s - loss: 0.0314 - accuracy: 0.98\n",
      "Epoch 52/75\n",
      "14/14 [==============================] - 1s 43ms/step - loss: 1.5166 - accuracy: 0.3750\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.4135 - accuracy: 0.8750Epoch 60/75\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.2179 - accuracy: 0.9174\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 1.5995 - accuracy: 0.2500Epoch 17/75\n",
      "14/14 [==============================] - 1s 35ms/step - loss: 0.4479 - accuracy: 0.8482\n",
      "Epoch 55/75\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0544 - accuracy: 0.9844\n",
      "Epoch 22/75\n",
      "14/14 [==============================] - 1s 46ms/step - loss: 0.0271 - accuracy: 0.9933\n",
      " 5/14 [=========>....................] - ETA: 0s - loss: 0.1968 - accuracy: 0.8938Epoch 14/75\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.2381 - accuracy: 0.8973A: 0s - loss: 1.5487 - accuracy: 0.3259\n",
      "Epoch 11/75\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.1987 - accuracy: 0.9330\n",
      "Epoch 69/75\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.4648 - accuracy: 0.8304\n",
      "Epoch 53/75\n",
      "14/14 [==============================] - 0s 37ms/step - loss: 1.5168 - accuracy: 0.3750\n",
      " - ETA: 0s - loss: 0.1837 - accuracy: 0.9038Epoch 61/75\n",
      "14/14 [==============================] - 1s 35ms/step - loss: 0.1822 - accuracy: 0.9063\n",
      "Epoch 18/75\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.4353 - accuracy: 0.8438\n",
      "Epoch 56/75\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.0370 - accuracy: 0.9911\n",
      " 2/14 [===>..........................] - ETA: 0s - loss: 0.1126 - accuracy: 0.9688Epoch 23/75\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.0206 - accuracy: 0.9978A: 0s - loss: 0.0257 - accuracy: 1.00\n",
      "Epoch 15/75\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.2038 - accuracy: 0.9040\n",
      "Epoch 12/75\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.1625 - accuracy: 0.9464A: 0s - loss: 0.1590 - accuracy: 0.94\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.0852 - accuracy: 0.9688Epoch 70/75\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.4971 - accuracy: 0.8170\n",
      "Epoch 54/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.4393 - accuracy: 0.8438\n",
      " 6/14 [===========>..................] - ETA: 0s - loss: 0.0443 - accuracy: 0.9844Epoch 57/75\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 1.5157 - accuracy: 0.3750\n",
      "Epoch 62/75\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.1707 - accuracy: 0.9219A: 0s - loss: 0.1626 - accuracy: 0.94\n",
      "Epoch 19/75\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.0216 - accuracy: 0.9955\n",
      "Epoch 24/75\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.0398 - accuracy: 0.9888\n",
      "Epoch 16/75\n",
      "14/14 [==============================] - 1s 35ms/step - loss: 0.2028 - accuracy: 0.9174\n",
      "Epoch 13/75\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.1352 - accuracy: 0.9576\n",
      " 8/14 [================>.............] - ETA: 0s - loss: 0.0110 - accuracy: 1.0000Epoch 71/75\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.4499 - accuracy: 0.8237\n",
      "12/14 [========================>.....] - ETA: 0s - loss: 0.0106 - accuracy: 1.0000Epoch 55/75\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0109 - accuracy: 1.0000A: 0s - loss: 0.0354 - accuracy: 0.98\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 1.5148 - accuracy: 0.3750Epoch 25/75\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.4176 - accuracy: 0.8438\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.1902 - accuracy: 0.9303Epoch 58/75\n",
      " 7/14 [==============>...............]14/14 [==============================] - ETA: 0s - loss: 0.2140 - accuracy: 0.8973 - 0s 37ms/step - loss: 1.5178 - accuracy: 0.3750\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 0.4196 - accuracy: 0.8854Epoch 63/75\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.1894 - accuracy: 0.9330\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 0.1915 - accuracy: 0.9330Epoch 20/75\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.2054 - accuracy: 0.9040\n",
      "Epoch 14/75\n",
      "14/14 [==============================] - 1s 36ms/step - loss: 0.0321 - accuracy: 0.9888\n",
      "Epoch 17/75\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.1748 - accuracy: 0.9420\n",
      "Epoch 72/75\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0092 - accuracy: 1.0000- loss: 0.4223 - accuracy: 0.8551 - ETA: 0s - loss: 0.1264 - accuracy: 0.96\n",
      "Epoch 26/75\n",
      "14/14 [==============================] - 1s 36ms/step - loss: 0.4263 - accuracy: 0.8415\n",
      "Epoch 56/75\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.4675 - accuracy: 0.8415\n",
      "Epoch 59/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.1877 - accuracy: 0.9196A: 0s - loss: 0.1833 - accuracy: 0.9255\n",
      "Epoch 21/75\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 1.5152 - accuracy: 0.3750\n",
      "Epoch 64/75\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.1718 - accuracy: 0.9286\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.1861 - accuracy: 0.9281Epoch 15/75\n",
      "14/14 [==============================] - ETA: 0s - loss: 1.5523 - accuracy: 0.3320 - 0s 27ms/step - loss: 0.0404 - accuracy: 0.9888\n",
      "Epoch 27/75\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.1866 - accuracy: 0.9330- loss: 0.1866 - accuracy: 0.9330 - ETA: 0s - loss: 0.0223 - accuracy: 0.99\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.0595 - accuracy: 1.0000Epoch 73/75\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.4679 - accuracy: 0.8058\n",
      "Epoch 60/75\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.0204 - accuracy: 0.9955A: 0s - loss: 0.5333 - accuracy: 0.87\n",
      "Epoch 18/75\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.4405 - accuracy: 0.8304\n",
      "11/14 [======================>.......] - ETA: 0s - loss: 1.5234 - accuracy: 0.3608Epoch 57/75\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 1.5120 - accuracy: 0.3750\n",
      " 8/14 [================>.............] - ETA: 0s - loss: 0.0340 - accuracy: 0.9922Epoch 65/75\n",
      "14/14 [==============================] - 1s 46ms/step - loss: 0.1750 - accuracy: 0.9263\n",
      "Epoch 22/75\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.1835 - accuracy: 0.9263\n",
      " 5/14 [=========>....................] - ETA: 0s - loss: 0.0181 - accuracy: 0.9938Epoch 16/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.0276 - accuracy: 0.9955\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 0.1496 - accuracy: 0.9583Epoch 28/75\n",
      "14/14 [==============================] 5/14 [=========>....................] - 0s 32ms/step - loss: 0.1727 - accuracy: 0.9420\n",
      " - ETA: 0s - loss: 1.5370 - accuracy: 0.3688Epoch 74/75\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.4351 - accuracy: 0.8504\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 1.5453 - accuracy: 0.3472Epoch 61/75\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 0.0333 - accuracy: 0.9933A: 0s - loss: 1.5364 - accuracy: 0.35\n",
      "Epoch 19/75\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 1.5143 - accuracy: 0.3750\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.7317 - accuracy: 0.7009\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.0108 - accuracy: 0.9969Epoch 58/75\n",
      "Epoch 66/75\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 0.1887 - accuracy: 0.9241\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.0087 - accuracy: 0.9978\n",
      "Epoch 23/75\n",
      "Epoch 29/75\n",
      "14/14 [==============================] - 1s 43ms/step - loss: 0.1699 - accuracy: 0.9219\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.1843 - accuracy: 0.9688Epoch 17/75\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.2250 - accuracy: 0.9241\n",
      "Epoch 75/75\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 0.4177 - accuracy: 0.8571\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.0895 - accuracy: 0.9594Epoch 62/75\n",
      "14/14 [==============================] - 1s 43ms/step - loss: 0.0762 - accuracy: 0.9665A: 0s - loss: 0.4240 - accuracy: 0.84\n",
      "Epoch 20/75\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 1.5117 - accuracy: 0.3750\n",
      "Epoch 67/75\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.0085 - accuracy: 0.9978\n",
      "12/14 [========================>.....] - ETA: 0s - loss: 0.1712 - accuracy: 0.9245Epoch 30/75\n",
      "14/14 [==============================] - 1s 44ms/step - loss: 1.1402 - accuracy: 0.4576\n",
      "Epoch 59/75\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.1433 - accuracy: 0.9397\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.4471 - accuracy: 0.8438Epoch 24/75\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.1677 - accuracy: 0.9241\n",
      "Epoch 18/75\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.2860 - accuracy: 0.9063\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.4502 - accuracy: 0.8527\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 0.7933 - accuracy: 0.6429Epoch 63/75\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.0485 - accuracy: 0.9777\n",
      "Epoch 21/75\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.1871 - accuracy: 0.9330\n",
      "Epoch 25/75\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 1.5172 - accuracy: 0.3750\n",
      "14/14 [==============================] - 1s 35ms/step - loss: 0.0092 - accuracy: 0.9978\n",
      "Epoch 68/75\n",
      "Epoch 31/75\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.7417 - accuracy: 0.6942\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 1.4673 - accuracy: 0.4688Epoch 60/75\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.1528 - accuracy: 0.9196\n",
      " 6/14 [===========>..................] - ETA: 0s - loss: 0.1708 - accuracy: 0.9323Epoch 19/75\n",
      " 4/14 [=======>......................] - ETA: 0s - loss: 1.5243 - accuracy: 0.3672"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:29:23.749402: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 34ms/step - loss: 0.4325 - accuracy: 0.8460A: 0s - loss: 0.2465 - accuracy: 0.90\n",
      "Epoch 64/75\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.2545 - accuracy: 0.8846 - 0s 31ms/step - loss: 0.1579 - accuracy: 0.9375\n",
      "12/14 [========================>.....] - ETA: 0s - loss: 0.0090 - accuracy: 0.9974Epoch 26/75\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.0091 - accuracy: 0.9978\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.2804 - accuracy: 0.9375Epoch 32/75\n",
      "14/14 [==============================] - 1s 35ms/step - loss: 0.0194 - accuracy: 1.0000\n",
      "Epoch 22/75\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 1.5166 - accuracy: 0.3750\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.0601 - accuracy: 0.9688Epoch 69/75\n",
      "14/14 [==============================] - 1s 35ms/step - loss: 0.8266 - accuracy: 0.6384\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 0.0279 - accuracy: 0.9896Epoch 61/75\n",
      "4/4 [==============================] - 1s 120ms/step - loss: 0.2356 - accuracy: 0.9821\n",
      "[CV 1/5] END ...epochs=75, layers=2, neurons=20;, score=0.982 total time=  40.8s\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.1883 - accuracy: 0.9107\n",
      "Epoch 20/75\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.4382 - accuracy: 0.8348\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 0.7243 - accuracy: 0.7083Epoch 65/75\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.0180 - accuracy: 0.9933\n",
      "Epoch 33/75\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.1858 - accuracy: 0.9397\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 1.5137 - accuracy: 0.3822Epoch 27/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 1.5159 - accuracy: 0.3750\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.0196 - accuracy: 0.9955\n",
      "Epoch 70/75\n",
      " - ETA: 0s - loss: 0.4201 - accuracy: 0.8281 4/14 [=======>......................] - ETA: 0s - loss: 0.0132 - accuracy: 1.0000Epoch 23/75\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.6987 - accuracy: 0.7076\n",
      "Epoch 62/75\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.4014 - accuracy: 0.8460\n",
      "Epoch 66/75\n",
      "14/14 [==============================] - 1s 44ms/step - loss: 0.1442 - accuracy: 0.9353- loss: 0.1642 - accuracy: 0.9281 - ETA: 0s - loss: 0.3609 - accuracy: 0.84\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 0.3785 - accuracy: 0.8646Epoch 21/75\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.0151 - accuracy: 0.9955\n",
      "Epoch 34/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.1581 - accuracy: 0.9353\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 0.1284 - accuracy: 0.9271Epoch 28/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.0098 - accuracy: 1.0000\n",
      "Epoch 24/75\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 1.5130 - accuracy: 0.3750\n",
      " 8/14 [================>.............] - ETA: 0s - loss: 0.4005 - accuracy: 0.8633Epoch 71/75\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.6348 - accuracy: 0.7277- loss: 0.0076 - accuracy: 1.0000 - ETA: 0s - loss: 0.1287 - accuracy: 0.9420\n",
      "Epoch 63/75\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.4026 - accuracy: 0.8504\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.4392 - accuracy: 0.8438Epoch 67/75\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.0111 - accuracy: 0.9978- loss: 0.0111 - accuracy: 0.9978 - ETA: 0s - loss: 0.1215 - accuracy: 0.94\n",
      "Epoch 35/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.1293 - accuracy: 0.9420\n",
      "Epoch 22/75\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.1676 - accuracy: 0.9308\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.0160 - accuracy: 0.9955\n",
      "11/14 [======================>.......] - ETA: 0s - loss: 0.3935 - accuracy: 0.8608Epoch 29/75\n",
      "Epoch 25/75\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 1.5130 - accuracy: 0.3750\n",
      "Epoch 72/75\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 0.3934 - accuracy: 0.8527\n",
      "12/14 [========================>.....] - ETA: 0s - loss: 0.5516 - accuracy: 0.8047Epoch 68/75\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.5452 - accuracy: 0.8080\n",
      "14/14 [==============================] - 0s 23ms/step - loss: 0.0064 - accuracy: 0.9978\n",
      " 4/14 [=======>......................] - ETA: 0s - loss: 0.3834 - accuracy: 0.8828Epoch 36/75\n",
      "Epoch 64/75\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.1117 - accuracy: 0.9442A: 0s - loss: 0.0019 - accuracy: 1.00\n",
      "Epoch 23/75\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.1713 - accuracy: 0.9353\n",
      "Epoch 30/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.0070 - accuracy: 1.0000\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.1786 - accuracy: 0.9062Epoch 26/75\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.3909 - accuracy: 0.8616\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 0.0100 - accuracy: 1.0000Epoch 69/75\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 1.5138 - accuracy: 0.3750\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.0021 - accuracy: 1.0000 - ETA: 0s - loss: 0.3221 - accuracy: 0.8750Epoch 73/75\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 37/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.4780 - accuracy: 0.8147A: 0s - loss: 0.4780 - accuracy: 0.81\n",
      "Epoch 65/75\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.1575 - accuracy: 0.9196- loss: 0.0015 - accuracy: 1.0000     - ETA: 0s - loss: 1.4893 - accuracy: 0.40\n",
      "Epoch 24/75\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.0087 - accuracy: 1.0000A: 0s - loss: 0.4657 - accuracy: 0.\n",
      "Epoch 27/75\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.4149 - accuracy: 0.8460\n",
      "14/14 [==============================] - 1s 43ms/step - loss: 0.1585 - accuracy: 0.9397\n",
      "Epoch 31/75\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 6.8323e-04 - accuracy: 1.0000Epoch 70/75\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 1.5171 - accuracy: 0.3750\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.1111 - accuracy: 1.0000Epoch 74/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      " 4/14 [=======>......................]Epoch 38/75- loss: 0.3676 - accuracy: 0.8420\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.4679 - accuracy: 0.8214- loss: 0.0013 - accuracy: 1.0000 - ETA: 0s - loss: 0.0014 - accuracy: 1.00\n",
      "Epoch 66/75\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 0.4281 - accuracy: 0.8438Epoch 1/75\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.0974 - accuracy: 0.9531\n",
      "Epoch 25/75\n",
      " - ETA: 0s - loss: 0.1563 - accuracy: 0.930314/14 [==============================] - 0s 34ms/step - loss: 0.0130 - accuracy: 0.9955- loss: 0.0091 - accuracy: 0.99\n",
      " 4/14 [=======>......................] - ETA: 0s - loss: 0.1174 - accuracy: 0.9453Epoch 28/75\n",
      "14/14 [==============================] - ETA: 0s - loss: 1.5135 - accuracy: 0.3781 - 0s 36ms/step - loss: 0.1537 - accuracy: 0.9263\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.0253 - accuracy: 1.0000Epoch 32/75\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.4410 - accuracy: 0.8371A: 0s - loss: 0.0018 - accuracy: 1.00\n",
      "12/14 [========================>.....] - ETA: 0s - loss: 1.5129 - accuracy: 0.3776Epoch 71/75\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.0017 - accuracy: 1.0000A: 0s - loss: 0.4963 - accuracy: 0.80\n",
      "Epoch 39/75\n",
      "14/14 [==============================] - 1s 43ms/step - loss: 1.5156 - accuracy: 0.3750\n",
      "Epoch 75/75\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 0.4989 - accuracy: 0.8080A: 0s - loss: 0.4989 - accuracy: 0.80\n",
      " 6/14 [===========>..................] - ETA: 0s - loss: 0.1479 - accuracy: 0.9635Epoch 67/75\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.1205 - accuracy: 0.9375"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:29:27.158695: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 1s 38ms/step - loss: 0.1203 - accuracy: 0.9375\n",
      "11/14 [======================>.......]Epoch 26/75 - ETA: 0s - loss: 0.0069 - accuracy: 1.0000\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.0082 - accuracy: 0.9978\n",
      "Epoch 29/75\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.1628 - accuracy: 0.9509\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.4088 - accuracy: 0.8630Epoch 33/75\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.4143 - accuracy: 0.8616\n",
      "Epoch 72/75\n",
      "14/14 [==============================] - 1s 34ms/step - loss: 8.8469e-04 - accuracy: 1.0000ss: 1.5132 - accuracy: 0.3702 - ETA: 0s - loss: 9.1621e-04 - accuracy: 1.00\n",
      "Epoch 40/75\n",
      "14/14 [==============================] - 1s 36ms/step - loss: 1.5153 - accuracy: 0.3750\n",
      "14/14 [==============================] - 1s 35ms/step - loss: 0.4471 - accuracy: 0.8348A: 1s - loss: 2.3506 - accuracy: 0.265\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.0787 - accuracy: 0.9688Epoch 68/75\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.0870 - accuracy: 0.9621\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.3964 - accuracy: 0.9062Epoch 27/75\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.2050 - accuracy: 0.9174A: 0s - loss: 1.9410 - accuracy: 0.\n",
      "Epoch 34/75\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.0060 - accuracy: 1.0000\n",
      "Epoch 30/75\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 9.4125e-04 - accuracy: 1.0000\n",
      "Epoch 41/75\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.4336 - accuracy: 0.8438\n",
      "Epoch 73/75\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 1.6904 - accuracy: 0.3281A: 0s - loss: 0.4554 - accuracy: 0.8264\n",
      "11/14 [======================>.......] - ETA: 0s - loss: 0.4490 - accuracy: 0.8267Epoch 2/75\n",
      " - ETA: 0s - loss: 1.4082 - accuracy: 0.406214/14 [==============================] - 0s 35ms/step - loss: 0.4587 - accuracy: 0.8237- loss: 0.2163 - accuracy: 0.92\n",
      "Epoch 69/75\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.1560 - accuracy: 0.9487\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 0.4280 - accuracy: 0.8527Epoch 28/75\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.0011 - accuracy: 1.0000    "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:29:28.203918: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 33ms/step - loss: 0.1976 - accuracy: 0.9286\n",
      "Epoch 35/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.4342 - accuracy: 0.8460\n",
      "Epoch 74/75\n",
      "14/14 [==============================] - 0s 36ms/step - loss: 0.0010 - accuracy: 1.0000- loss: 0.0010 - accuracy: 1.0000 - ETA: 0s - loss: 0.1378 - accuracy: 0.93\n",
      "Epoch 42/75\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.0052 - accuracy: 1.0000\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 3.2366e-04 - accuracy: 1.0000Epoch 31/75\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 1.3557 - accuracy: 0.3973\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 0.3552 - accuracy: 0.89584/4 [==============================]Epoch 3/75\n",
      " - 1s 61ms/step - loss: 1.5030 - accuracy: 0.3750\n",
      "[CV 2/5] END ...epochs=75, layers=2, neurons=20;, score=0.375 total time=  42.2s\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.4576 - accuracy: 0.8304- loss: 1.0998 - accuracy: 0.4688 - ETA: 0s - loss: 0.4598 - accuracy: 0.82\n",
      "Epoch 70/75\n",
      "14/14 [==============================] - 1s 36ms/step - loss: 0.1124 - accuracy: 0.9665\n",
      "Epoch 29/75\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.3873 - accuracy: 0.8683- loss: 1.0827 - accuracy: 0.5268 - ETA: 0s - loss: 0.1537 - accuracy: 0.93\n",
      "Epoch 75/75\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.1617 - accuracy: 0.9286\n",
      "Epoch 36/75\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 6.8131e-04 - accuracy: 1.0000s - loss: 6.8131e-04 - accuracy: 1.00\n",
      "Epoch 43/75\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 1.0497 - accuracy: 0.5670A: 0s - loss: 8.3007e-04 - accuracy: 1.00\n",
      "Epoch 4/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.0059 - accuracy: 1.0000\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 0.4313 - accuracy: 0.8571Epoch 32/75\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.0906 - accuracy: 0.9710- ETA: 0s - loss: 0.0921 - accuracy: 0.97\n",
      "14/14 [==============================] - 1s 36ms/step - loss: 0.4582 - accuracy: 0.8259314/14 [==============================] - ETA: 0s - loss: 0.4582 - accuracy: 0.82\n",
      "Epoch 30/75\n",
      "Epoch 71/75\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 0.4368 - accuracy: 0.8415- loss: 0.7243 - accuracy: 0.7535 - ETA: 0s - loss: 0.4368 - accuracy: 0.84\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 7.0064e-04 - accuracy: 1.0000\n",
      "12/14 [========================>.....] - ETA: 0s - loss: 0.1627 - accuracy: 0.9401Epoch 44/75\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.1718 - accuracy: 0.9375\n",
      " 5/14 [=========>....................] - ETA: 0s - loss: 0.4216 - accuracy: 0.8625Epoch 37/75\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.6852 - accuracy: 0.7589\n",
      "Epoch 5/75\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.0056 - accuracy: 1.0000- loss: 0.0058 - accuracy: 1.0000 - ETA: 0s - loss: 0.2030 - accuracy: 0.92\n",
      "Epoch 33/75\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 7.2949e-04 - accuracy: 1.0000s - loss: 0.4328 - accuracy: 0.83\n",
      "Epoch 45/75\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.4325 - accuracy: 0.8304\n",
      " - ETA: 0s - loss: 0.0055 - accuracy: 1.0000Epoch 72/75\n",
      "14/14 [==============================] - 1s 36ms/step - loss: 0.0852 - accuracy: 0.9799\n",
      "Epoch 31/75\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.4740 - accuracy: 0.8688 - ETA: 0s - loss: 0.5130 - accuracy: 0.7812"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:29:29.776200: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 28ms/step - loss: 0.1950 - accuracy: 0.9263\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.1673 - accuracy: 0.9375Epoch 38/75\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.4944 - accuracy: 0.8594\n",
      "Epoch 6/75\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.0041 - accuracy: 1.0000==============>...............] - ETA: 0s - loss: 0.2261 - accuracy: 0.9688\n",
      " 8/14 [================>.............] - ETA: 0s - loss: 0.1173 - accuracy: 0.9727Epoch 34/75\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 0.2426 - accuracy: 0.9732\n",
      "[CV 4/5] END ...epochs=75, layers=2, neurons=20;, score=0.973 total time=  37.5s\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 6.6505e-04 - accuracy: 1.0000\n",
      "Epoch 46/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.1272 - accuracy: 0.9710\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.3925 - accuracy: 0.8460\n",
      "Epoch 32/75\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 0.0019 - accuracy: 1.0000Epoch 73/75\n",
      "14/14 [==============================] - 0s 37ms/step - loss: 0.1910 - accuracy: 0.9241\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.3154 - accuracy: 0.8973\n",
      "Epoch 7/75\n",
      " 8/14 [================>.............] - ETA: 0s - loss: 0.0014 - accuracy: 1.0000Epoch 39/75\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0014 - accuracy: 1.0000A: 0s - loss: 0.1618 - accuracy: 0.93TA: 0s - loss: 0.4960 - accuracy: 0.78\n",
      "Epoch 1/75\n",
      "Epoch 47/75\n",
      "14/14 [==============================] - 0s 36ms/step - loss: 0.0031 - accuracy: 1.0000\n",
      "Epoch 35/75\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.1149 - accuracy: 0.9754- ETA: 0s - loss: 0.0028 - accuracy: 1.000s - loss: 0.4891 - accuracy: 0.\n",
      "11/14 [======================>.......] - ETA: 0s - loss: 0.1570 - accuracy: 0.9460Epoch 33/75\n",
      "14/14 [==============================] - 1s 36ms/step - loss: 0.4750 - accuracy: 0.8192\n",
      "Epoch 74/75\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.3064 - accuracy: 0.8973\n",
      " 6/14 [===========>..................] - ETA: 0s - loss: 0.0024 - accuracy: 1.0000Epoch 8/75\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.1559 - accuracy: 0.9442\n",
      "Epoch 40/75\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 48/75\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.0091 - accuracy: 0.9978A: 0s - loss: 0.2308 - accuracy: 0.91\n",
      "11/14 [======================>.......] - ETA: 0s - loss: 0.4022 - accuracy: 0.8352Epoch 36/75\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.4185 - accuracy: 0.8393\n",
      "Epoch 75/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.1015 - accuracy: 0.9643\n",
      " - ETA: 0s - loss: 0.1452 - accuracy: 0.9531Epoch 34/75\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.2096 - accuracy: 0.9174\n",
      "Epoch 9/75\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.1494 - accuracy: 0.9464\n",
      "Epoch 41/75\n",
      "14/14 [==============================] - 0s 24ms/step - loss: 9.0769e-04 - accuracy: 1.0000\n",
      "Epoch 49/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.0972 - accuracy: 0.9598- loss: 0.0473 - accuracy: 0.9844 - ETA: 0s - loss: 0.1312 - accuracy: 0.\n",
      "10/14 [====================>.........]Epoch 37/75- loss: 0.1676 - accuracy: 0.93\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.1643 - accuracy: 0.9375\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.4347 - accuracy: 0.8438\n",
      "Epoch 10/75\n",
      "14/14 [==============================] - 0s 22ms/step - loss: 8.3924e-04 - accuracy: 1.0000\n",
      "Epoch 50/75\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.1400 - accuracy: 0.9420\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 0.1014 - accuracy: 0.9688Epoch 42/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.0633 - accuracy: 0.9799\n",
      " 5/14 [=========>....................] - ETA: 0s - loss: 2.8512 - accuracy: 0.5063Epoch 35/75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:29:31.509200: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 26ms/step - loss: 0.1673 - accuracy: 0.9397\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 1.6845 - accuracy: 0.5759\n",
      "Epoch 11/75\n",
      "Epoch 38/75\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 5.4267e-04 - accuracy: 1.0000s - loss: 0.5102 - accuracy: 0.82\n",
      "Epoch 51/75\n",
      "11/14 [======================>.......] - ETA: 0s - loss: 0.0823 - accuracy: 0.9801Epoch 1/75\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.5489 - accuracy: 0.8080\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.0837 - accuracy: 0.9808Epoch 43/75\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.0932 - accuracy: 0.9777\n",
      "Epoch 36/75\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 0.0918 - accuracy: 0.989600"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:29:32.161222: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 2s 46ms/step - loss: 1.6848 - accuracy: 0.3929\n",
      "Epoch 2/75\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.1350 - accuracy: 0.9554\n",
      "Epoch 12/75\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.2264 - accuracy: 0.97320\n",
      "[CV 3/5] END ...epochs=75, layers=2, neurons=20;, score=0.973 total time=  41.5s\n",
      " 3/14 [=====>........................]14/14 [==============================] - 0s 32ms/step - loss: 7.6996e-04 - accuracy: 1.0000\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.7459 - accuracy: 0.6964\n",
      "Epoch 52/75\n",
      "Epoch 39/75\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.8641 - accuracy: 0.7612\n",
      "Epoch 44/75\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.1381 - accuracy: 0.9598\n",
      "Epoch 37/75\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.1164 - accuracy: 0.958300"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:29:32.609492: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 35ms/step - loss: 1.1828 - accuracy: 0.5357A: 0s - loss: 1.1936 - accuracy: 0.5288\n",
      "Epoch 3/75\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 4.1682e-04 - accuracy: 1.0000\n",
      "Epoch 53/75\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.1190 - accuracy: 0.9487\n",
      "Epoch 13/75\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.6437 - accuracy: 0.7723\n",
      "Epoch 40/75\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.3200 - accuracy: 0.8772\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 0.5802 - accuracy: 0.7188Epoch 45/75\n",
      "14/14 [==============================] - 1s 36ms/step - loss: 0.2027 - accuracy: 0.93754/14 [=======>......................] - ETA: 1s - loss: 3.2799 - accuracy: 0.2734\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 0.2952 - accuracy: 0.8958Epoch 38/75\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 3.9485e-04 - accuracy: 1.0000\n",
      "Epoch 54/75\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.8102 - accuracy: 0.6830\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 0.1993 - accuracy: 0.9420Epoch 4/75\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.0820 - accuracy: 0.9732\n",
      "Epoch 14/75\n",
      "14/14 [==============================] - 1s 49ms/step - loss: 2.4014 - accuracy: 0.2723\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.5829 - accuracy: 0.7433\n",
      "Epoch 2/75\n",
      "Epoch 41/75\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.1744 - accuracy: 0.9397\n",
      " 4/14 [=======>......................] - ETA: 0s - loss: 0.5945 - accuracy: 0.7578Epoch 46/75\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 3.8938e-04 - accuracy: 1.0000\n",
      "Epoch 55/75\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.2435 - accuracy: 0.9063\n",
      "Epoch 39/75\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.5809 - accuracy: 0.7031- ETA: 0s - loss: 0.6015 - accuracy: 0.\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.1214 - accuracy: 0.9420\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 0.1450 - accuracy: 0.9420Epoch 5/75\n",
      "Epoch 15/75\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.1441 - accuracy: 0.9375 - 0s 29ms/step - loss: 1.3124 - accuracy: 0.4821\n",
      "Epoch 3/75\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.5310 - accuracy: 0.7589\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 0.2790 - accuracy: 0.9152Epoch 42/75\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.1403 - accuracy: 0.9397\n",
      "Epoch 47/75\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 5.4759e-04 - accuracy: 1.0000\n",
      "Epoch 56/75\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.3180 - accuracy: 0.9063A: 0s - loss: 0.1359 - accuracy: 0.94\n",
      " 4/14 [=======>......................] - ETA: 0s - loss: 7.0286e-04 - accuracy: 1.0000Epoch 40/75\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.9465 - accuracy: 0.6518\n",
      "12/14 [========================>.....] - ETA: 0s - loss: 5.4916e-04 - accuracy: 1.0000Epoch 4/75\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.1031 - accuracy: 0.9665\n",
      "Epoch 16/75\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.1309 - accuracy: 0.9453 - 0s 33ms/step - loss: 0.5024 - accuracy: 0.7857\n",
      "14/14 [==============================] - 0s 23ms/step - loss: 4.9968e-04 - accuracy: 1.0000\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.0460 - accuracy: 1.0000Epoch 43/75\n",
      "Epoch 57/75\n",
      "14/14 [==============================] - 1s 46ms/step - loss: 0.5195 - accuracy: 0.7121\n",
      "Epoch 6/75\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.1406 - accuracy: 0.9442\n",
      "Epoch 48/75\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 0.6156 - accuracy: 0.7723Epoch 1/75s: 0.1075 - accuracy: 0.9375 - ETA: 0s - loss: 0.4790 - accuracy: 0.81\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.3393 - accuracy: 0.8817A: 0s - loss: 0.4775 - accuracy: 0.79\n",
      "Epoch 41/75\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.5713 - accuracy: 0.7991\n",
      "Epoch 5/75\n",
      "14/14 [==============================] - 0s 24ms/step - loss: 3.3028e-04 - accuracy: 1.0000\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.1579 - accuracy: 0.9281Epoch 58/75\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.0796 - accuracy: 0.9754\n",
      " 5/14 [=========>....................] - ETA: 0s - loss: 0.2888 - accuracy: 0.8938Epoch 17/75\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.4530 - accuracy: 0.7188\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.4955 - accuracy: 0.7788Epoch 7/75\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.4939 - accuracy: 0.7768\n",
      "Epoch 44/75\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.1562 - accuracy: 0.9286\n",
      " 5/14 [=========>....................] - ETA: 0s - loss: 0.4283 - accuracy: 0.8125Epoch 49/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.2830 - accuracy: 0.9107\n",
      " 8/14 [================>.............] - ETA: 0s - loss: 0.4638 - accuracy: 0.8242Epoch 42/75\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.3681 - accuracy: 0.8817\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 3.7259e-04 - accuracy: 1.0000\n",
      "Epoch 6/75\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.4677 - accuracy: 0.7604Epoch 59/75\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.0984 - accuracy: 0.9621\n",
      "Epoch 18/75\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.4755 - accuracy: 0.7879\n",
      "Epoch 45/75\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.4481 - accuracy: 0.7879\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.0445 - accuracy: 0.9688Epoch 8/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.1480 - accuracy: 0.9397- loss: 0.4338 - accuracy: 0.7812 - ETA: 0s - loss: 0.5020 - accuracy: 0.71\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 0.2644 - accuracy: 0.9464Epoch 50/75\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 3.4620e-04 - accuracy: 1.0000s - loss: 0.0689 - accuracy: 0.97\n",
      "Epoch 60/75\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.2488 - accuracy: 0.9397A: 0s - loss: 0.1280 - accuracy: 0.95\n",
      "Epoch 7/75\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.2358 - accuracy: 0.9219\n",
      "Epoch 43/75\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.1215 - accuracy: 0.9514"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:29:35.521350: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 30ms/step - loss: 0.0945 - accuracy: 0.9598\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 0.1616 - accuracy: 0.9479Epoch 19/75\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.3736 - accuracy: 0.8638\n",
      "Epoch 9/75\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.4723 - accuracy: 0.7813\n",
      "Epoch 46/75\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.1412 - accuracy: 0.9442\n",
      " 5/14 [=========>....................] - ETA: 0s - loss: 0.2066 - accuracy: 0.9250Epoch 51/75\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 3.5784e-04 - accuracy: 1.0000\n",
      " 5/14 [=========>....................] - ETA: 0s - loss: 0.4002 - accuracy: 0.8500Epoch 61/75\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.1856 - accuracy: 0.9531A: 0s - loss: 0.4450 - accuracy: 0.76\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 0.4016 - accuracy: 0.8661Epoch 8/75\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.1641 - accuracy: 0.9464\n",
      "Epoch 44/75\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.1065 - accuracy: 0.9531\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.2771 - accuracy: 0.9688Epoch 20/75\n",
      "14/14 [==============================] - 2s 31ms/step - loss: 2.0409 - accuracy: 0.2969\n",
      "Epoch 2/75\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.3657 - accuracy: 0.8750\n",
      "Epoch 10/75\n",
      "14/14 [==============================] - 0s 21ms/step - loss: 3.7685e-04 - accuracy: 1.0000\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.1585 - accuracy: 0.9353\n",
      "Epoch 62/75\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.4304 - accuracy: 0.8029Epoch 52/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.4353 - accuracy: 0.7902\n",
      " 4/14 [=======>......................] - ETA: 0s - loss: 0.1613 - accuracy: 0.9453Epoch 47/75\n",
      "14/14 [==============================] - 0s 24ms/step - loss: 0.1730 - accuracy: 0.9598\n",
      "Epoch 9/75\n",
      "14/14 [==============================] - 0s 20ms/step - loss: 7.1393e-04 - accuracy: 1.0000ss: 0.1365 - accuracy: 0.9479 - ETA: 0s - loss: 1.4493 - accuracy: 0.3812\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.1455 - accuracy: 0.9563Epoch 63/75\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.1493 - accuracy: 0.9442\n",
      "Epoch 21/75\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.1683 - accuracy: 0.9598\n",
      "Epoch 45/75\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.1484 - accuracy: 0.9487\n",
      "Epoch 53/75\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.3219 - accuracy: 0.9040\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.1370 - accuracy: 0.9688Epoch 11/75\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 1.3135 - accuracy: 0.4799\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 0.2433 - accuracy: 0.9062Epoch 3/75\n",
      "14/14 [==============================] - 0s 24ms/step - loss: 0.1567 - accuracy: 0.9576\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 9.5019e-04 - accuracy: 1.0000Epoch 10/75\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.4280 - accuracy: 0.7924\n",
      "Epoch 48/75\n",
      " 6/14 [===========>..................]14/14 [==============================] - ETA: 0s - loss: 0.2617 - accuracy: 0.9323 - 0s 21ms/step - loss: 0.0010 - accuracy: 1.0000\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 0.1249 - accuracy: 0.9509Epoch 64/75\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.2840 - accuracy: 0.8795A: 0s - loss: 0.1084 - accuracy: 0.\n",
      "12/14 [========================>.....] - ETA: 0s - loss: 0.2471 - accuracy: 0.9401Epoch 22/75\n",
      "14/14 [==============================] - 0s 24ms/step - loss: 0.0994 - accuracy: 0.9732\n",
      "Epoch 11/75\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.1160 - accuracy: 0.9442\n",
      "Epoch 54/75\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.2644 - accuracy: 0.9263\n",
      "Epoch 12/75\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.1158 - accuracy: 0.9531\n",
      "Epoch 46/75\n",
      "14/14 [==============================] - 0s 19ms/step - loss: 8.0589e-04 - accuracy: 1.0000\n",
      "Epoch 65/75\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.7154 - accuracy: 0.7924\n",
      "Epoch 4/75\n",
      "14/14 [==============================] - 0s 36ms/step - loss: 0.4255 - accuracy: 0.7946\n",
      "Epoch 49/75\n",
      "14/14 [==============================] - 0s 22ms/step - loss: 0.0670 - accuracy: 0.9777\n",
      "Epoch 12/75\n",
      "14/14 [==============================] - 0s 19ms/step - loss: 2.7523e-04 - accuracy: 1.0000\n",
      "Epoch 66/75\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.1799 - accuracy: 0.9375- loss: 0.2704 - accuracy: 0.9148 - ETA: 0s - loss: 2.3047e-04 - accuracy: 1.00\n",
      "Epoch 23/75\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.1417 - accuracy: 0.9487\n",
      " 5/14 [=========>....................] - ETA: 0s - loss: 0.4245 - accuracy: 0.7625Epoch 55/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.2802 - accuracy: 0.9129- loss: 0.0843 - accuracy: 0.9635 - ETA: 0s - loss: 0.1957 - accuracy: 0.92\n",
      "12/14 [========================>.....] - ETA: 0s - loss: 0.3755 - accuracy: 0.9036Epoch 13/75\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.3618 - accuracy: 0.9085\n",
      "Epoch 5/75\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.1226 - accuracy: 0.9665\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 3.4262e-04 - accuracy: 1.0000Epoch 47/75\n",
      "14/14 [==============================] - 0s 23ms/step - loss: 3.1867e-04 - accuracy: 1.0000ss: 0.0722 - accuracy: 0.9750 - ETA: 0s - loss: 0.1367 - accuracy: 0.94\n",
      "Epoch 67/75\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.4183 - accuracy: 0.7813\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.0802 - accuracy: 0.9710\n",
      "Epoch 50/75\n",
      "Epoch 13/75\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.1447 - accuracy: 0.9330\n",
      "Epoch 56/75\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.1447 - accuracy: 0.9397\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.0989 - accuracy: 0.9375Epoch 24/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.2197 - accuracy: 0.9420\n",
      " 8/14 [================>.............] - ETA: 0s - loss: 0.3762 - accuracy: 0.8359Epoch 14/75\n",
      "14/14 [==============================] - 0s 22ms/step - loss: 3.3272e-04 - accuracy: 1.0000\n",
      "Epoch 68/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.2033 - accuracy: 0.9442\n",
      "Epoch 6/75\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.0972 - accuracy: 0.9732\n",
      " 8/14 [================>.............] - ETA: 0s - loss: 0.0758 - accuracy: 0.97Epoch 48/75\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.0796 - accuracy: 0.9665\n",
      "Epoch 14/75\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.1402 - accuracy: 0.9308\n",
      "Epoch 57/75\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.3941 - accuracy: 0.8147- loss: 3.4829e-04 - accuracy: 1.0000 - ETA: 0s - loss: 0.3941 - accuracy: 0.81\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.1172 - accuracy: 0.9375Epoch 51/75\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0976 - accuracy: 0.9576\n",
      "Epoch 25/75\n",
      "14/14 [==============================] - 0s 20ms/step - loss: 3.0556e-04 - accuracy: 1.0000\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 0.1106 - accuracy: 0.9643Epoch 69/75\n",
      "14/14 [==============================] - 0s 23ms/step - loss: 0.0749 - accuracy: 0.9799\n",
      "Epoch 15/75\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.2458 - accuracy: 0.9196\n",
      "Epoch 15/75\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.0947 - accuracy: 0.9888A: 0s - loss: 0.1130 - accuracy: 0.96\n",
      "Epoch 7/75\n",
      "14/14 [==============================] - 0s 36ms/step - loss: 0.0951 - accuracy: 0.9688- loss: 0.3909 - accuracy: 0.8203 - ETA: 0s - loss: 0.0975 - accuracy: 0.9663\n",
      "12/14 [========================>.....] - ETA: 0s - loss: 0.0836 - accuracy: 0.9583Epoch 49/75\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.1199 - accuracy: 0.9487\n",
      "Epoch 58/75\n",
      "14/14 [==============================] - 0s 21ms/step - loss: 3.0569e-04 - accuracy: 1.0000\n",
      " 8/14 [================>.............] - ETA: 0s - loss: 0.0787 - accuracy: 0.9727Epoch 70/75\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0843 - accuracy: 0.9576\n",
      "Epoch 26/75\n",
      "14/14 [==============================] - 0s 36ms/step - loss: 0.4001 - accuracy: 0.7991\n",
      "Epoch 52/75\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.0708 - accuracy: 0.9754\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.3907 - accuracy: 0.7812Epoch 16/75\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.2273 - accuracy: 0.9420\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.1542 - accuracy: 0.9406Epoch 16/75\n",
      "14/14 [==============================] - 0s 19ms/step - loss: 1.9117e-04 - accuracy: 1.0000\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.0612 - accuracy: 0.9722Epoch 71/75\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0715 - accuracy: 0.9866\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 0.2332 - accuracy: 0.9167Epoch 8/75\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.1521 - accuracy: 0.9397\n",
      "11/14 [======================>.......] - ETA: 0s - loss: 0.0678 - accuracy: 0.9688Epoch 59/75\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.0654 - accuracy: 0.9688- loss: 0.1451 - accuracy: 0.9375 - ETA: 0s - loss: 0.0579 - accuracy: 1.\n",
      "Epoch 27/75\n",
      "14/14 [==============================] - 1s 36ms/step - loss: 0.1280 - accuracy: 0.9688\n",
      "Epoch 50/75\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.0818 - accuracy: 0.9732\n",
      "Epoch 17/75\n",
      "14/14 [==============================] - 0s 20ms/step - loss: 2.3576e-04 - accuracy: 1.0000\n",
      "Epoch 72/75\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.3911 - accuracy: 0.8371\n",
      "11/14 [======================>.......] - ETA: 0s - loss: 0.1451 - accuracy: 0.9261Epoch 53/75\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.2480 - accuracy: 0.9241\n",
      "Epoch 17/75\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.1422 - accuracy: 0.9353\n",
      " 6/14 [===========>..................]Epoch 60/75\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.0461 - accuracy: 0.9911\n",
      "Epoch 9/75\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0883 - accuracy: 0.9554\n",
      "Epoch 28/75\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 0.0687 - accuracy: 0.9799\n",
      "Epoch 18/75\n",
      "14/14 [==============================] - 0s 23ms/step - loss: 2.4906e-04 - accuracy: 1.0000\n",
      "Epoch 73/75\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.1119 - accuracy: 0.9710A: 0s - loss: 0.1914 - accuracy: 0.9375\n",
      "Epoch 51/75\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.4043 - accuracy: 0.8304\n",
      "Epoch 54/75\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.2400 - accuracy: 0.9330\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.2796 - accuracy: 0.7812Epoch 18/75\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.1362 - accuracy: 0.9509\n",
      "Epoch 61/75\n",
      "14/14 [==============================] - 0s 19ms/step - loss: 3.8746e-04 - accuracy: 1.0000\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0247 - accuracy: 0.9978\n",
      "Epoch 74/75\n",
      "Epoch 10/75\n",
      "14/14 [==============================] - 0s 24ms/step - loss: 0.0592 - accuracy: 0.9911\n",
      "Epoch 19/75\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.0998 - accuracy: 0.9643\n",
      "Epoch 29/75\n",
      " - 0s 34ms/step - loss: 0.1051 - accuracy: 0.9688- loss: 0.1218 - accuracy: 0.951.00 ETA: 0s - loss: 0.1063 - accuracy: 0.95\n",
      " 8/14 [================>.............] - ETA: 0s - loss: 0.0161 - accuracy: 0.9961Epoch 52/75\n",
      "14/14 [==============================] - 0s 18ms/step - loss: 2.7973e-04 - accuracy: 1.0000\n",
      "11/14 [======================>.......] - ETA: 0s - loss: 0.3690 - accuracy: 0.8580Epoch 75/75\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.1300 - accuracy: 0.9531\n",
      "Epoch 62/75\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.3675 - accuracy: 0.8661\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.2574 - accuracy: 0.9152\n",
      "12/14 [========================>.....]Epoch 55/75\n",
      " - ETA: 0s - loss: 0.0162 - accuracy: 0.9974Epoch 19/75\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.0586 - accuracy: 0.9799\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.2850 - accuracy: 0.9062Epoch 20/75\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.0152 - accuracy: 0.9978\n",
      "Epoch 11/75\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0932 - accuracy: 0.9621\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.0107 - accuracy: 1.0000Epoch 30/75\n",
      "14/14 [==============================] - 0s 19ms/step - loss: 2.4693e-04 - accuracy: 1.0000\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.1284 - accuracy: 0.9420\n",
      "Epoch 63/75\n",
      "14/14 [==============================] - 0s 22ms/step - loss: 0.0451 - accuracy: 0.9933\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.0766 - accuracy: 0.9832Epoch 21/75\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.2413 - accuracy: 0.9219\n",
      "Epoch 20/75\n",
      "14/14 [==============================] - 1s 36ms/step - loss: 0.0798 - accuracy: 0.9821\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.0595 - accuracy: 0.9688Epoch 53/75\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 0.0537 - accuracy: 0.9754\n",
      "Epoch 31/75\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0161 - accuracy: 0.9955\n",
      "Epoch 12/75\n",
      "14/14 [==============================] - 1s 36ms/step - loss: 0.3618 - accuracy: 0.8839\n",
      "Epoch 56/75\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 0.0908 - accuracy: 0.9479"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:29:40.467757: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 21ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "[CV 5/5] END ...epochs=75, layers=2, neurons=20;, score=1.000 total time=  35.3s\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.1445 - accuracy: 0.9442\n",
      "Epoch 64/75\n",
      "14/14 [==============================] - 0s 24ms/step - loss: 0.0388 - accuracy: 0.9911\n",
      "Epoch 22/75\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.2238 - accuracy: 0.9308\n",
      "Epoch 21/75\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.1027 - accuracy: 0.9531\n",
      "Epoch 32/75\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.0234 - accuracy: 0.9933\n",
      "Epoch 13/75\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.1069 - accuracy: 0.9754\n",
      "11/14 [======================>.......] - ETA: 0s - loss: 0.3440 - accuracy: 0.8750Epoch 54/75\n",
      "14/14 [==============================] - 0s 22ms/step - loss: 0.0688 - accuracy: 0.9821A: 0s - loss: 0.2441 - accuracy: 0.93TA: 0s - loss: 0.0584 - accuracy: 0.98\n",
      "Epoch 23/75\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.3532 - accuracy: 0.8638\n",
      "Epoch 57/75\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.1249 - accuracy: 0.9509\n",
      "Epoch 65/75\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.2436 - accuracy: 0.9241A: 0s - loss: 0.1774 - accuracy: 0.\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.0678 - accuracy: 0.9792Epoch 22/75\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.0906 - accuracy: 0.9598\n",
      "Epoch 33/75\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.0427 - accuracy: 0.9911A: 0s - loss: 0.0453 - accuracy: 0.99\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 0.2359 - accuracy: 0.9688Epoch 14/75\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.0777 - accuracy: 0.9732\n",
      "Epoch 24/75\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.0846 - accuracy: 0.9710\n",
      "Epoch 55/75\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.1152 - accuracy: 0.9487\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 0.0374 - accuracy: 0.9896Epoch 66/75\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.3478 - accuracy: 0.9152\n",
      " 5/14 [=========>....................] - ETA: 0s - loss: 0.0451 - accuracy: 0.9875Epoch 58/75\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.0884 - accuracy: 0.9594 7/14 [==============>...............] - ETA: 0s - loss: 0.0461 - accuracy: 0.9866Epoch 1/75\n",
      "14/14 [==============================] - 0s 19ms/step - loss: 0.0457 - accuracy: 0.9888- loss: 0.0849 - accuracy: 0.9732 - ETA: 0s - loss: 0.1271 - accuracy: 0.94\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.2219 - accuracy: 0.9375\n",
      "Epoch 25/75\n",
      "Epoch 23/75\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0711 - accuracy: 0.9688\n",
      "Epoch 34/75\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.0344 - accuracy: 0.9911\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 0.3062 - accuracy: 0.9167Epoch 15/75\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.1312 - accuracy: 0.9464\n",
      "Epoch 67/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.0920 - accuracy: 0.9710- loss: 0.2773 - accuracy: 0.9152 - ETA: 0s - loss: 0.0840 - accuracy: 0.95\n",
      "Epoch 56/75\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.2712 - accuracy: 0.9167"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:29:41.881477: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 32ms/step - loss: 0.3528 - accuracy: 0.9129\n",
      "Epoch 59/75\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.0596 - accuracy: 0.9799\n",
      "Epoch 26/75\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0670 - accuracy: 0.9710\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.1134 - accuracy: 0.9438Epoch 35/75\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.2545 - accuracy: 0.9196\n",
      "Epoch 24/75\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.1133 - accuracy: 0.9487\n",
      "Epoch 68/75\n",
      "14/14 [==============================] - 0s 36ms/step - loss: 0.0666 - accuracy: 0.9799\n",
      "14/14 [==============================] - 1s 24ms/step - loss: 1.9701 - accuracy: 0.2879\n",
      "Epoch 16/75\n",
      "Epoch 2/75\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.0876 - accuracy: 0.9754\n",
      "14/14 [==============================] - 0s 23ms/step - loss: 0.0754 - accuracy: 0.9754\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 0.1273 - accuracy: 0.9554Epoch 27/75\n",
      "Epoch 57/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.3219 - accuracy: 0.9174\n",
      "Epoch 60/75\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.0467 - accuracy: 0.9821\n",
      "Epoch 36/75\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.2062 - accuracy: 0.9442\n",
      "Epoch 25/75\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.1078 - accuracy: 0.9665A: 0s - loss: 0.1078 - accuracy: 0.96\n",
      "Epoch 69/75\n",
      "14/14 [==============================] - 0s 22ms/step - loss: 1.1929 - accuracy: 0.5067\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.0542 - accuracy: 0.9875Epoch 3/75\n",
      "14/14 [==============================] - 0s 22ms/step - loss: 0.0543 - accuracy: 0.9888A: 0s - loss: 0.0811 - accuracy: 0.96\n",
      "Epoch 28/75\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.0487 - accuracy: 0.9844\n",
      "Epoch 17/75\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.0651 - accuracy: 0.9732\n",
      " - 0s 19ms/step - loss: 0.7786 - accuracy: 0.7210\n",
      "Epoch 4/75\n",
      "Epoch 37/75\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.0577 - accuracy: 0.9821\n",
      "Epoch 58/75\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.1338 - accuracy: 0.9531\n",
      "14/14 [==============================] - 0s 36ms/step - loss: 0.3111 - accuracy: 0.9286\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 0.0443 - accuracy: 0.9896Epoch 70/75\n",
      "Epoch 61/75\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.2572 - accuracy: 0.9107\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.0722 - accuracy: 0.9856Epoch 26/75\n",
      "14/14 [==============================] - 0s 21ms/step - loss: 0.0758 - accuracy: 0.9799\n",
      "Epoch 29/75\n",
      "14/14 [==============================] - 0s 18ms/step - loss: 0.4517 - accuracy: 0.8549\n",
      "Epoch 5/75\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.0326 - accuracy: 0.9911A: 0s - loss: 0.2772 - accuracy: 0.93\n",
      "Epoch 18/75\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0526 - accuracy: 0.9777\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 0.2325 - accuracy: 0.9464Epoch 38/75\n",
      "14/14 [==============================] - 0s 23ms/step - loss: 0.0404 - accuracy: 0.9933\n",
      "Epoch 30/75\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.0817 - accuracy: 0.9732\n",
      "Epoch 59/75\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0984 - accuracy: 0.9621\n",
      "Epoch 71/75\n",
      "14/14 [==============================] - 0s 19ms/step - loss: 0.2174 - accuracy: 0.9464\n",
      "Epoch 6/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.2026 - accuracy: 0.9442A: 0s - loss: 0.3204 - accuracy: 0.93\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.2518 - accuracy: 0.9375Epoch 27/75\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.3213 - accuracy: 0.9330\n",
      "Epoch 62/75\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0594 - accuracy: 0.9732- loss: 0.0586 - accuracy: 0.9736 - ETA: 0s - loss: 0.1496 - accuracy: 0.93\n",
      "Epoch 19/75\n",
      "14/14 [==============================] - 0s 24ms/step - loss: 0.0395 - accuracy: 0.9933\n",
      " 5/14 [=========>....................] - ETA: 0s - loss: 0.2945 - accuracy: 0.9125Epoch 31/75\n",
      "14/14 [==============================] - 0s 19ms/step - loss: 0.1688 - accuracy: 0.9487\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 0.2308 - accuracy: 0.9420Epoch 7/75\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0592 - accuracy: 0.9688\n",
      "Epoch 39/75\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 0.1269 - accuracy: 0.9509\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 0.3248 - accuracy: 0.9241Epoch 72/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.0697 - accuracy: 0.9821\n",
      "Epoch 60/75\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.2081 - accuracy: 0.9442\n",
      "Epoch 28/75\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.3240 - accuracy: 0.9129\n",
      "Epoch 63/75\n",
      "14/14 [==============================] - 0s 20ms/step - loss: 0.1436 - accuracy: 0.9531\n",
      "Epoch 8/75\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 0.0332 - accuracy: 0.9911\n",
      "Epoch 32/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.0346 - accuracy: 0.9844\n",
      "Epoch 20/75\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 0.0993 - accuracy: 0.9576A: 0s - loss: 0.0035 - accuracy: 1.00\n",
      "Epoch 73/75\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.0399 - accuracy: 0.9799- loss: 0.0615 - accuracy: 0.9688 - ETA: 0s - loss: 0.2590 - accuracy: 0.91\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 0.0903 - accuracy: 0.9777Epoch 40/75\n",
      " 5/14 [=========>....................] - 0s 34ms/step - loss: 0.0896 - accuracy: 0.9710\n",
      "14/14 [==============================] - 0s 21ms/step - loss: 0.0861 - accuracy: 0.9754\n",
      "Epoch 61/75\n",
      "Epoch 9/75\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.0278 - accuracy: 0.9955- loss: 0.3223 - accuracy: 0.9279 - ETA: 0s - loss: 0.0212 - accuracy: 0.99\n",
      "Epoch 33/75\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.3176 - accuracy: 0.9263\n",
      "Epoch 64/75\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.2246 - accuracy: 0.9308\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.0563 - accuracy: 0.9653Epoch 29/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.0176 - accuracy: 0.9955- loss: 0.1144 - accuracy: 0.9792 - ETA: 0s - loss: 0.0923 - accuracy: 0.9\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.1034 - accuracy: 0.9471Epoch 21/75\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.1063 - accuracy: 0.9487\n",
      "Epoch 74/75\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.0536 - accuracy: 0.9688\n",
      "Epoch 41/75\n",
      "14/14 [==============================] - 0s 22ms/step - loss: 0.0983 - accuracy: 0.9754\n",
      "Epoch 10/75\n",
      "14/14 [==============================] - 0s 23ms/step - loss: 0.0344 - accuracy: 0.9888- loss: 0.0043 - accuracy: 1.0000 - ETA: 0s - loss: 0.1314 - accuracy: 0.94\n",
      "Epoch 34/75\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.1041 - accuracy: 0.9732\n",
      "Epoch 62/75\n",
      "14/14 [==============================] - 0s 17ms/step - loss: 0.1029 - accuracy: 0.9754\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.2015 - accuracy: 0.9375\n",
      "Epoch 11/75\n",
      "Epoch 30/75\n",
      "11/14 [======================>.......] - ETA: 0s - loss: 0.0065 - accuracy: 0.9972 - 0s 25ms/step - loss: 0.1236 - accuracy: 0.9487\n",
      "14/14 [==============================] - 1s 36ms/step - loss: 0.3084 - accuracy: 0.9420\n",
      "Epoch 75/75\n",
      "Epoch 65/75\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.0704 - accuracy: 0.9777\n",
      "Epoch 42/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.0069 - accuracy: 0.9978\n",
      "Epoch 22/75\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 0.0357 - accuracy: 0.9933\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 0.1128 - accuracy: 0.9625 - ETA: 0s - loss: 0.0094 - accuracy: 1.0000Epoch 35/75\n",
      "14/14 [==============================] - 0s 21ms/step - loss: 0.0839 - accuracy: 0.9754\n",
      "Epoch 12/75\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.0863 - accuracy: 0.9710A: 0s - loss: 0.1063 - accuracy: 0.95TA: 0s - loss: 0.0525 - accuracy: 0.98\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.2216 - accuracy: 0.9196Epoch 63/75\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.2216 - accuracy: 0.9196\n",
      "Epoch 31/75\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.1079 - accuracy: 0.9576\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.0563 - accuracy: 0.9754\n",
      "Epoch 43/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.3045 - accuracy: 0.9509\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.0986 - accuracy: 0.9375Epoch 66/75\n",
      "14/14 [==============================] - 0s 24ms/step - loss: 0.0303 - accuracy: 0.9933A: 0s - loss: 0.0055 - accuracy: 1.00\n",
      "Epoch 36/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.0053 - accuracy: 1.0000\n",
      "Epoch 23/75\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 0.0458 - accuracy: 0.9866- loss: 0.0426 - accuracy: 0.9750 - ETA: 0s - loss: 0.0458 - accuracy: 0.98\n",
      "Epoch 13/75\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 0.1954 - accuracy: 0.9420\n",
      "Epoch 32/75\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.0234 - accuracy: 0.9969"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:29:45.671595: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 27ms/step - loss: 0.0312 - accuracy: 0.9866\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0058 - accuracy: 1.0000Epoch 44/75\n",
      "14/14 [==============================] - 0s 22ms/step - loss: 0.0438 - accuracy: 0.9955\n",
      "Epoch 37/75\n",
      "14/14 [==============================] - 0s 20ms/step - loss: 0.0246 - accuracy: 0.9955\n",
      "Epoch 14/75\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.0787 - accuracy: 0.9777\n",
      "Epoch 64/75\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.0053 - accuracy: 1.0000\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.0022 - accuracy: 1.0000[CV 1/5] END ...epochs=75, layers=2, neurons=40;, score=1.000 total time=  38.4s\n",
      " 4/14 [=======>......................] - 0s 34ms/step - loss: 0.3163 - accuracy: 0.9174\n",
      " - ETA: 0s - loss: 0.0395 - accuracy: 0.9766Epoch 67/75\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 24/75\n",
      "14/14 [==============================] - 0s 22ms/step - loss: 0.0367 - accuracy: 1.0000A: 0s - loss: 0.0378 - accuracy: 0.98\n",
      "12/14 [========================>.....] - ETA: 0s - loss: 0.2192 - accuracy: 0.9245Epoch 38/75\n",
      "14/14 [==============================] - 0s 20ms/step - loss: 0.0280 - accuracy: 0.9888A: 0s - loss: 0.0264 - accuracy: 0.99\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.0357 - accuracy: 0.9832Epoch 15/75\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.2305 - accuracy: 0.9219\n",
      "Epoch 33/75\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.0371 - accuracy: 0.9821\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.0387 - accuracy: 1.0000Epoch 45/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.0700 - accuracy: 0.9821A: 0s - loss: 0.0171 - accuracy: 0.9896  \n",
      "14/14 [==============================] - 0s 31ms/step - loss: 8.5664e-04 - accuracy: 1.0000\n",
      "Epoch 65/75\n",
      "Epoch 25/75\n",
      "14/14 [==============================] - 1s 36ms/step - loss: 0.2962 - accuracy: 0.9420\n",
      "Epoch 68/75\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0612 - accuracy: 0.9821- loss: 0.0499 - accuracy: 0.9896 - ETA: 0s - loss: 0.1780 - accuracy: 0.9509\n",
      "Epoch 39/75\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.0503 - accuracy: 0.9888\n",
      "Epoch 16/75\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0350 - accuracy: 0.9799\n",
      "Epoch 46/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.2132 - accuracy: 0.9308\n",
      " 4/14 [=======>......................] - ETA: 0s - loss: 0.1547 - accuracy: 0.9688Epoch 34/75\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.0791 - accuracy: 0.9799- loss: 0.0745 - accuracy: 0.9808 - ETA: 0s - loss: 0.1770 - accuracy: 0.93\n",
      "Epoch 66/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 26/75\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.3234 - accuracy: 0.8839\n",
      " - ETA: 0s - loss: 0.0997 - accuracy: 0.9760Epoch 69/75\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0963 - accuracy: 0.9754\n",
      "Epoch 40/75\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.0359 - accuracy: 0.9888\n",
      " 5/14 [=========>....................] - ETA: 0s - loss: 0.0453 - accuracy: 0.9875Epoch 17/75\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0595 - accuracy: 0.9754\n",
      "Epoch 47/75\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.1790 - accuracy: 0.9509\n",
      "Epoch 35/75\n",
      "14/14 [==============================] - 0s 36ms/step - loss: 0.0630 - accuracy: 0.9799\n",
      "Epoch 67/75\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 27/75\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.3340 - accuracy: 0.8862\n",
      "Epoch 70/75\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.0215 - accuracy: 0.9933- loss: 0.0224 - accuracy: 0.9922 - ETA: 0s - loss: 3.0549e-04 - accuracy: 1.00\n",
      "Epoch 18/75\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.0628 - accuracy: 0.9821\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 0.2937 - accuracy: 0.9271Epoch 41/75\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.0562 - accuracy: 0.9799\n",
      "Epoch 48/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.1922 - accuracy: 0.9397\n",
      "Epoch 36/75\n",
      "14/14 [==============================] - 0s 23ms/step - loss: 0.0083 - accuracy: 1.0000A: 0s - loss: 5.5611e-04 - accuracy: 1.\n",
      "Epoch 19/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.0647 - accuracy: 0.9777\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 7.8944e-04 - accuracy: 1.0000\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.0055 - accuracy: 1.0000Epoch 68/75\n",
      "Epoch 28/75\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.3191 - accuracy: 0.9174\n",
      "Epoch 71/75\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0401 - accuracy: 0.9844\n",
      " 4/14 [=======>......................] - ETA: 0s - loss: 0.0046 - accuracy: 1.0000Epoch 42/75\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.0577 - accuracy: 0.9799A: 0s - loss: 0.0557 - accuracy: 0.\n",
      "Epoch 49/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.2243 - accuracy: 0.9174A: 0s - loss: 0.3003 - accuracy: 0.93\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 0.0635 - accuracy: 0.9583Epoch 37/75\n",
      "11/14 [======================>.......] - ETA: 0s - loss: 4.8714e-04 - accuracy: 1.0000Epoch 1/75\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.0117 - accuracy: 0.9978\n",
      "Epoch 20/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 6.7352e-04 - accuracy: 1.0000\n",
      " 5/14 [=========>....................]Epoch 29/75\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.0171 - accuracy: 1.0000\n",
      "Epoch 43/75\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.0836 - accuracy: 0.9665\n",
      "Epoch 69/75\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.2928 - accuracy: 0.9353\n",
      "Epoch 72/75\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.0465 - accuracy: 0.9732\n",
      "Epoch 50/75\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.2402 - accuracy: 0.9018A: 0s - loss: 0.0944 - accuracy: 0.93\n",
      "11/14 [======================>.......] - ETA: 0s - loss: 0.0144 - accuracy: 0.9943Epoch 38/75\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 0.0186 - accuracy: 0.9911\n",
      "Epoch 21/75\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 5.2074e-04 - accuracy: 1.0000\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 0.1706 - accuracy: 0.9583Epoch 30/75\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 0.0116 - accuracy: 0.9978\n",
      "Epoch 44/75\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.2664 - accuracy: 0.9554A: 0s - loss: 0.0270 - accuracy: 0.96\n",
      "Epoch 73/75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:29:48.527509: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s 27ms/step - loss: 0.0515 - accuracy: 0.9688- loss: 0.0515 - accuracy: 0.96\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.0616 - accuracy: 0.9821\n",
      " 1/14 [=>............................] - ETA: 7s - loss: 1.8058 - accuracy: 0.1250Epoch 70/75\n",
      "Epoch 51/75\n",
      "14/14 [==============================] - 0s 22ms/step - loss: 0.0108 - accuracy: 1.0000\n",
      "Epoch 22/75\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.1704 - accuracy: 0.9509\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.0060 - accuracy: 1.0000Epoch 39/75\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.0279 - accuracy: 0.9888A: 0s - loss: 6.4149e-04 - accuracy: 1.00\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 0.0159 - accuracy: 0.9911Epoch 45/75\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 6.0155e-04 - accuracy: 1.0000\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 2.2513 - accuracy: 0.2465Epoch 31/75\n",
      "14/14 [==============================] - 0s 22ms/step - loss: 0.0060 - accuracy: 0.9978\n",
      " 5/14 [=========>....................] - ETA: 0s - loss: 2.4580e-04 - accuracy: 1.0000Epoch 23/75\n",
      "14/14 [==============================] - 1s 34ms/step - loss: 2.0316 - accuracy: 0.2656\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.2765 - accuracy: 0.9420\n",
      "Epoch 2/75\n",
      "Epoch 74/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.0355 - accuracy: 0.9777\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.0550 - accuracy: 0.9812Epoch 52/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.0882 - accuracy: 0.9688\n",
      "Epoch 71/75\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.2165 - accuracy: 0.9263- loss: 0.0014 - accuracy: 1.0000 - ETA: 0s - loss: 0.2211 - accuracy: 0.92\n",
      "Epoch 40/75\n",
      "14/14 [==============================] - 0s 23ms/step - loss: 0.0450 - accuracy: 0.9866\n",
      "Epoch 46/75\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 5.4964e-04 - accuracy: 1.0000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0134 - accuracy: 0.9978\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 0.0454 - accuracy: 0.9911Epoch 32/75\n",
      "Epoch 24/75\n",
      "13/14 [==========================>...] - 0s 36ms/step - loss: 1.4932 - accuracy: 0.3884\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.0560 - accuracy: 0.9844Epoch 3/75\n",
      "14/14 [==============================] - 0s 36ms/step - loss: 0.0267 - accuracy: 0.9844\n",
      "Epoch 53/75\n",
      "14/14 [==============================] - 1s 36ms/step - loss: 0.2638 - accuracy: 0.9442\n",
      "Epoch 75/75\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.0539 - accuracy: 0.9844\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.2581 - accuracy: 0.9062Epoch 72/75\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.0763 - accuracy: 0.9777A: 0s - loss: 0.0349 - accuracy: 1.00\n",
      "Epoch 47/75\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.1924 - accuracy: 0.9375\n",
      "Epoch 41/75\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.0139 - accuracy: 0.9955A: 0s - loss: 2.5910e-04 - accuracy: 1.\n",
      "11/14 [======================>.......] - ETA: 0s - loss: 1.1773 - accuracy: 0.5521 - ETA: 0s - loss: 0.0371 - accuracy: 0.9801Epoch 25/75\n",
      "14/14 [==============================] - 1s 35ms/step - loss: 4.5705e-04 - accuracy: 1.0000\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.0649 - accuracy: 0.9812Epoch 33/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.0294 - accuracy: 0.9844\n",
      " 4/14 [=======>......................] - ETA: 0s - loss: 0.0052 - accuracy: 1.0000Epoch 54/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.0739 - accuracy: 0.9754\n",
      "Epoch 73/75\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.0868 - accuracy: 0.9621\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 1.1164 - accuracy: 0.5625\n",
      "Epoch 48/75\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.0731 - accuracy: 1.0000Epoch 4/75\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.2630 - accuracy: 0.9375\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.2101 - accuracy: 0.9219\n",
      "Epoch 42/75\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.0054 - accuracy: 1.0000- loss: 0.0607 - accuracy: 0.9812 - ETA: 0s - loss: 0.0379 - accuracy: 0.\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 0.9407 - accuracy: 0.6250Epoch 26/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 8.8885e-04 - accuracy: 1.0000ss: 0.1031 - accuracy: 0.9688 - ETA: 0s - loss: 0.0015 - accuracy: 1.00\n",
      "11/14 [======================>.......] - ETA: 0s - loss: 0.0691 - accuracy: 0.9744Epoch 34/75\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.0446 - accuracy: 0.9777\n",
      "Epoch 55/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.0668 - accuracy: 0.9754\n",
      "Epoch 74/75\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.1122 - accuracy: 0.9665\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.0352 - accuracy: 0.9688Epoch 49/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.8778 - accuracy: 0.6406\n",
      "Epoch 5/75\n",
      "14/14 [==============================] - 1s 36ms/step - loss: 0.2215 - accuracy: 0.9174\n",
      " 5/14 [=========>....................] - ETA: 0s - loss: 0.0788 - accuracy: 0.9625Epoch 43/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.0024 - accuracy: 1.0000\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.0012 - accuracy: 1.0000Epoch 27/75\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 0.6702 - accuracy: 0.7366"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:29:50.951652: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 1s 40ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 35/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.0508 - accuracy: 0.9844\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 0.2198 - accuracy: 0.9152Epoch 56/75\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.0679 - accuracy: 0.9754\n",
      "Epoch 50/75\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.0856 - accuracy: 0.9710\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.6278 - accuracy: 0.7644Epoch 75/75\n",
      " 4/14 [=======>......................] - ETA: 0s - loss: 1.8146e-04 - accuracy: 1.0000 - 1s 40ms/step - loss: 0.6141 - accuracy: 0.7746\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 0.0028 - accuracy: 1.0000Epoch 6/75\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.5337 - accuracy: 0.8125Epoch 28/75\n",
      "14/14 [==============================] - 1s 43ms/step - loss: 0.1949 - accuracy: 0.9353\n",
      " 6/14 [===========>..................] - ETA: 0s - loss: 0.4845 - accuracy: 0.8542Epoch 44/75\n",
      "4/4 [==============================] - 1s 81ms/step - loss: 0.1955 - accuracy: 0.9821\n",
      "[CV 2/5] END ...epochs=75, layers=2, neurons=40;, score=0.982 total time=  43.0s\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.0460 - accuracy: 0.9777\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 3.0115e-04 - accuracy: 1.0000\n",
      "Epoch 57/75\n",
      "Epoch 36/75\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.0284 - accuracy: 0.9955\n",
      "Epoch 51/75\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.4818 - accuracy: 0.8371\n",
      "Epoch 7/75\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.0778 - accuracy: 0.9688\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 29/75\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.2381 - accuracy: 0.9129- loss: 0.0010 - accuracy: 1.0000 - ETA: 0s - loss: 0.0435 - accuracy: 0.\n",
      " 8/14 [================>.............] - ETA: 0s - loss: 0.4115 - accuracy: 0.8750Epoch 45/75\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.0313 - accuracy: 0.9933\n",
      "Epoch 52/75\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0920 - accuracy: 0.9665\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 3.2382e-04 - accuracy: 1.0000Epoch 58/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 3.2487e-04 - accuracy: 1.0000\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 0.1424 - accuracy: 0.9479Epoch 37/75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:29:51.909451: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 26ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 30/75\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.3803 - accuracy: 0.8817\n",
      " 5/14 [=========>....................] - ETA: 0s - loss: 0.0332 - accuracy: 0.9875Epoch 8/75\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.0013 - accuracy: 1.0000ETA: 0s - loss: 0.0281 - accuracy: 0.98\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.1603 - accuracy: 0.9410[CV 3/5] END ...epochs=75, layers=2, neurons=40;, score=1.000 total time=  42.1s\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.1805 - accuracy: 0.9397A: 0s - loss: 8.4205e-04 - accuracy: 1.00\n",
      "12/14 [========================>.....]Epoch 46/75\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0235 - accuracy: 0.9933\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.1854 - accuracy: 0.9375Epoch 53/75\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 9.7745e-04 - accuracy: 1.0000\n",
      "13/14 [==========================>...]14/14 [==============================] - ETA: 0s - loss: 2.2051e-04 - accuracy: 1.0000 - ETA: 0s - loss: 0.1133 - accuracy: 0.9621Epoch 31/75\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.1133 - accuracy: 0.9621\n",
      "Epoch 59/75\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 2.5183e-04 - accuracy: 1.0000\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 9.6927e-04 - accuracy: 1.0000Epoch 38/75\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.3466 - accuracy: 0.8772\n",
      "Epoch 9/75\n",
      " 8/14 [================>.............] - ETA: 0s - loss: 4.5532e-04 - accuracy: 1.0000Epoch 1/75\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.0146 - accuracy: 0.9978\n",
      "Epoch 54/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.2052 - accuracy: 0.9219\n",
      "Epoch 47/75\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 6.7650e-04 - accuracy: 1.0000\n",
      "Epoch 32/75\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.0311 - accuracy: 0.9888- loss: 0.3172 - accuracy: 0.8125 - ETA: 0s - loss: 3.8854e-04 - accuracy: 1.00\n",
      "Epoch 60/75\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 3.4951e-04 - accuracy: 1.0000\n",
      "Epoch 39/75\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.2965 - accuracy: 0.9018\n",
      "Epoch 10/75\n",
      "12/14 [========================>.....] - ETA: 0s - loss: 9.6584e-04 - accuracy: 1.0000 - ETA: 0s - loss: 0.0167 - accuracy: 0.9974Epoch 1/75\n",
      " 4/14 [=======>......................] - ETA: 0s - loss: 0.2556 - accuracy: 0.914100"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:29:53.037728: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 35ms/step - loss: 0.1917 - accuracy: 0.9286\n",
      "Epoch 48/75\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.0154 - accuracy: 0.9978\n",
      "Epoch 55/75\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 33/75\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.0426 - accuracy: 0.9821\n",
      " 8/14 [================>.............] - ETA: 0s - loss: 0.2466 - accuracy: 0.9141Epoch 61/75\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 3.4716e-04 - accuracy: 1.0000\n",
      "Epoch 40/75\n",
      "14/14 [==============================] - 1s 35ms/step - loss: 0.2485 - accuracy: 0.9129\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 0.0112 - accuracy: 0.9955Epoch 11/75\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.0224 - accuracy: 0.9933\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 1.8696e-04 - accuracy: 1.0000Epoch 56/75\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 6.8360e-04 - accuracy: 1.0000\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 1.8487 - accuracy: 0.3625Epoch 34/75\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.2013 - accuracy: 0.9219\n",
      "Epoch 49/75\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.0556 - accuracy: 0.9754\n",
      "12/14 [========================>.....] - ETA: 0s - loss: 1.7649 - accuracy: 0.3828Epoch 62/75\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 1.7915e-04 - accuracy: 1.0000\n",
      "Epoch 41/75\n",
      "14/14 [==============================] - 1s 32ms/step - loss: 1.7071 - accuracy: 0.3906\n",
      "Epoch 2/75\n",
      "14/14 [==============================] - 0s 24ms/step - loss: 0.2214 - accuracy: 0.9308\n",
      " 5/14 [=========>....................] - ETA: 0s - loss: 0.1656 - accuracy: 0.9313Epoch 12/75\n",
      "14/14 [==============================] - 0s 24ms/step - loss: 0.0113 - accuracy: 1.0000\n",
      "Epoch 57/75\n",
      "14/14 [==============================] - 0s 24ms/step - loss: 7.3563e-04 - accuracy: 1.0000\n",
      "Epoch 35/75\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 1.8809e-04 - accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:29:54.042605: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 30ms/step - loss: 0.1868 - accuracy: 0.9308\n",
      "Epoch 50/75\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0397 - accuracy: 0.9866\n",
      "Epoch 63/75\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 0.2151 - accuracy: 0.9263\n",
      "Epoch 13/75\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 1.5827e-04 - accuracy: 1.0000\n",
      "Epoch 42/75\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 1.0598 - accuracy: 0.6339\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 1.4217e-04 - accuracy: 1.0000Epoch 3/75\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.0147 - accuracy: 1.0000\n",
      "Epoch 58/75\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 8.7116e-04 - accuracy: 1.0000\n",
      "Epoch 36/75\n",
      "14/14 [==============================] - 0s 24ms/step - loss: 0.0690 - accuracy: 0.9710\n",
      "Epoch 64/75\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.1690 - accuracy: 0.9442\n",
      "Epoch 51/75\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.1964 - accuracy: 0.9241\n",
      " 8/14 [================>.............] - ETA: 0s - loss: 1.5755 - accuracy: 0.2969Epoch 14/75\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 4.5322e-04 - accuracy: 1.0000\n",
      "Epoch 43/75\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.6261 - accuracy: 0.7902\n",
      "Epoch 4/75\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 6.5358e-04 - accuracy: 1.0000\n",
      " 5/14 [=========>....................] - ETA: 0s - loss: 0.1802 - accuracy: 0.9375Epoch 37/75\n",
      "14/14 [==============================] - 2s 46ms/step - loss: 1.5448 - accuracy: 0.3371\n",
      "Epoch 2/75\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.0140 - accuracy: 1.0000\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 0.1850 - accuracy: 0.9286Epoch 59/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.0459 - accuracy: 0.9844A: 0s - loss: 0.1754 - accuracy: 0.9349 3/14 [=====>........................] - ETA: 0s - loss: 1.4849 - accuracy: 0.41\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.1708 - accuracy: 0.9375Epoch 65/75\n",
      "14/14 [==============================] - 0s 36ms/step - loss: 0.1720 - accuracy: 0.9375\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 2.6691e-04 - accuracy: 1.0000Epoch 52/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.2013 - accuracy: 0.9219\n",
      "Epoch 15/75\n",
      "14/14 [==============================] - 0s 23ms/step - loss: 0.0011 - accuracy: 1.0000- loss: 0.1386 - accuracy: 0.9688 - ETA: 0s - loss: 2.7648e-04 - accuracy: 1.00\n",
      " 8/14 [================>.............] - ETA: 0s - loss: 1.5309 - accuracy: 0.3555Epoch 38/75\n",
      "14/14 [==============================] - 1s 36ms/step - loss: 2.4294e-04 - accuracy: 1.0000\n",
      "Epoch 44/75\n",
      "14/14 [==============================] - 1s 36ms/step - loss: 0.2993 - accuracy: 0.9063\n",
      "12/14 [========================>.....] - ETA: 0s - loss: 0.0254 - accuracy: 1.0000Epoch 5/75\n",
      "14/14 [==============================] - 0s 36ms/step - loss: 1.5046 - accuracy: 0.3817\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.0260 - accuracy: 0.9931Epoch 3/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.0268 - accuracy: 0.9978- ETA: 0s - loss: 0.0268 - accuracy: 0.99\n",
      "Epoch 60/75\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.1962 - accuracy: 0.9286\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 0.1393 - accuracy: 0.9866Epoch 53/75\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      " 5/14 [=========>....................] - ETA: 0s - loss: 1.4153 - accuracy: 0.3812Epoch 39/75\n",
      "14/14 [==============================] - 1s 34ms/step - loss: 0.0281 - accuracy: 0.9888\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.1900 - accuracy: 0.9263\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.0818 - accuracy: 0.9688Epoch 66/75\n",
      "Epoch 16/75\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 3.2096e-04 - accuracy: 1.0000=====>......................] - ETA: 0s - loss: 6.4234e-04 - accuracy: 1.00\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.1266 - accuracy: 0.9710\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 1.4064 - accuracy: 0.3938Epoch 45/75\n",
      "Epoch 6/75\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 1.3634 - accuracy: 0.4263\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.0176 - accuracy: 0.9978\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.2637 - accuracy: 0.9031Epoch 61/75\n",
      " 5/14 [=========>....................] - ETA: 0s - loss: 0.0790 - accuracy: 0.9812Epoch 4/75\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 5.9796e-04 - accuracy: 1.0000\n",
      " 6/14 [===========>..................] - ETA: 0s - loss: 1.8846e-04 - accuracy: 1.0000Epoch 40/75\n",
      "14/14 [==============================] - 1s 36ms/step - loss: 0.2067 - accuracy: 0.9196\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.2476 - accuracy: 0.9085\n",
      "Epoch 54/75\n",
      "Epoch 17/75\n",
      "14/14 [==============================] - 1s 43ms/step - loss: 0.0439 - accuracy: 0.9799- loss: 9.2446e-04 - accuracy: 1.0000 - ETA: 0s - loss: 1.2160 - accuracy: 0.50\n",
      " 5/14 [=========>....................] - ETA: 0s - loss: 1.1774 - accuracy: 0.5312Epoch 67/75\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.0692 - accuracy: 0.9866- loss: 0.0476 - accuracy: 0.9766     - ETA: 0s - loss: 0.2274 - accuracy: 0.89\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 2.5330e-04 - accuracy: 1.0000Epoch 7/75\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 2.3893e-04 - accuracy: 1.0000\n",
      " 6/14 [===========>..................]Epoch 46/75loss: 0.0376 - accuracy: 1.0000\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.0202 - accuracy: 1.0000\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.1823 - accuracy: 0.9236Epoch 62/75\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 6.1490e-04 - accuracy: 1.0000\n",
      "Epoch 41/75\n",
      "14/14 [==============================] - 1s 36ms/step - loss: 1.0847 - accuracy: 0.5625A: 0s - loss: 2.7857e-04 - accuracy: 1.00\n",
      " 6/14 [===========>..................] - ETA: 0s - loss: 1.4946e-04 - accuracy: 1.0000Epoch 5/75\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.1816 - accuracy: 0.9219\n",
      "Epoch 18/75\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.1985 - accuracy: 0.9196- loss: 0.1908 - accuracy: 0.9183 - ETA: 0s - loss: 0.0080 - accuracy: 1.0000\n",
      " 4/14 [=======>......................] - ETA: 0s - loss: 4.0632e-04 - accuracy: 1.0000Epoch 55/75\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.0972 - accuracy: 0.9688\n",
      " 4/14 [=======>......................]Epoch 68/75- loss: 0.3270 - accuracy: 0.90\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 1.5629e-04 - accuracy: 1.0000\n",
      "Epoch 47/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.0079 - accuracy: 1.0000\n",
      "Epoch 63/75\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.0287 - accuracy: 0.9888\n",
      "Epoch 42/75\n",
      "14/14 [==============================] - 1s 43ms/step - loss: 0.0508 - accuracy: 0.9888A: 0s - loss: 0.1050 - accuracy: 0.96\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 2.8330e-04 - accuracy: 1.0000Epoch 8/75\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.2316 - accuracy: 0.9063\n",
      " 5/14 [=========>....................] - ETA: 0s - loss: 2.8201e-04 - accuracy: 1.0000Epoch 19/75\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.2184 - accuracy: 0.9509 - 1s 41ms/step - loss: 0.8059 - accuracy: 0.6808\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.0961 - accuracy: 0.9591Epoch 6/75\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.0958 - accuracy: 0.9576\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.6674 - accuracy: 0.7188Epoch 69/75\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.1840 - accuracy: 0.9353\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.0877 - accuracy: 0.9688Epoch 56/75\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.0103 - accuracy: 1.0000\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.0605 - accuracy: 0.9792Epoch 64/75\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 1.5607e-04 - accuracy: 1.0000\n",
      "Epoch 48/75\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.1537 - accuracy: 0.9554\n",
      " 4/14 [=======>......................] - ETA: 0s - loss: 0.6457 - accuracy: 0.7188Epoch 43/75\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 0.0563 - accuracy: 0.9799- loss: 0.0510 - accuracy: 0.9844 - ETA: 0s - loss: 0.2251 - accuracy: 0.93\n",
      "Epoch 9/75\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.1660 - accuracy: 0.9375\n",
      " 6/14 [===========>..................] - ETA: 0s - loss: 1.6908e-04 - accuracy: 1.0000 - ETA: 0s - loss: 0.0403 - accuracy: 0.9844 - ETA: 0s - loss: 0.2154 - accuracy: 0.9156Epoch 20/75\n",
      "14/14 [==============================] - 1s 43ms/step - loss: 0.5664 - accuracy: 0.7098A: 0s - loss: 0.2141 - accuracy: 0.91\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 0.1369 - accuracy: 0.9688Epoch 7/75\n",
      "14/14 [==============================] - 1s 45ms/step - loss: 0.0506 - accuracy: 0.9799\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.2158 - accuracy: 0.91Epoch 70/75\n",
      "14/14 [==============================] - 1s 43ms/step - loss: 0.2158 - accuracy: 0.9174\n",
      " 4/14 [=======>......................] - ETA: 0s - loss: 0.1257 - accuracy: 0.9609Epoch 57/75\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 2.3868e-04 - accuracy: 1.0000s - loss: 0.0085 - accuracy: 1.00\n",
      "Epoch 49/75\n",
      "14/14 [==============================] - 1s 45ms/step - loss: 0.0080 - accuracy: 1.0000\n",
      "Epoch 65/75\n",
      "14/14 [==============================] - 1s 58ms/step - loss: 0.1706 - accuracy: 0.9509\n",
      "Epoch 44/75\n",
      "14/14 [==============================] - 1s 54ms/step - loss: 0.1574 - accuracy: 0.9330\n",
      "14/14 [==============================] - 1s 60ms/step - loss: 0.0489 - accuracy: 0.9844\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 0.0910 - accuracy: 0.9583Epoch 21/75\n",
      "Epoch 10/75\n",
      "14/14 [==============================] - 1s 57ms/step - loss: 0.1541 - accuracy: 0.9442- loss: 0.1011 - accuracy: 0.9554 - ETA: 0s - loss: 0.0430 - accuracy: 0.\n",
      "Epoch 58/75\n",
      "14/14 [==============================] - 1s 74ms/step - loss: 0.4538 - accuracy: 0.7478A: 0s - loss: 0.1670 - accuracy: 0.92\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.1268 - accuracy: 0.9554Epoch 8/75\n",
      "14/14 [==============================] - 1s 68ms/step - loss: 0.1268 - accuracy: 0.9554\n",
      "Epoch 71/75\n",
      "14/14 [==============================] - 1s 66ms/step - loss: 0.0188 - accuracy: 0.9978- loss: 0.0385 - accuracy: 0.9844 - ETA: 0s - loss: 0.0187 - accuracy: 0.99\n",
      "Epoch 66/75\n",
      "14/14 [==============================] - 1s 75ms/step - loss: 3.0525e-04 - accuracy: 1.0000ss: 0.1915 - accuracy: 0.9297 - ETA: 0s - loss: 0.4463 - accuracy: 0.80\n",
      "Epoch 50/75\n",
      "14/14 [==============================] - 1s 59ms/step - loss: 0.0897 - accuracy: 0.9643\n",
      "Epoch 45/75\n",
      "14/14 [==============================] - 1s 50ms/step - loss: 0.1436 - accuracy: 0.9464\n",
      "Epoch 22/75\n",
      "14/14 [==============================] - 1s 55ms/step - loss: 0.0260 - accuracy: 0.9933\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.1780 - accuracy: 0.9410Epoch 11/75\n",
      "14/14 [==============================] - 1s 56ms/step - loss: 0.1586 - accuracy: 0.9442A: 0s - loss: 0.1307 - accuracy: 0.95 - ETA: 0s - loss: 0.1342 - accuracy: 0.\n",
      "Epoch 59/75\n",
      "14/14 [==============================] - 1s 55ms/step - loss: 0.1474 - accuracy: 0.9464\n",
      "Epoch 72/75\n",
      "14/14 [==============================] - 1s 53ms/step - loss: 0.0159 - accuracy: 0.9978\n",
      "Epoch 67/75\n",
      "14/14 [==============================] - 1s 60ms/step - loss: 0.4123 - accuracy: 0.8036\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.0011 - accuracy: 1.0000Epoch 9/75\n",
      "14/14 [==============================] - 1s 51ms/step - loss: 1.9160e-04 - accuracy: 1.0000\n",
      "Epoch 51/75\n",
      "14/14 [==============================] - 1s 48ms/step - loss: 0.0438 - accuracy: 0.9821\n",
      "Epoch 46/75\n",
      "14/14 [==============================] - 1s 49ms/step - loss: 0.1674 - accuracy: 0.9219\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 2.9576e-04 - accuracy: 1.0000Epoch 23/75\n",
      "14/14 [==============================] - 1s 65ms/step - loss: 0.0241 - accuracy: 0.9955A: 0s - loss: 3.5147e-04 - accuracy: 1.00\n",
      "Epoch 12/75\n",
      "14/14 [==============================] - 1s 63ms/step - loss: 0.1717 - accuracy: 0.9308A: 0s - loss: 3.1409e-04 - accuracy: 1.\n",
      "Epoch 60/75\n",
      "14/14 [==============================] - 1s 67ms/step - loss: 0.2022 - accuracy: 0.9286\n",
      "Epoch 73/75\n",
      "14/14 [==============================] - 1s 66ms/step - loss: 0.0038 - accuracy: 1.0000- loss: 0.1964 - accuracy: 0.9018 - ETA: 0s - loss: 0.3573 - accuracy: 0.84\n",
      "12/14 [========================>.....] - ETA: 0s - loss: 2.6428e-04 - accuracy: 1.0000Epoch 68/75\n",
      "14/14 [==============================] - 1s 69ms/step - loss: 2.4625e-04 - accuracy: 1.0000ss: 0.0359 - accuracy: 0.9922 - ETA: 1s - loss: 0.2053 - accuracy: 0.92\n",
      "Epoch 52/75\n",
      "14/14 [==============================] - 1s 71ms/step - loss: 0.0259 - accuracy: 0.9933\n",
      "Epoch 47/75\n",
      "14/14 [==============================] - 1s 76ms/step - loss: 0.3480 - accuracy: 0.8549\n",
      "Epoch 10/75\n",
      "14/14 [==============================] - 1s 56ms/step - loss: 0.0266 - accuracy: 0.9955\n",
      "14/14 [==============================] - 1s 72ms/step - loss: 0.2534 - accuracy: 0.8862\n",
      "Epoch 13/75\n",
      "Epoch 24/75\n",
      "14/14 [==============================] - 1s 45ms/step - loss: 0.1553 - accuracy: 0.9464\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.0157 - accuracy: 1.0000Epoch 61/75\n",
      "14/14 [==============================] - 1s 48ms/step - loss: 0.1369 - accuracy: 0.9509- loss: 0.1714 - accuracy: 0.9286 - ETA: 0s - loss: 0.1369 - accuracy: 0.95\n",
      "Epoch 74/75\n",
      "14/14 [==============================] - 1s 44ms/step - loss: 0.0116 - accuracy: 1.0000\n",
      "Epoch 69/75\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.0242 - accuracy: 0.9911\n",
      " 4/14 [=======>......................] - ETA: 0s - loss: 0.1777 - accuracy: 0.9453Epoch 48/75\n",
      "14/14 [==============================] - 1s 43ms/step - loss: 1.9975e-04 - accuracy: 1.0000\n",
      "Epoch 53/75\n",
      "14/14 [==============================] - 1s 36ms/step - loss: 0.1571 - accuracy: 0.9286A: 0s - loss: 0.0059 - accuracy: 1.0000\n",
      "14/14 [==============================] - 1s 43ms/step - loss: 0.2864 - accuracy: 0.8638\n",
      "Epoch 11/75\n",
      "Epoch 25/75\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.0103 - accuracy: 0.9978\n",
      "Epoch 14/75\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.2238 - accuracy: 0.9196- loss: 0.2235 - accuracy: 0.9219 - ETA: 0s - loss: 0.0152 - accuracy: 0.99\n",
      "Epoch 62/75\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.0175 - accuracy: 1.0000\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.2970 - accuracy: 0.9062Epoch 70/75\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 1.2398e-04 - accuracy: 1.0000\n",
      "Epoch 54/75============>.............] - ETA: 0s - loss: 0.0102 - accuracy: 1.0000\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.0176 - accuracy: 0.9933\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 0.0111 - accuracy: 1.0000    Epoch 49/75\n",
      "14/14 [==============================] - 1s 46ms/step - loss: 0.0583 - accuracy: 0.9732\n",
      "Epoch 75/75\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.2806 - accuracy: 0.8951\n",
      "12/14 [========================>.....] - ETA: 0s - loss: 0.0077 - accuracy: 1.0000Epoch 12/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.1509 - accuracy: 0.9286\n",
      " 4/14 [=======>......................] - ETA: 0s - loss: 0.0265 - accuracy: 0.9844Epoch 26/75\n",
      "14/14 [==============================] - 1s 34ms/step - loss: 0.0075 - accuracy: 1.0000\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.0852 - accuracy: 1.0000Epoch 15/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.5267 - accuracy: 0.8371\n",
      "Epoch 63/75\n",
      "14/14 [============================= - 0s 28ms/step - loss: 0.0141 - accuracy: 0.9978\n",
      " 6/14 [===========>..................] - ETA: 0s - loss: 0.0983 - accuracy: 0.9688Epoch 71/75\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.0180 - accuracy: 0.9933\n",
      "Epoch 50/75\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 1.4961e-04 - accuracy: 1.0000\n",
      "10/14 [====================>.........]Epoch 55/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.0690 - accuracy: 0.9754\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.1841 - accuracy: 0.9018\n",
      "Epoch 13/75\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.0956 - accuracy: 0.9665\n",
      " 5/14 [=========>....................] - ETA: 0s - loss: 1.2913e-04 - accuracy: 1.0000Epoch 27/75\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.0060 - accuracy: 1.0000\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.1419 - accuracy: 0.9375Epoch 16/75\n",
      " 3/14 [=====>........................] - 0s 36ms/step - loss: 0.6794 - accuracy: 0.6964\n",
      " - ETA: 0s - loss: 0.0087 - accuracy: 1.0000Epoch 64/75\n",
      "14/14 [==============================] - 0s 36ms/step - loss: 0.0061 - accuracy: 1.0000\n",
      "Epoch 72/75\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.0147 - accuracy: 0.9933A: 0s - loss: 0.0121 - accuracy: 1.00\n",
      "Epoch 51/75\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 1.1062e-04 - accuracy: 1.0000\n",
      "Epoch 56/75\n",
      "14/14 [==============================] - 1s 60ms/step - loss: 0.1798 - accuracy: 0.9219A: 0s - loss: 0.0071 - accuracy: 1.\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.4942 - accuracy: 0.7743Epoch 14/75\n",
      "14/14 [==============================] - 1s 56ms/step - loss: 0.0055 - accuracy: 1.0000\n",
      "11/14 [======================>.......] - ETA: 0s - loss: 0.0067 - accuracy: 1.0000Epoch 17/75\n",
      "14/14 [==============================] - 1s 62ms/step - loss: 0.1137 - accuracy: 0.9509\n",
      "Epoch 28/75\n",
      "14/14 [==============================] - 1s 57ms/step - loss: 0.0058 - accuracy: 1.0000- loss: 0.0061 - accuracy: 1.0000 - ETA: 0s - loss: 0.4952 - accuracy: 0.76\n",
      "Epoch 73/75\n",
      "14/14 [==============================] - 1s 61ms/step - loss: 0.4974 - accuracy: 0.7679\n",
      "Epoch 65/75\n",
      " 7/14 [==============>...............]14/14 [==============================] - ETA: 0s - loss: 0.1609 - accuracy: 0.9554 - 1s 59ms/step - loss: 1.4614e-04 - accuracy: 1.0000\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 0.5285 - accuracy: 0.7396Epoch 57/75\n",
      "14/14 [==============================] - 1s 62ms/step - loss: 0.0120 - accuracy: 0.9978\n",
      " 8/14 [================>.............] - ETA: 0s - loss: 0.1588 - accuracy: 0.9570Epoch 52/75\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.0036 - accuracy: 1.00000000 - ETA: 0s - loss: 0.1384 - accuracy: 0.96"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:30:03.349407: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 1s 55ms/step - loss: 0.1283 - accuracy: 0.9621A: 0s - loss: 0.4570 - accuracy: 0.77\n",
      " - ETA: 0s - loss: 1.3692e-04 - accuracy: 1.0000Epoch 15/75\n",
      "14/14 [==============================] - 1s 47ms/step - loss: 0.0034 - accuracy: 1.0000\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.0091 - accuracy: 1.0000- ETA: 0s - loss: 0.1122 - accuracy: 1.00\n",
      "Epoch 74/75\n",
      "Epoch 18/75\n",
      "14/14 [==============================] - 1s 43ms/step - loss: 0.4656 - accuracy: 0.7612\n",
      " - ETA: 0s - loss: 0.0979 - accuracy: 0.9844Epoch 66/75\n",
      "14/14 [==============================] - 1s 55ms/step - loss: 0.1094 - accuracy: 0.9487\n",
      "Epoch 29/75\n",
      "14/14 [==============================] - 1s 49ms/step - loss: 1.1253e-04 - accuracy: 1.0000s - loss: 0.0765 - accuracy: 0.9896\n",
      "Epoch 58/75\n",
      "14/14 [==============================] - 1s 45ms/step - loss: 0.0130 - accuracy: 0.9955\n",
      "Epoch 53/75\n",
      "4/4 [==============================] - 1s 117ms/step - loss: 0.0155 - accuracy: 0.9911 ETA: 0s - loss: 0.0155 - accuracy: 0.99\n",
      "12/14 [========================>.....] - ETA: 0s - loss: 0.1190 - accuracy: 0.9714 - ETA: 0s - loss: 0.0195 - accuracy: 0.9974[CV 4/5] END ...epochs=75, layers=2, neurons=40;, score=0.991 total time=  39.7s\n",
      "14/14 [==============================] - 1s 72ms/step - loss: 0.1247 - accuracy: 0.97104/14 [==============================] - ETA: 0s - loss: 0.1247 - accuracy: 0.97\n",
      "Epoch 16/75\n",
      "14/14 [==============================] - 1s 71ms/step - loss: 0.0221 - accuracy: 0.9955\n",
      "12/14 [========================>.....] - ETA: 0s - loss: 0.4669 - accuracy: 0.7526Epoch 75/75\n",
      "14/14 [==============================] - 1s 75ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 19/75\n",
      "14/14 [==============================] - 1s 74ms/step - loss: 0.4626 - accuracy: 0.7522\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.1111 - accuracy: 0.9621Epoch 67/75\n",
      "14/14 [==============================] - 1s 74ms/step - loss: 0.1111 - accuracy: 0.9621\n",
      "Epoch 30/75\n",
      "14/14 [==============================] - 1s 70ms/step - loss: 0.0131 - accuracy: 0.9933 [=====>........................] - ETA: 0s - loss: 0.4218 - accuracy: 0.75\n",
      " 5/14 [=========>....................] - ETA: 0s - loss: 0.0014 - accuracy: 1.0000 - 1s 82ms/step - loss: 1.2702e-04 - accuracy: 1.0000ss: 0.1221 - accuracy: 0.97\n",
      "Epoch 54/75\n",
      " 5/14 [=========>....................] - ETA: 0s - loss: 0.4286 - accuracy: 0.7438Epoch 59/75\n",
      "14/14 [==============================] - 1s 71ms/step - loss: 0.0260 - accuracy: 0.9955A: 0s - loss: 0.1160 - accuracy: 0.\n",
      "14/14 [==============================] - 1s 68ms/step - loss: 0.4397 - accuracy: 0.7522\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 6.1389e-05 - accuracy: 1.0000Epoch 68/\n",
      "14/14 [==============================] - 1s 84ms/step - loss: 0.1036 - accuracy: 0.9777\n",
      "Epoch 17/75\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 20/75\n",
      "14/14 [==============================] - 1s 73ms/step - loss: 0.0919 - accuracy: 0.9643\n",
      "11/14 [======================>.......] - ETA: 0s - loss: 7.6254e-05 - accuracy: 1.0000Epoch 31/75\n",
      "14/14 [==============================] - 1s 57ms/step - loss: 0.0096 - accuracy: 0.9955- ETA: 0s - loss: 7.1497e-05 - accuracy: 1.00\n",
      " 5/14 [=========>....................] - ETA: 0s - loss: 0.4155 - accuracy: 0.7688Epoch 55/75\n",
      "14/14 [==============================] - 1s 66ms/step - loss: 4.3926e-04 - accuracy: 1.0000\n",
      "Epoch 60/75\n",
      "14/14 [==============================] - 1s 58ms/step - loss: 0.4325 - accuracy: 0.7589A: 0s - loss: 0.1167 - accuracy: 0.96\n",
      "Epoch 69/75\n",
      "14/14 [==============================] - 1s 48ms/step - loss: 0.0040 - accuracy: 1.0000\n",
      "14/14 [==============================] - 1s 56ms/step - loss: 0.1079 - accuracy: 0.9688\n",
      "Epoch 21/75\n",
      "Epoch 18/75\n",
      "14/14 [==============================] - 1s 52ms/step - loss: 0.0968 - accuracy: 0.9598\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 1.4154e-04 - accuracy: 1.0000Epoch 32/75\n",
      "14/14 [==============================] - 1s 62ms/step - loss: 0.0216 - accuracy: 0.9911\n",
      " 6/14 [===========>..................]Epoch 56/75\n",
      "14/14 [==============================] - 1s 52ms/step - loss: 2.3412e-04 - accuracy: 1.0000\n",
      " 5/14 [=========>....................] - ETA: 0s - loss: 0.0034 - accuracy: 1.0000Epoch 61/75\n",
      " 6/14 [===========>..................] - ETA: 0s - loss: 0.0036 - accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:30:07.073838: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 1s 58ms/step - loss: 0.4781 - accuracy: 0.7589A: 0s - loss: 0.0035 - accuracy: 1.\n",
      "14/14 [==============================] - 1s 56ms/step - loss: 0.1134 - accuracy: 0.9598\n",
      "Epoch 70/75\n",
      "Epoch 19/75\n",
      "14/14 [==============================] - 1s 51ms/step - loss: 0.0755 - accuracy: 0.9777- loss: 0.0755 - accuracy: 0.9777 - ETA: 0s - loss: 0.0031 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 63ms/step - loss: 0.0031 - accuracy: 1.0000\n",
      "11/14 [======================>.......] - ETA: 0s - loss: 0.0134 - accuracy: 0.9915Epoch 33/75\n",
      "Epoch 22/75\n",
      "14/14 [==============================] - 1s 44ms/step - loss: 0.0118 - accuracy: 0.9933\n",
      "Epoch 57/75\n",
      "14/14 [==============================] - 1s 46ms/step - loss: 2.7205e-04 - accuracy: 1.0000s - loss: 1.3821e-04 - accuracy: 1.00\n",
      "Epoch 62/75\n",
      "4/4 [==============================] - 1s 81ms/step - loss: 1.8483e-04 - accuracy: 1.0000\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.4034 - accuracy: 0.8542[CV 1/5] END ...epochs=75, layers=2, neurons=60;, score=1.000 total time=  37.3s\n",
      "14/14 [==============================] - 1s 58ms/step - loss: 0.2513 - accuracy: 0.9174A: 0s - loss: 0.4257 - accuracy: 0.85\n",
      "11/14 [======================>.......] - ETA: 0s - loss: 0.0034 - accuracy: 1.0000Epoch 20/75\n",
      "14/14 [==============================] - 1s 63ms/step - loss: 0.4189 - accuracy: 0.8527\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.3886 - accuracy: 0.7812 - ETA: 0s - loss: 0.0181 - accuracy: 0.9922Epoch 71/75\n",
      "14/14 [==============================] - 1s 67ms/step - loss: 0.0034 - accuracy: 1.0000\n",
      "Epoch 23/75\n",
      "14/14 [==============================] - 1s 59ms/step - loss: 0.0171 - accuracy: 0.9933\n",
      " 2/14 [===>..........................] - ETA: 0s - loss: 0.4172 - accuracy: 0.8281Epoch 58/75\n",
      "14/14 [==============================] - 1s 73ms/step - loss: 0.0775 - accuracy: 0.9710\n",
      "Epoch 34/75\n",
      "14/14 [==============================] - 1s 62ms/step - loss: 1.5554e-04 - accuracy: 1.0000\n",
      " 2/14 [===>..........................] - ETA: 1s - loss: 0.0023 - accuracy: 1.0000    Epoch 63/75\n",
      "14/14 [==============================] - 1s 45ms/step - loss: 0.0152 - accuracy: 0.9955A: 0s - loss: 0.4305 - accuracy: 0.851.\n",
      "Epoch 59/75\n",
      "14/14 [==============================] - 1s 59ms/step - loss: 0.1762 - accuracy: 0.9420\n",
      "12/14 [========================>.....] - ETA: 0s - loss: 0.0036 - accuracy: 0.9974Epoch 21/75\n",
      "14/14 [==============================] - 1s 58ms/step - loss: 0.4350 - accuracy: 0.8482\n",
      "Epoch 72/75\n",
      "14/14 [==============================] - 1s 51ms/step - loss: 0.0034 - accuracy: 0.9978\n",
      "Epoch 24/75\n",
      "14/14 [==============================] - 1s 45ms/step - loss: 0.0834 - accuracy: 0.9665\n",
      "Epoch 35/75\n",
      "14/14 [==============================] - 1s 43ms/step - loss: 1.5888e-04 - accuracy: 1.0000\n",
      "Epoch 64/75\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 0.1030 - accuracy: 0.9598Epoch 1/75\n",
      "14/14 [==============================] - 1s 36ms/step - loss: 0.4322 - accuracy: 0.8504\n",
      "11/14 [======================>.......]13/14 [==========================>...] - ETA: 0s - loss: 0.0055 - accuracy: 1.0000 - ETA: 0s - loss: 1.5206e-04 - accuracy: 1.0000Epoch 73/75\n",
      "14/14 [==============================] - 1s 43ms/step - loss: 0.0132 - accuracy: 0.9955\n",
      "Epoch 60/75\n",
      "14/14 [==============================] - 1s 46ms/step - loss: 0.0466 - accuracy: 0.9844\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.2821 - accuracy: 0.9062Epoch 22/75\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 0.0056 - accuracy: 1.0000 [==============================] - ETA: 0s - loss: 0.0056 - accuracy: 1.00\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 1.3663e-04 - accuracy: 1.0000Epoch 25/75\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 1.3262e-04 - accuracy: 1.0000\n",
      "12/14 [========================>.....] - ETA: 0s - loss: 0.0854 - accuracy: 0.9661Epoch 65/75\n",
      "14/14 [==============================] - 1s 51ms/step - loss: 0.0817 - accuracy: 0.9688\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 0.0010 - accuracy: 1.0000    Epoch 36/75\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.3927 - accuracy: 0.8638A: 0s - loss: 0.0746 - accuracy: 0.970.99\n",
      "12/14 [========================>.....] - ETA: 0s - loss: 0.0510 - accuracy: 0.9844Epoch 74/75\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.0090 - accuracy: 0.9978\n",
      "Epoch 61/75\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.0457 - accuracy: 0.9866\n",
      "Epoch 23/75\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.0050 - accuracy: 1.0000\n",
      "Epoch 26/75\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.1083 - accuracy: 0.9464 - 1s 40ms/step - loss: 1.7678e-04 - accuracy: 1.0000\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.1083 - accuracy: 0.9464\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 3.5290e-04 - accuracy: 1.0000Epoch 37/75\n",
      "Epoch 66/75\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.0174 - accuracy: 0.9911A: 0s - loss: 0.3670 - accuracy: 0.\n",
      "Epoch 62/75\n",
      "12/14 [========================>.....] - ETA: 0s - loss: 0.3413 - accuracy: 0.880200"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:30:10.652478: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0325 - accuracy: 0.9911\n",
      "12/14 [========================>.....] - ETA: 0s - loss: 0.0278 - accuracy: 0.9896Epoch 24/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.3367 - accuracy: 0.8817\n",
      "Epoch 75/75\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.0266 - accuracy: 0.9888\n",
      "Epoch 27/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.0960 - accuracy: 0.9576\n",
      "Epoch 38/75\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 1.2830e-04 - accuracy: 1.0000\n",
      "Epoch 67/75\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0143 - accuracy: 0.9978- loss: 0.0148 - accuracy: 0.9976 - ETA: 0s - loss: 1.6325e-04 - accuracy: 1.00\n",
      "Epoch 63/75\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.3610 - accuracy: 0.8661- ETA: 0s - loss: 0.0015 - accuracy: 1.\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.0353 - accuracy: 0.9821\n",
      "Epoch 25/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.0926 - accuracy: 0.9598\n",
      "Epoch 39/75\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 0.0720 - accuracy: 0.9688Epoch 1/75\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.0627 - accuracy: 0.9799\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.1089 - accuracy: 0.9375Epoch 28/75\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 7.9830e-05 - accuracy: 1.0000\n",
      "Epoch 68/75\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.0072 - accuracy: 0.9978A: 0s - loss: 1.5767 - accuracy: 0.31\n",
      "Epoch 64/75\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.0416 - accuracy: 0.9844\n",
      "Epoch 26/75\n",
      "14/14 [==============================] - 2s 41ms/step - loss: 1.5360 - accuracy: 0.3504\n",
      "Epoch 2/75\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.0450 - accuracy: 0.9799- loss: 0.1356 - accuracy: 0.9401 - ETA: 0s - loss: 7.4061e-05 - accuracy: 1.00\n",
      "Epoch 29/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.1386 - accuracy: 0.9397\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.0061 - accuracy: 0.9976Epoch 40/75\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.0057 - accuracy: 0.9978\n",
      "Epoch 65/75\n",
      "14/14 [==============================] - 1s 28ms/step - loss: 8.1986e-05 - accuracy: 1.0000\n",
      "Epoch 69/75\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 1.4331 - accuracy: 0.3728- ETA: 0s - loss: 0.1129 - accuracy: 0.94\n",
      "Epoch 3/75\n",
      "11/14 [======================>.......] - ETA: 0s - loss: 0.0207 - accuracy: 0.9972"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:30:11.949257: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 1s 37ms/step - loss: 0.0640 - accuracy: 0.9710\n",
      "2/4 [==============>...............]Epoch 27/75\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.0404 - accuracy: 0.9799\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 1.7146e-04 - accuracy: 1.0000Epoch 66/75\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.0215 - accuracy: 0.9955\n",
      "Epoch 30/75\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.1128 - accuracy: 0.9509\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.2634 - accuracy: 0.8750Epoch 41/75\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 1.4338e-04 - accuracy: 1.0000\n",
      "Epoch 70/75\n",
      "4/4 [==============================] - 1s 90ms/step - loss: 0.3084 - accuracy: 0.8393\n",
      "[CV 5/5] END ...epochs=75, layers=2, neurons=40;, score=0.839 total time=  42.\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 1.2844 - accuracy: 0.4196\n",
      "Epoch 4/75\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 1.1954 - accuracy: 0.4688"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:30:12.526304: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 22ms/step - loss: 0.2053 - accuracy: 0.8973\n",
      " 8/14 [================>.............] - ETA: 0s - loss: 6.5031e-05 - accuracy: 1.0000Epoch 42/75\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.0038 - accuracy: 1.0000\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0358 - accuracy: 0.9888\n",
      "Epoch 31/75\n",
      "Epoch 67/75\n",
      "11/14 [======================>.......]14/14 [==============================] - 0s 31ms/step - loss: 0.0683 - accuracy: 0.9688\n",
      " - ETA: 0s - loss: 6.9871e-05 - accuracy: 1.0000Epoch 28/75\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 6.7060e-05 - accuracy: 1.0000s - loss: 1.1371 - accuracy: 0.49\n",
      "Epoch 71/75\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 1.0820 - accuracy: 0.5179- loss: 6.2315e-05 - accuracy: 1.0000 - ETA: 0s - loss: 0.0571 - accuracy: 0.96\n",
      "14/14 [==============================] - 0s 22ms/step - loss: 0.0706 - accuracy: 0.9710\n",
      "Epoch 5/75\n",
      "Epoch 68/75\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.1119 - accuracy: 0.9576\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.0448 - accuracy: 0.9861Epoch 43/75\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0042 - accuracy: 1.0000A: 21s - loss: 1.6109 - accuracy: 0.18\n",
      " 3/14 [=====>........................]Epoch 32/75\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 7.0442e-05 - accuracy: 1.0000\n",
      "Epoch 72/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.0381 - accuracy: 0.9866\n",
      "Epoch 29/75\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 0.1401 - accuracy: 0.9531A: 0s - loss: 0.9242 - accuracy: 0.50\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 1.5763 - accuracy: 0.2951Epoch 69/75\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.8761 - accuracy: 0.5201\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 8.6087e-05 - accuracy: 1.0000Epoch 6/75\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.0839 - accuracy: 0.9643\n",
      "Epoch 44/75\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 33/75\n",
      "14/14 [==============================] - 2s 33ms/step - loss: 1.5735 - accuracy: 0.3259\n",
      "Epoch 2/75\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 1.3853e-04 - accuracy: 1.0000A: 0s - loss: 0.7720 - accuracy: 0.52\n",
      " 5/14 [=========>....................] - ETA: 0s - loss: 0.0045 - accuracy: 1.0000Epoch 73/75\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.0446 - accuracy: 0.9777\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 0.0039 - accuracy: 1.0000Epoch 30/75\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.1631 - accuracy: 0.9442\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.0046 - accuracy: 1.0000Epoch 70/75\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.7109 - accuracy: 0.5759- loss: 0.7109 - accuracy: 0.5759 - ETA: 0s - loss: 0.0041 - accuracy: 1.00\n",
      "Epoch 7/75\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.1063 - accuracy: 0.9576\n",
      "Epoch 45/75\n",
      "14/14 [==============================] - 0s 24ms/step - loss: 1.4903 - accuracy: 0.3817\n",
      "Epoch 3/75\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0129 - accuracy: 0.9933\n",
      "Epoch 34/75\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 1.5320e-04 - accuracy: 1.0000\n",
      "Epoch 74/75\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.2409 - accuracy: 0.9152A: 0s - loss: 0.2500 - accuracy: 0.\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 1.4949 - accuracy: 0.3203 - ETA: 0s - loss: 0.0773 - accuracy: 0.9688Epoch 71/75\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.0397 - accuracy: 0.9821\n",
      "Epoch 31/75\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.5733 - accuracy: 0.7768- loss: 0.0836 - accuracy: 0.9631 - ETA: 0s - loss: 0.5688 - accuracy: 0.76\n",
      "Epoch 8/75\n",
      "Epoch 1/75\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.0827 - accuracy: 0.9621\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 1.4548 - accuracy: 0.3750Epoch 46/75\n",
      "14/14 [============================= - 1s 37ms/step - loss: 1.4446 - accuracy: 0.3817\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 1.1050e-04 - accuracy: 1.0000Epoch 4/75\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.0159 - accuracy: 0.9933\n",
      "Epoch 35/75\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.1738 - accuracy: 0.9330A: 0s - loss: 1.0389e-04 - accuracy: 1.00\n",
      "Epoch 72/75\n",
      "14/14 [==============================] - 0s 37ms/step - loss: 1.0952e-04 - accuracy: 1.0000\n",
      "Epoch 75/75============>.............] - ETA: 0s - loss: 0.5028 - accuracy: 0.8672\n",
      "14/14 [==============================] - 1s 36ms/step - loss: 0.0259 - accuracy: 0.9888\n",
      "Epoch 32/75\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.1012 - accuracy: 0.9531- ETA: 0s - loss: 1.3191 - accuracy: 0.3854 - ETA: 0s - loss: 0.1070 - accuracy: 0.94\n",
      "Epoch 47/75\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.5125 - accuracy: 0.8705\n",
      "Epoch 9/75\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 1.2989 - accuracy: 0.3795\n",
      "Epoch 5/75\n",
      "14/14 [==============================] - 0s 24ms/step - loss: 0.1758 - accuracy: 0.9397\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 1.2565 - accuracy: 0.3125Epoch 73/75\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.0191 - accuracy: 0.9933\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.3242 - accuracy: 0.8750Epoch 36/75\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 1.1283e-04 - accuracy: 1.0000\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.0149 - accuracy: 0.9955\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 0.1375 - accuracy: 0.9464Epoch 33/75\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0737 - accuracy: 0.9799\n",
      "Epoch 48/75\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.0807 - accuracy: 0.9688: 0s - loss: 0.0093 - accuracy: 1.0000 - ETA: 0s - loss: 0.0929 - accuracy: 0.96"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:30:15.017242: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-01-09 14:30:15.215379: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 25ms/step - loss: 1.1701 - accuracy: 0.4174\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 0.0624 - accuracy: 0.9688Epoch 6/75\n",
      "14/14 [==============================] - 1s 33ms/step - loss: 0.4876 - accuracy: 0.8661\n",
      "Epoch 10/75\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.1098 - accuracy: 0.9554\n",
      " 4/14 [=======>......................] - ETA: 0s - loss: 1.0048 - accuracy: 0.6094Epoch 74/75\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.0056 - accuracy: 1.0000\n",
      "Epoch 37/75\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 2.7089e-04 - accuracy: 1.0000A: 0s - loss: 0.0684 - accuracy: 0.96\n",
      "12/14 [========================>.....] - ETA: 0s - loss: 0.9939 - accuracy: 0.5885[CV 2/5] END ...epochs=75, layers=2, neurons=60;, score=1.000 total time=  42.3s\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.0817 - accuracy: 0.9643\n",
      "Epoch 49/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.9914 - accuracy: 0.5826\n",
      "Epoch 7/75\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 0.0379 - accuracy: 0.9844\n",
      "Epoch 34/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.4451 - accuracy: 0.8705\n",
      "Epoch 11/75\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.0657 - accuracy: 0.9665\n",
      "Epoch 75/75\n",
      "14/14 [==============================] - 0s 36ms/step - loss: 0.0032 - accuracy: 1.0000\n",
      "Epoch 38/75\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.8110 - accuracy: 0.6228- loss: 0.0876 - accuracy: 0.9602 - ETA: 0s - loss: 0.0036 - accuracy: 1.00\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.0951 - accuracy: 0.9576\n",
      "Epoch 8/75\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 1.5761 - accuracy: 0.3293Epoch 50/75\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.0829 - accuracy: 0.9643\n",
      "14/14 [==============================] - 2s 41ms/step - loss: 1.5770 - accuracy: 0.3259\n",
      "Epoch 2/75\n",
      "14/14 [==============================] - 1s 36ms/step - loss: 0.0376 - accuracy: 0.9911\n",
      "Epoch 35/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.3860 - accuracy: 0.8973\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 1.5567 - accuracy: 0.3125Epoch 12/75\n",
      "14/14 [==============================] 2/14 [===>..........................] - 0s 32ms/step - loss: 0.0021 - accuracy: 1.0000\n",
      " - ETA: 0s - loss: 0.1013 - accuracy: 0.9844Epoch 39/75\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.0879 - accuracy: 0.9732A: 0s - loss: 0.0879 - accuracy: 0.97TA: 0s - loss: 0.0671 - accuracy: 0.98\n",
      "Epoch 51/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.6896 - accuracy: 0.6250 [========================>.....] - ETA: 0s - loss: 1.5321 - accuracy: 0.3698\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 1.5306 - accuracy: 0.3638\n",
      "Epoch 9/75\n",
      "Epoch 3/75\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.3757 - accuracy: 0.9085\n",
      "Epoch 13/75\n",
      "11/14 [======================>.......] - ETA: 0s - loss: 0.0013 - accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:30:16.348030: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 32ms/step - loss: 9.5672e-04 - accuracy: 1.0000\n",
      "[CV 3/5] END ...epochs=75, layers=2, neurons=60;, score=1.000 total time=  35.4s\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.0612 - accuracy: 0.9888\n",
      " 4/14 [=======>......................] - ETA: 0s - loss: 0.5997 - accuracy: 0.6562Epoch 36/75\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 40/75\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0863 - accuracy: 0.9665- loss: 0.0011 - accuracy: 1.0000 - ETA: 0s - loss: 0.0895 - accuracy: 0.96\n",
      " 5/14 [=========>....................] - ETA: 0s - loss: 0.0011 - accuracy: 1.0000Epoch 52/75\n",
      "14/14 [==============================] - 0s 24ms/step - loss: 0.4103 - accuracy: 0.8638\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 1.4519 - accuracy: 0.3726Epoch 14/75\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.5886 - accuracy: 0.6674\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 0.0010 - accuracy: 1.0000Epoch 10/75\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 1.4522 - accuracy: 0.3683\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.4883 - accuracy: 0.7188Epoch 4/75\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 1.2962 - accuracy: 0.4688Epoch 1/75\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0859 - accuracy: 0.9732 - 0s 33ms/step - loss: 0.0329 - accuracy: 0.9955\n",
      "Epoch 37/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 9.1202e-04 - accuracy: 1.0000ss: 0.5756 - accuracy: 0.6367 - ETA: 0s - loss: 0.0039 - accuracy: 1.00\n",
      "Epoch 41/75\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.1006 - accuracy: 0.9653"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:30:17.109435: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 28ms/step - loss: 0.5832 - accuracy: 0.6496\n",
      "Epoch 11/75\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.1037 - accuracy: 0.9598\n",
      "Epoch 53/75\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 1.3242 - accuracy: 0.4464\n",
      "14/14 [==============================] - 1s 36ms/step - loss: 0.3393 - accuracy: 0.9085\n",
      "Epoch 5/75\n",
      "Epoch 15/75\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.0381 - accuracy: 0.9955- loss: 0.0542 - accuracy: 0.9965 - ETA: 0s - loss: 0.5558 - accuracy: 0.6719\n",
      "Epoch 38/75\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      " 2/14 [===>..........................] - ETA: 0s - loss: 0.0020 - accuracy: 1.0000Epoch 42/75\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.5817 - accuracy: 0.6674\n",
      " 4/14 [=======>......................] - ETA: 0s - loss: 0.0995 - accuracy: 0.9567 - ETA: 0s - loss: 5.1749e-04 - accuracy: 1.0000Epoch 12/753376 - accuracy: 0.90\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0952 - accuracy: 0.9598\n",
      "Epoch 54/75\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.3239 - accuracy: 0.9107\n",
      " 6/14 [===========>..................] - ETA: 0s - loss: 4.0896e-04 - accuracy: 1.0000Epoch 16/75\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 1.0922 - accuracy: 0.5446\n",
      "Epoch 6/75\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.0197 - accuracy: 1.00002/14 [========================>.....] - ETA: 0s - loss: 1.5312 - accuracy: 0.\n",
      " 8/14 [================>.............] - ETA: 0s - loss: 0.3345 - accuracy: 0.9023Epoch 39/75\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 1.5222 - accuracy: 0.3683\n",
      "Epoch 2/75\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 3.7277e-04 - accuracy: 1.0000\n",
      "11/14 [======================>.......] - ETA: 0s - loss: 0.1096 - accuracy: 0.9489Epoch 43/75\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 0.5443 - accuracy: 0.6719\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.9034 - accuracy: 0.6354Epoch 13/75\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 0.0015 - accuracy: 1.0000Epoch 1/75\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.0991 - accuracy: 0.9509\n",
      "Epoch 55/75\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.3372 - accuracy: 0.9085- loss: 0.0930 - accuracy: 0.9688 - ETA: 0s - loss: 0.8925 - accuracy: 0.62\n",
      " 6/14 [===========>..................] - ETA: 0s - loss: 1.4977 - accuracy: 0.3958Epoch 17/75\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.8839 - accuracy: 0.6272\n",
      "Epoch 7/75\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.5527 - accuracy: 0.7299\n",
      "Epoch 14/75\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.0228 - accuracy: 0.9978- loss: 0.3551 - accuracy: 0.9018 - ETA: 0s - loss: 3.2954e-04 - accuracy: 1.00\n",
      "Epoch 40/75\n",
      " - 1s 37ms/step - loss: 1.4697 - accuracy: 0.3862- loss: 1.4697 - accuracy: 0.38\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.0458 - accuracy: 1.0000Epoch 3/75\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 2.9570e-04 - accuracy: 1.0000\n",
      "Epoch 44/75\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.7557 - accuracy: 0.6597"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:30:18.488826: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 31ms/step - loss: 0.0982 - accuracy: 0.9531\n",
      "Epoch 56/75\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.3287 - accuracy: 0.9152A: 0s - loss: 9.9765e-05 - accuracy: 1.0000\n",
      "Epoch 18/75\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.7482 - accuracy: 0.6496\n",
      "Epoch 8/75\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.5160 - accuracy: 0.7076A: 0s - loss: 0.1007 - accuracy: 0.95\n",
      "Epoch 15/75\n",
      "14/14 [==============================] - 0s 36ms/step - loss: 0.0699 - accuracy: 0.9866A: 0s - loss: 3.2079e-04 - accuracy: 1.\n",
      "Epoch 41/75\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 1.4226 - accuracy: 0.3862\n",
      "Epoch 4/75\n",
      "14/14 [==============================] - ETA: 0s - loss: 1.5840 - accuracy: 0.3086 - 0s 29ms/step - loss: 0.0873 - accuracy: 0.9710\n",
      "Epoch 57/75\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.2812 - accuracy: 0.9330\n",
      "Epoch 19/75\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 3.0896e-04 - accuracy: 1.0000\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 0.0825 - accuracy: 0.9583Epoch 45/75\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.5383 - accuracy: 0.7522\n",
      " 5/14 [=========>....................] - ETA: 0s - loss: 0.0656 - accuracy: 0.9875Epoch 16/75\n",
      "14/14 [==============================] - 1s 35ms/step - loss: 0.6357 - accuracy: 0.6763\n",
      "Epoch 9/75\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 1.5563 - accuracy: 0.3393A: 0s - loss: 1.1455e-04 - accuracy: 1.00\n",
      "Epoch 2/75\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.0750 - accuracy: 0.9665\n",
      "Epoch 58/75\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.0826 - accuracy: 0.9799\n",
      "Epoch 42/75\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.2677 - accuracy: 0.9375\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.5132 - accuracy: 0.7292Epoch 20/75\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 1.3002 - accuracy: 0.3862\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 2.3471e-04 - accuracy: 1.0000Epoch 5/75\n",
      " - ETA: 0s - loss: 1.4731 - accuracy: 0.387014/14 [==============================] - 0s 28ms/step - loss: 0.4710 - accuracy: 0.7969\n",
      "Epoch 17/75\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 2.4256e-04 - accuracy: 1.0000\n",
      " 3/14 [=====>........................]14/14 [==============================] - 0s 20ms/step - loss: 1.4783 - accuracy: 0.3750\n",
      "11/14 [======================>.......] - ETA: 0s - loss: 0.5261 - accuracy: 0.7188Epoch 3/75\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.6899 - accuracy: 0.5938Epoch 46/75\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.5202 - accuracy: 0.7232A: 0s - loss: 0.0610 - accuracy: 0.98\n",
      "Epoch 10/75\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.1514 - accuracy: 0.9509\n",
      "Epoch 43/75\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.0701 - accuracy: 0.9777\n",
      "Epoch 59/75\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.2586 - accuracy: 0.9420\n",
      "Epoch 21/75\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 1.2820 - accuracy: 0.5000\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.4275 - accuracy: 0.8058\n",
      "Epoch 4/75\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 1.1379 - accuracy: 0.3951\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.0594 - accuracy: 0.9688Epoch 18/75\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.4707 - accuracy: 0.8090Epoch 6/75\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 2.6866e-04 - accuracy: 1.0000ss: 0.3567 - accuracy: 0.8750 - ETA: 0s - loss: 0.2751 - accuracy: 0.90\n",
      "Epoch 47/75\n",
      "14/14 [==============================] - 1s 36ms/step - loss: 0.4891 - accuracy: 0.8281- loss: 0.4625 - accuracy: 0.8125 - ETA: 0s - loss: 0.3115 - accuracy: 0.88\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 0.2323 - accuracy: 0.9375Epoch 11/75\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.0639 - accuracy: 0.9844\n",
      "Epoch 60/75\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.9155 - accuracy: 0.5647\n",
      "Epoch 5/75\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.2154 - accuracy: 0.9263\n",
      "Epoch 44/75\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.4305 - accuracy: 0.8036\n",
      "Epoch 19/75\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 1.0420 - accuracy: 0.4040\n",
      "Epoch 7/75\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 2.5059e-04 - accuracy: 1.0000\n",
      "Epoch 48/75\n",
      "14/14 [==============================] - 1s 44ms/step - loss: 0.3291 - accuracy: 0.8996\n",
      "Epoch 22/75\n",
      " - ETA: 0s - loss: 3.0073e-04 - accuracy: 1.000014/14 [==============================] - 1s 33ms/step - loss: 0.4176 - accuracy: 0.8996\n",
      "Epoch 12/75\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.7263 - accuracy: 0.6562\n",
      "Epoch 6/75\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.4485 - accuracy: 0.7813\n",
      "11/14 [======================>.......] - ETA: 0s - loss: 2.1960e-04 - accuracy: 1.0000Epoch 20/75\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.0647 - accuracy: 0.9754\n",
      "Epoch 61/75\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.3262 - accuracy: 0.8951\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.0359 - accuracy: 1.0000Epoch 23/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.9064 - accuracy: 0.5379\n",
      "Epoch 8/75\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 4.8260e-04 - accuracy: 1.0000\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 0.4475 - accuracy: 0.7812Epoch 49/75\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.1269 - accuracy: 0.9576\n",
      " 1/14 [=>............................] 9/14 [==================>...........] - ETA: 0s - loss: 0.3784 - accuracy: 0.9062 - ETA: 0s - loss: 5.8667e-05 - accuracy: 1.0000Epoch 45/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.3702 - accuracy: 0.9174\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 0.7566 - accuracy: 0.6116Epoch 13/75\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 0.5596 - accuracy: 0.7478\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 0.3295 - accuracy: 0.8929Epoch 7/75\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.4075 - accuracy: 0.8170\n",
      "Epoch 21/75\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.0673 - accuracy: 0.9732\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.7820 - accuracy: 0.5737\n",
      "Epoch 9/75\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 0.4459 - accuracy: 0.7991Epoch 62/75\n",
      "14/14 [==============================] - 0s 36ms/step - loss: 0.3697 - accuracy: 0.8795\n",
      "Epoch 24/75\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 6.5817e-04 - accuracy: 1.0000\n",
      " 5/14 [=========>....................] - ETA: 0s - loss: 0.4797 - accuracy: 0.7812Epoch 50/75\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.0763 - accuracy: 0.9710\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 0.7321 - accuracy: 0.7083Epoch 46/75\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.3607 - accuracy: 0.8460\n",
      " 6/14 [===========>..................] - ETA: 0s - loss: 0.4486 - accuracy: 0.8802Epoch 8/75\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.4394 - accuracy: 0.8058A: 0s - loss: 0.7438 - accuracy: 0.\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 0.1788 - accuracy: 0.9375Epoch 22/75\n",
      "14/14 [==============================] - 1s 36ms/step - loss: 0.3500 - accuracy: 0.9107\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.5252 - accuracy: 0.7500Epoch 14/75\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.0694 - accuracy: 0.9754\n",
      "Epoch 63/75\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.4584 - accuracy: 0.8527- loss: 0.0330 - accuracy: 0.9965 - ETA: 0s - loss: 0.4049 - accuracy: 0.81\n",
      "Epoch 25/75\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.7426 - accuracy: 0.7031\n",
      "11/14 [======================>.......] - ETA: 0s - loss: 0.0397 - accuracy: 0.9915Epoch 10/75\n",
      "14/14 [==============================] - 0s 22ms/step - loss: 0.2247 - accuracy: 0.9063\n",
      "Epoch 9/75\n",
      "14/14 [==============================] - 1s 36ms/step - loss: 6.9459e-04 - accuracy: 1.0000s - loss: 0.7569 - accuracy: 0.78\n",
      "Epoch 51/75\n",
      "14/14 [==============================] - 1s 36ms/step - loss: 0.0398 - accuracy: 0.9911A: 0s - loss: 0.7765 - accuracy: 0.75\n",
      "Epoch 47/75\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.3972 - accuracy: 0.8170\n",
      "Epoch 23/75\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.0762 - accuracy: 0.9732\n",
      "Epoch 64/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.3461 - accuracy: 0.9085\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 6.2500e-04 - accuracy: 1.0000Epoch 15/75\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.3747 - accuracy: 0.8839\n",
      "Epoch 26/75\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.1329 - accuracy: 0.9665\n",
      "Epoch 10/75\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.7562 - accuracy: 0.7165\n",
      "Epoch 11/75\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 6.5476e-04 - accuracy: 1.0000s - loss: 0.2751 - accuracy: 0.88\n",
      "11/14 [======================>.......] - ETA: 0s - loss: 0.0829 - accuracy: 0.9688Epoch 52/75\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.3506 - accuracy: 0.8281A: 0s - loss: 0.3506 - accuracy: 0.82\n",
      "Epoch 24/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.0586 - accuracy: 0.9866\n",
      "Epoch 48/75\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0756 - accuracy: 0.9754\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.2807 - accuracy: 0.8993Epoch 65/75\n",
      "14/14 [==============================] - 0s 21ms/step - loss: 0.1059 - accuracy: 0.9598\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.3059 - accuracy: 0.9263\n",
      " 5/14 [=========>....................] - ETA: 0s - loss: 7.3378e-04 - accuracy: 1.0000Epoch 11/75\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 0.0644 - accuracy: 0.9896Epoch 16/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.2841 - accuracy: 0.9040\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 0.3008 - accuracy: 0.9062Epoch 27/75\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0654 - accuracy: 0.9792 - 0s 34ms/step - loss: 0.7510 - accuracy: 0.7143A: 0s - loss: 6.5094e-04 - accuracy: 1.00\n",
      "Epoch 12/75\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.4108 - accuracy: 0.8013\n",
      "Epoch 25/75\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0747 - accuracy: 0.9777\n",
      "Epoch 66/75\n",
      "14/14 [==============================] - 1s 36ms/step - loss: 5.3943e-04 - accuracy: 1.0000\n",
      "Epoch 53/75\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.0626 - accuracy: 0.9821\n",
      "Epoch 49/75\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 0.1389 - accuracy: 0.9420\n",
      "Epoch 12/75\n",
      " 5/14 [=========>....................] - ETA: 0s - loss: 1.2571e-04 - accuracy: 1.0000 - 0s 36ms/step - loss: 0.2905 - accuracy: 0.9353\n",
      "Epoch 17/75\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.2564 - accuracy: 0.9174\n",
      "Epoch 28/75\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.3852 - accuracy: 0.8214A: 0s - loss: 0.3852 - accuracy: 0.82\n",
      "Epoch 26/75\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.7163 - accuracy: 0.7165\n",
      "Epoch 13/75\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.1618 - accuracy: 0.9554\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0465 - accuracy: 0.9844\n",
      "Epoch 13/75\n",
      "Epoch 67/75\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.0571 - accuracy: 0.9821A: 0s - loss: 0.1109 - accuracy: 0.93\n",
      "Epoch 50/75\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 2.4797e-04 - accuracy: 1.0000\n",
      "Epoch 54/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.2662 - accuracy: 0.9509A: 0s - loss: 0.3699 - accuracy: 0.82\n",
      "Epoch 18/75\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.2734 - accuracy: 0.9219\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.0727 - accuracy: 0.9722Epoch 29/75\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.3729 - accuracy: 0.8237\n",
      "Epoch 27/75\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.1018 - accuracy: 0.9554\n",
      "Epoch 14/75\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.0765 - accuracy: 0.9688\n",
      "Epoch 68/75\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.6761 - accuracy: 0.7411\n",
      "11/14 [======================>.......] - ETA: 0s - loss: 0.0404 - accuracy: 0.9886Epoch 14/75\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 1.9798e-04 - accuracy: 1.0000\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.2731 - accuracy: 0.9531Epoch 55/75\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.0383 - accuracy: 0.9911\n",
      "12/14 [========================>.....] - ETA: 0s - loss: 0.2639 - accuracy: 0.9583Epoch 51/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.2596 - accuracy: 0.9531\n",
      "Epoch 19/75\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.2488 - accuracy: 0.9219\n",
      "Epoch 30/75\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.0937 - accuracy: 0.9621\n",
      "Epoch 15/75\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.3704 - accuracy: 0.8192\n",
      "Epoch 28/75\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.0666 - accuracy: 0.9665- ETA: 0s - loss: 0.0666 - accuracy: 0.96\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.6847 - accuracy: 0.7156Epoch 69/75\n",
      " - ETA: 0s - loss: 0.1185 - accuracy: 0.960914/14 [==============================] - 0s 32ms/step - loss: 0.6532 - accuracy: 0.7165- loss: 0.2190 - accuracy: 0.93\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 0.2235 - accuracy: 0.9286Epoch 15/75\n",
      "14/14 [==============================] 5/14 [=========>....................] - 1s 38ms/step - loss: 1.9916e-04 - accuracy: 1.0000\n",
      " - ETA: 0s - loss: 0.5107 - accuracy: 0.7688Epoch 56/75\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.2121 - accuracy: 0.9353\n",
      "Epoch 31/75\n",
      "14/14 [==============================] - 0s 23ms/step - loss: 0.3932 - accuracy: 0.8125\n",
      "Epoch 29/75\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.1071 - accuracy: 0.9621\n",
      "Epoch 16/75\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.2771 - accuracy: 0.9420\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.3688 - accuracy: 0.8750Epoch 20/75\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.0507 - accuracy: 0.9754\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 0.5078 - accuracy: 0.7411Epoch 52/75\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.1519 - accuracy: 0.9397A: 0s - loss: 0.3456 - accuracy: 0.85\n",
      "Epoch 70/75\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.4814 - accuracy: 0.7366- ETA: 0s - loss: 0.0302 - accuracy: 0.99\n",
      "Epoch 16/75\n",
      "14/14 [==============================] - 0s 23ms/step - loss: 0.0870 - accuracy: 0.9576\n",
      "Epoch 17/75\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.3777 - accuracy: 0.8125A: 0s - loss: 0.3757 - accuracy: 0.81\n",
      "Epoch 30/75\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 2.0357e-04 - accuracy: 1.0000s - loss: 0.2580 - accuracy: 0.91\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.2586 - accuracy: 0.9152\n",
      "Epoch 57/75\n",
      "Epoch 32/75\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.0358 - accuracy: 0.9933\n",
      "Epoch 53/75\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.2895 - accuracy: 0.9241\n",
      " 5/14 [=========>....................]Epoch 21/75- loss: 0.0999 - accuracy: 0.95\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.3429 - accuracy: 0.8973- loss: 0.4004 - accuracy: 0.8750 - ETA: 0s - loss: 4.3301e-04 - accuracy: 1.0000\n",
      " 5/14 [=========>....................] - ETA: 0s - loss: 0.2594 - accuracy: 0.9000Epoch 71/75\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.0918 - accuracy: 0.9598\n",
      "Epoch 18/75\n",
      "14/14 [==============================] - 1s 46ms/step - loss: 0.4001 - accuracy: 0.7455\n",
      "Epoch 17/75\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.4079 - accuracy: 0.7969\n",
      " 8/14 [================>.............] - ETA: 0s - loss: 0.6355 - accuracy: 0.78Epoch 31/75\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.2627 - accuracy: 0.9063\n",
      "11/14 [======================>.......] - ETA: 0s - loss: 0.0477 - accuracy: 0.9801Epoch 33/75\n",
      "14/14 [==============================] - 1s 43ms/step - loss: 2.2118e-04 - accuracy: 1.0000\n",
      "Epoch 58/75\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.2334 - accuracy: 0.9554\n",
      "Epoch 22/75\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.0494 - accuracy: 0.9777\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.6255 - accuracy: 0.8005Epoch 54/75\n",
      "14/14 [==============================] - 0s 36ms/step - loss: 0.6085 - accuracy: 0.8013\n",
      "Epoch 72/75\n",
      "14/14 [==============================] - 0s 21ms/step - loss: 0.0765 - accuracy: 0.9710\n",
      "Epoch 19/75\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.7617 - accuracy: 0.6295- loss: 0.0561 - accuracy: 0.9777 - ETA: 0s - loss: 0.7617 - accuracy: 0.62\n",
      "Epoch 32/75\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.4319 - accuracy: 0.7344\n",
      "Epoch 18/75\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.2186 - accuracy: 0.9219\n",
      "Epoch 34/75\n",
      "14/14 [==============================] - 0s 20ms/step - loss: 0.0511 - accuracy: 0.9799\n",
      "11/14 [======================>.......] - ETA: 0s - loss: 0.2158 - accuracy: 0.9432Epoch 20/75\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 1.9716e-04 - accuracy: 1.0000ss: 0.0471 - accuracy: 0.9830 - ETA: 0s - loss: 0.1167 - accuracy: 0.93\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.2202 - accuracy: 0.9399Epoch 59/75\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.2233 - accuracy: 0.9375- loss: 0.7635 - accuracy: 0.6042 - ETA: 0s - loss: 0.0449 - accuracy: 0.98\n",
      "Epoch 73/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.0449 - accuracy: 0.9866\n",
      "Epoch 55/75\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.2581 - accuracy: 0.9308\n",
      "Epoch 23/75\n",
      "14/14 [==============================] - 0s 24ms/step - loss: 0.7696 - accuracy: 0.5893\n",
      "Epoch 33/75\n",
      " 7/14 [==============>...............] - 0s 24ms/step - loss: 0.0489 - accuracy: 0.9754\n",
      " - ETA: 0s - loss: 0.0628 - accuracy: 0.9732Epoch 21/75\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.4054 - accuracy: 0.7656\n",
      "Epoch 19/75\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.2207 - accuracy: 0.9263\n",
      "Epoch 35/75\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.1753 - accuracy: 0.9397- loss: 0.4909 - accuracy: 0.7188 - ETA: 0s - loss: 0.7923 - accuracy: 0.5469 - ETA: 0s - loss: 0.2452 - accuracy: 0.9410\n",
      "Epoch 74/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 2.9395e-04 - accuracy: 1.0000\n",
      "Epoch 60/75\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.2282 - accuracy: 0.9554- loss: 0.7589 - accuracy: 0.5649 - ETA: 0s - loss: 6.7823e-05 - accuracy: 1.00\n",
      "Epoch 24/75\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.7678 - accuracy: 0.5580\n",
      "Epoch 34/75\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.0476 - accuracy: 0.9754\n",
      "Epoch 56/75\n",
      "14/14 [==============================] - 0s 22ms/step - loss: 0.0407 - accuracy: 0.9844\n",
      " 5/14 [=========>....................] - ETA: 0s - loss: 0.0964 - accuracy: 0.9313Epoch 22/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.3698 - accuracy: 0.7522- loss: 0.2788 - accuracy: 0.9271 - ETA: 0s - loss: 0.4022 - accuracy: 0.\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.2216 - accuracy: 0.9330\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 2.4988e-04 - accuracy: 1.0000Epoch 20/75\n",
      "Epoch 36/75\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.7406 - accuracy: 0.5781A: 0s - loss: 0.3073 - accuracy: 0.92\n",
      "14/14 [==============================]Epoch 35/75\n",
      " - 0s 32ms/step - loss: 0.0810 - accuracy: 0.9643\n",
      "Epoch 75/75\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.0522 - accuracy: 0.9754- loss: 2.4215e-04 - accuracy: 1.0000 - ETA: 0s - loss: 0.0678 - accuracy: 1.00\n",
      "Epoch 23/75\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.2586 - accuracy: 0.9375\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.0544 - accuracy: 0.9799\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 2.3307e-04 - accuracy: 1.0000\n",
      "Epoch 57/75\n",
      "Epoch 61/75\n",
      "Epoch 25/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.3652 - accuracy: 0.7455A: 0s - loss: 0.2027 - accuracy: 0.92\n",
      "Epoch 21/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.2227 - accuracy: 0.9152\n",
      "Epoch 37/75\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.6686 - accuracy: 0.6674\n",
      "Epoch 36/75\n",
      "14/14 [==============================] - 0s 24ms/step - loss: 0.0687 - accuracy: 0.9688\n",
      "Epoch 24/75\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.0824 - accuracy: 0.9754\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 2.0184e-04 - accuracy: 1.0000\n",
      "Epoch 62/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.2628 - accuracy: 0.9241\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 0.6974 - accuracy: 0.6741Epoch 26/75\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.0349 - accuracy: 0.9799\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.0828 - accuracy: 1.0000Epoch 58/75\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.1319 - accuracy: 0.9487A: 0s - loss: 0.2256 - accuracy: 0.92\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.2599 - accuracy: 0.8996\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 0.1859 - accuracy: 0.9598Epoch 25/75\n",
      "Epoch 38/75\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.6861 - accuracy: 0.6964\n",
      "Epoch 37/75\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.1962 - accuracy: 0.93750000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:30:27.720532: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 35ms/step - loss: 0.3405 - accuracy: 0.7478\n",
      "Epoch 22/75\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.0463 - accuracy: 0.99110\n",
      "[CV 4/5] END ...epochs=75, layers=2, neurons=60;, score=0.991 total time=  41.6s\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.2330 - accuracy: 0.9397- loss: 0.1953 - accuracy: 0.9375 - ETA: 0s - loss: 0.0403 - accuracy: 0.98\n",
      " 6/14 [===========>..................] - ETA: 0s - loss: 0.3052 - accuracy: 0.7917Epoch 27/75\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 3.3501e-04 - accuracy: 1.0000\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.7023 - accuracy: 0.6528Epoch 63/75\n",
      "14/14 [==============================] - 0s 24ms/step - loss: 0.2038 - accuracy: 0.9308A: 0s - loss: 0.1863 - accuracy: 0.94\n",
      "Epoch 26/75\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.0350 - accuracy: 0.9844\n",
      "Epoch 59/75\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.7107 - accuracy: 0.6786\n",
      "Epoch 38/75\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.1891 - accuracy: 0.9353\n",
      " 4/14 [=======>......................] - ETA: 0s - loss: 0.1395 - accuracy: 0.9297Epoch 39/75\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.3195 - accuracy: 0.7723\n",
      "Epoch 23/75\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.2332 - accuracy: 0.9308\n",
      "Epoch 28/75\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 0.1011 - accuracy: 0.9643\n",
      "Epoch 27/75\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 3.2256e-04 - accuracy: 1.0000\n",
      "Epoch 64/75\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.8358 - accuracy: 0.6071\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.0371 - accuracy: 0.9866\n",
      "Epoch 39/75\n",
      "Epoch 60/75\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.2107 - accuracy: 0.9152\n",
      "Epoch 40/75\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.3157 - accuracy: 0.7857\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 0.2050 - accuracy: 0.9479Epoch 24/75\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 0.8316 - accuracy: 0.5982Epoch 1/75\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.0514 - accuracy: 0.9732\n",
      "Epoch 28/75\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.2038 - accuracy: 0.9531\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.7797 - accuracy: 0.6281Epoch 29/75\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 3.2074e-04 - accuracy: 1.0000\n",
      "Epoch 65/75\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.7753 - accuracy: 0.6339\n",
      "Epoch 40/75\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.1902 - accuracy: 0.9330A: 0s - loss: 4.8664e-04 - accuracy: 1.00\n",
      "Epoch 41/75\n",
      "12/14 [========================>.....] - ETA: 0s - loss: 0.2891 - accuracy: 0.8255"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:30:28.929516: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 28ms/step - loss: 0.2998 - accuracy: 0.8125\n",
      " 4/14 [=======>......................]Epoch 25/75 - ETA: 0s - loss: 0.7226 - accuracy: 0.6562\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.0457 - accuracy: 0.9844\n",
      "Epoch 61/75\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.0510 - accuracy: 0.9777\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 0.0290 - accuracy: 1.0000Epoch 29/75\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.2200 - accuracy: 0.9375\n",
      "Epoch 30/75\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 0.7043 - accuracy: 0.6808\n",
      "Epoch 41/75\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.1802 - accuracy: 0.9375\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 1.7119e-04 - accuracy: 1.0000\n",
      "Epoch 42/75\n",
      "Epoch 66/75\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.2823 - accuracy: 0.8013\n",
      "Epoch 26/75\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.0421 - accuracy: 0.9844\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.6656 - accuracy: 0.7396Epoch 62/75\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0345 - accuracy: 0.9844\n",
      "Epoch 30/75\n",
      "14/14 [==============================] 7/14 [==============>...............] - 0s 34ms/step - loss: 0.1691 - accuracy: 0.9598\n",
      " 4/14 [=======>......................] - ETA: 0s - loss: 0.0333 - accuracy: 0.9844Epoch 31/75\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.6717 - accuracy: 0.7165\n",
      "Epoch 42/75\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 1.5087 - accuracy: 0.3594\n",
      "Epoch 2/75\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.1953 - accuracy: 0.9241\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.0363 - accuracy: 0.9784Epoch 43/75\n",
      "14/14 [==============================] - 0s 23ms/step - loss: 0.0369 - accuracy: 0.9777\n",
      "Epoch 31/75\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 3.4011e-04 - accuracy: 1.0000\n",
      " 8/14 [================>.............]Epoch 67/75- loss: 0.0430 - accuracy: 0.97\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.2922 - accuracy: 0.8571\n",
      "Epoch 27/75\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.0429 - accuracy: 0.9754\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 0.2487 - accuracy: 0.9196Epoch 63/75\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.6447 - accuracy: 0.7388\n",
      " 5/14 [=========>....................] - ETA: 0s - loss: 9.7925e-05 - accuracy: 1.0000Epoch 43/75\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.1808 - accuracy: 0.9397\n",
      "Epoch 32/75\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 1.2798 - accuracy: 0.4688\n",
      "Epoch 3/75\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 0.0273 - accuracy: 0.9844\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 0.1354 - accuracy: 0.9792Epoch 32/75\n",
      " 5/14 [=========>....................] - 0s 34ms/step - loss: 0.2298 - accuracy: 0.9196\n",
      " 8/14 [================>.............] - ETA: 0s - loss: 0.6800 - accuracy: 0.7266Epoch 44/75\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 1.9905e-04 - accuracy: 1.0000\n",
      "Epoch 68/75\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.3149 - accuracy: 0.8728\n",
      "Epoch 28/75\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.6590 - accuracy: 0.7321\n",
      "Epoch 44/75\n",
      "14/14 [==============================] - 1s 36ms/step - loss: 0.0472 - accuracy: 0.9821\n",
      "Epoch 64/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.1386 - accuracy: 0.9754\n",
      "Epoch 33/75\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.0204 - accuracy: 0.9933\n",
      "Epoch 33/75\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.7999 - accuracy: 0.7366\n",
      " 8/14 [================>.............] - ETA: 0s - loss: 7.0645e-04 - accuracy: 1.0000Epoch 4/75\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.1958 - accuracy: 0.9219\n",
      " 8/14 [================>.............] - ETA: 0s - loss: 0.4362 - accuracy: 0.8164Epoch 45/75\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 0.6393 - accuracy: 0.7388\n",
      "Epoch 45/75\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 5.1617e-04 - accuracy: 1.0000\n",
      "Epoch 69/75\n",
      "14/14 [==============================] - 0s 24ms/step - loss: 0.0165 - accuracy: 0.9911\n",
      "Epoch 34/75\n",
      "14/14 [==============================] - 1s 36ms/step - loss: 0.4122 - accuracy: 0.8326\n",
      "Epoch 29/75\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.3446 - accuracy: 0.9018- ETA: 0s - loss: 0.3446 - accuracy: 0.90\n",
      "Epoch 5/75\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.0306 - accuracy: 0.9821\n",
      "Epoch 65/75\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.1633 - accuracy: 0.9509\n",
      "Epoch 34/75\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.2027 - accuracy: 0.9196- ETA: 0s - loss: 0.2027 - accuracy: 0.91\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.6301 - accuracy: 0.7455\n",
      "Epoch 46/75\n",
      "Epoch 46/75\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.0198 - accuracy: 0.9911\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 2.4592e-04 - accuracy: 1.0000\n",
      "Epoch 35/75\n",
      "Epoch 70/75\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.3958 - accuracy: 0.8348- loss: 0.0446 - accuracy: 0.9777 - ETA: 0s - loss: 0.0059 - accuracy: 1.\n",
      "Epoch 30/75\n",
      "14/14 [==============================] - 0s 36ms/step - loss: 0.1342 - accuracy: 0.9688A: 0s - loss: 0.3490 - accuracy: 0.84\n",
      "14/14 [==============================] - 0s 36ms/step - loss: 0.0380 - accuracy: 0.9844\n",
      "Epoch 6/75\n",
      "Epoch 66/75\n",
      "14/14 [==============================] - 0s 23ms/step - loss: 0.0169 - accuracy: 0.9955\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.1595 - accuracy: 0.9554\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 0.3410 - accuracy: 0.8438Epoch 35/75\n",
      "Epoch 36/75\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.6264 - accuracy: 0.7299\n",
      "Epoch 47/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.1979 - accuracy: 0.9219A: 0s - loss: 0.6437 - accuracy: 0.65\n",
      "Epoch 47/75\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 2.3204e-04 - accuracy: 1.0000\n",
      "Epoch 71/75\n",
      "14/14 [==============================] - 0s 21ms/step - loss: 0.0119 - accuracy: 0.9978\n",
      "Epoch 37/75\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.0639 - accuracy: 0.9844\n",
      "Epoch 7/75\n",
      "14/14 [==============================] - 1s 36ms/step - loss: 0.3395 - accuracy: 0.8527\n",
      "Epoch 31/75\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.6316 - accuracy: 0.7188\n",
      "Epoch 48/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.0379 - accuracy: 0.9844\n",
      "Epoch 67/75\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.1562 - accuracy: 0.9420\n",
      "Epoch 36/75\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.1819 - accuracy: 0.9263\n",
      "Epoch 48/75\n",
      "14/14 [==============================] - 0s 23ms/step - loss: 0.0140 - accuracy: 0.9955\n",
      "Epoch 38/75\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.4426 - accuracy: 0.8507 - 0s 35ms/step - loss: 1.9683e-04 - accuracy: 1.0000\n",
      "Epoch 72/75\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0332 - accuracy: 0.9911\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 0.2069 - accuracy: 0.9107Epoch 8/75\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.6072 - accuracy: 0.7433\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.0538 - accuracy: 0.9719Epoch 49/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.4835 - accuracy: 0.8080A: 0s - loss: 0.0183 - accuracy: 1.00\n",
      "Epoch 32/75\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.1580 - accuracy: 0.9509\n",
      "Epoch 37/75\n",
      "14/14 [==============================] - 0s 21ms/step - loss: 0.0222 - accuracy: 0.9933\n",
      "Epoch 39/75\n",
      "14/14 [==============================] - 0s 36ms/step - loss: 0.0407 - accuracy: 0.9799\n",
      " 3/14 [=====>........................]Epoch 68/75\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.1906 - accuracy: 0.9174\n",
      "Epoch 49/75\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.5977 - accuracy: 0.7344- loss: 9.4861e-05 - accuracy: 1.0000 - ETA: 0s - loss: 0.0914 - accuracy: 0.\n",
      "Epoch 50/75\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 1.4920e-04 - accuracy: 1.0000A: 0s - loss: 0.1353 - accuracy: 0.96\n",
      "Epoch 73/75\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.0272 - accuracy: 0.9955\n",
      "11/14 [======================>.......] - ETA: 0s - loss: 0.4547 - accuracy: 0.8153Epoch 9/75\n",
      "14/14 [==============================] - 0s 23ms/step - loss: 0.0235 - accuracy: 0.9955\n",
      "Epoch 40/75\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.4171 - accuracy: 0.8170- loss: 0.0052 - accuracy: 1.0000 - ETA: 0s - loss: 0.0644 - accuracy: 0.97\n",
      "Epoch 33/75\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.1320 - accuracy: 0.9598- loss: 0.2551 - accuracy: 0.9006 - ETA: 0s - loss: 0.2713 - accuracy: 0.96\n",
      "Epoch 38/75\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.0399 - accuracy: 0.9844A: 0s - loss: 0.0399 - accuracy: 0.98\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.2378 - accuracy: 0.9063 - ETA: 0s - loss: 0.5762 - accuracy: 0.7656Epoch 69/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.2336 - accuracy: 0.9107\n",
      "Epoch 50/75\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 0.5794 - accuracy: 0.7522A: 0s - loss: 0.2684 - accuracy: 0.91\n",
      " 6/14 [===========>..................] - ETA: 0s - loss: 0.2737 - accuracy: 0.8958Epoch 51/75\n",
      "14/14 [==============================] - 0s 22ms/step - loss: 0.0322 - accuracy: 0.9955\n",
      "Epoch 41/75\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0483 - accuracy: 0.9821\n",
      "Epoch 10/75\n",
      "14/14 [==============================] - 0s 36ms/step - loss: 2.9819e-04 - accuracy: 1.0000\n",
      "Epoch 74/75\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.3506 - accuracy: 0.8884\n",
      "11/14 [======================>.......] - ETA: 0s - loss: 0.1407 - accuracy: 0.9460Epoch 34/75\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.2907 - accuracy: 0.8839- ETA: 0s - loss: 0.4199 - accuracy: 0.90\n",
      "Epoch 51/75\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.1382 - accuracy: 0.9487\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.0491 - accuracy: 0.9784Epoch 39/75\n",
      "14/14 [==============================] - 1s 35ms/step - loss: 0.0506 - accuracy: 0.9777\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.5731 - accuracy: 0.7455\n",
      "14/14 [==============================]Epoch 52/75\n",
      " - ETA: 0s - loss: 0.0235 - accuracy: 0.9978Epoch 70/75\n",
      "14/14 [==============================] - 0s 23ms/step - loss: 0.0235 - accuracy: 0.9978\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 0.3125 - accuracy: 0.9583Epoch 42/75\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.0430 - accuracy: 0.9799\n",
      " 5/14 [=========>....................] - ETA: 0s - loss: 0.2888 - accuracy: 0.9000Epoch 11/75\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 4.6796e-04 - accuracy: 1.0000\n",
      "Epoch 75/75\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.0079 - accuracy: 1.0000\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 1.3061e-04 - accuracy: 1.0000Epoch 43/75\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.3019 - accuracy: 0.9330\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.2523 - accuracy: 0.9018\n",
      "Epoch 35/75\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 0.0301 - accuracy: 0.9955Epoch 52/75\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.5729 - accuracy: 0.7634\n",
      "Epoch 53/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.1343 - accuracy: 0.9554\n",
      "Epoch 40/75\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.0274 - accuracy: 0.9911\n",
      "Epoch 71/75\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.0210 - accuracy: 0.9955\n",
      "Epoch 12/75\n",
      "14/14 [==============================] 4/14 [=======>......................] - 0s 23ms/step - loss: 0.0206 - accuracy: 1.0000\n",
      " - ETA: 0s - loss: 0.0062 - accuracy: 1.0000Epoch 44/75\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 2.0792e-04 - accuracy: 1.0000\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 0.5958 - accuracy: 0.7344\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.0407 - accuracy: 0.9896Epoch 54/75\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.2865 - accuracy: 0.9040\n",
      "11/14 [======================>.......] - ETA: 0s - loss: 0.0370 - accuracy: 0.9915Epoch 36/75\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.2114 - accuracy: 0.9241\n",
      "Epoch 53/75\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.0334 - accuracy: 0.9911\n",
      "Epoch 72/75\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0054 - accuracy: 1.0000\n",
      "Epoch 13/75\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.1501 - accuracy: 0.9308\n",
      "Epoch 41/75\n",
      "14/14 [==============================] - 0s 24ms/step - loss: 0.0740 - accuracy: 0.9732\n",
      "Epoch 45/75\n",
      " 7/14 [==============>...............] - 0s 28ms/step - loss: 0.6081 - accuracy: 0.7388\n",
      " 5/14 [=========>....................] - ETA: 0s - loss: 0.0628 - accuracy: 0.9812Epoch 55/75\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.1723 - accuracy: 0.9344"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:30:34.636124: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 29ms/step - loss: 0.2787 - accuracy: 0.9330\n",
      "Epoch 37/75\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.1982 - accuracy: 0.9241A: 0s - loss: 0.0264 - accuracy: 0.99\n",
      "Epoch 54/75\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 1.1047e-04 - accuracy: 1.0000\n",
      "[CV 5/5] END ...epochs=75, layers=2, neurons=60;, score=1.000 total time=  42.9s\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.1115 - accuracy: 0.9643\n",
      "Epoch 42/75\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 0.0651 - accuracy: 0.9732\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.0366 - accuracy: 0.9911\n",
      "Epoch 46/75\n",
      "Epoch 73/75\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0059 - accuracy: 0.9978\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.1327 - accuracy: 0.9688Epoch 14/75\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.6011 - accuracy: 0.7366- loss: 0.2526 - accuracy: 0.9107 - ETA: 0s - loss: 0.1341 - accuracy: 0.95\n",
      "Epoch 56/75\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.2775 - accuracy: 0.9263\n",
      "Epoch 38/75\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.2257 - accuracy: 0.9085\n",
      "Epoch 55/75\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.1518 - accuracy: 0.9554\n",
      " 8/14 [================>.............] - ETA: 0s - loss: 0.6124 - accuracy: 0.7461Epoch 47/75\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0170 - accuracy: 0.9955\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 0.2670 - accuracy: 0.9479Epoch 15/75\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.0347 - accuracy: 0.9866\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.5902 - accuracy: 0.7594Epoch 74/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.1104 - accuracy: 0.9598\n",
      "Epoch 43/75\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.5785 - accuracy: 0.7500\n",
      "Epoch 57/75\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.0587 - accuracy: 0.9799\n",
      "Epoch 48/75\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.2591 - accuracy: 0.9375\n",
      "Epoch 39/75\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.0303 - accuracy: 0.9866\n",
      "Epoch 16/75\n",
      "14/14 [==============================] - 0s 36ms/step - loss: 0.1626 - accuracy: 0.9375\n",
      "Epoch 56/75\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.1167 - accuracy: 0.9509\n",
      "Epoch 44/75\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.0321 - accuracy: 0.9844\n",
      "Epoch 75/75\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.5678 - accuracy: 0.7500\n",
      "Epoch 58/75\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.0729 - accuracy: 0.9757 - 0s 24ms/step - loss: 0.0454 - accuracy: 0.9844- loss: 0.5904 - accuracy: 0.71\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 0.2334 - accuracy: 0.9063Epoch 49/75\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.3033 - accuracy: 0.9063\n",
      " - ETA: 0s - loss: 0.0444 - accuracy: 0.9821Epoch 40/75\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.0870 - accuracy: 0.9665\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.1190 - accuracy: 0.9495Epoch 17/75\n",
      "Epoch 1/75\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.1261 - accuracy: 0.9487\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.1615 - accuracy: 0.9375Epoch 45/75\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.2040 - accuracy: 0.9174A: 0s - loss: 0.2040 - accuracy: 0.91\n",
      "Epoch 57/75\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.0373 - accuracy: 0.9866\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.5720 - accuracy: 0.7299\n",
      " 4/14 [=======>......................] - ETA: 0s - loss: 0.1149 - accuracy: 0.9609Epoch 59/75\n",
      "14/14 [==============================] - 0s 23ms/step - loss: 0.0449 - accuracy: 0.9866\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.6535 - accuracy: 0.6250Epoch 50/75\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.3756 - accuracy: 0.8304\n",
      "Epoch 41/75\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.0880 - accuracy: 0.9732\n",
      "Epoch 18/75\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.1171 - accuracy: 0.9554\n",
      "Epoch 46/75\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 0.1659 - accuracy: 0.9330\n",
      " 4/14 [=======>......................] - ETA: 0s - loss: 0.0214 - accuracy: 0.9922Epoch 58/75\n",
      " 5/14 [=========>....................] - 0s 23ms/step - loss: 0.0484 - accuracy: 0.9777\n",
      " - ETA: 0s - loss: 0.3472 - accuracy: 0.8750Epoch 51/75\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.5511 - accuracy: 0.7701\n",
      "Epoch 60/75\n",
      " 8/14 [================>.............] - ETA: 0s - loss: 0.1373 - accuracy: 0.9375"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:30:36.638719: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 27ms/step - loss: 0.0364 - accuracy: 0.9888\n",
      "Epoch 19/75\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 0.0032 - accuracy: 1.0000\n",
      "[CV 1/5] END ...epochs=75, layers=3, neurons=20;, score=1.000 total time=  44.3s\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.3414 - accuracy: 0.8460\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.0233 - accuracy: 1.0000Epoch 42/75\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.1981 - accuracy: 0.9263\n",
      "12/14 [========================>.....] - ETA: 0s - loss: 0.1150 - accuracy: 0.9531Epoch 47/75\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.2509 - accuracy: 0.8438"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:30:36.914513: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 25ms/step - loss: 0.0168 - accuracy: 0.9955\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.4683 - accuracy: 0.8750Epoch 52/75\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.1283 - accuracy: 0.9487\n",
      "Epoch 59/75\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.5485 - accuracy: 0.7656\n",
      "Epoch 61/75\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0374 - accuracy: 0.9866A: 0s - loss: 0.2301 - accuracy: 0.90\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 1.5887 - accuracy: 0.3438 Epoch 20/75\n",
      "14/14 [==============================] - 0s 22ms/step - loss: 0.0152 - accuracy: 1.0000\n",
      "Epoch 53/75\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.2653 - accuracy: 0.9152\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.3419 - accuracy: 0.8304\n",
      "Epoch 48/75\n",
      "Epoch 43/75\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.1759 - accuracy: 0.9219\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 0.0010 - accuracy: 1.0000Epoch 60/75\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.5735 - accuracy: 0.7656\n",
      "Epoch 62/75\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.0064 - accuracy: 0.9978\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.5360 - accuracy: 0.7361Epoch 21/75\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.0102 - accuracy: 1.0000\n",
      "12/14 [========================>.....] - ETA: 0s - loss: 0.2833 - accuracy: 0.9089Epoch 54/75\n",
      "14/14 [============================= - 2s 45ms/step - loss: 1.5503 - accuracy: 0.3683\n",
      "11/14 [======================>.......] - ETA: 0s - loss: 0.1802 - accuracy: 0.9205Epoch 2/75\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.2777 - accuracy: 0.9085\n",
      "Epoch 49/75\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.3033 - accuracy: 0.8817\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.1788 - accuracy: 0.9207Epoch 44/75\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.1709 - accuracy: 0.9241\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 1.4866 - accuracy: 0.3750Epoch 61/75\n",
      "14/14 [==============================] - 1s 36ms/step - loss: 0.5373 - accuracy: 0.7545\n",
      "Epoch 63/75\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 1.4338 - accuracy: 0.3795A: 0s - loss: 0.0047 - accuracy: 1.00TA: 0s - loss: 1.4626 - accuracy: 0.37\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.3296 - accuracy: 0.9028Epoch 3/75\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.0099 - accuracy: 1.0000\n",
      "Epoch 55/75\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.1610 - accuracy: 0.9479 - 1s 40ms/step - loss: 0.0045 - accuracy: 1.0000\n",
      "Epoch 22/75\n",
      "14/14 [==============================] - 1s 35ms/step - loss: 0.3405 - accuracy: 0.8728 [================>.............] - ETA: 0s - loss: 0.5227 - accuracy: 0.75\n",
      "Epoch 1/75\n",
      "Epoch 45/75\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.1753 - accuracy: 0.9286\n",
      "Epoch 62/75\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 0.1749 - accuracy: 0.9442- loss: 1.3214 - accuracy: 0.4500 - ETA: 0s - loss: 0.1159 - accuracy: 0.93\n",
      "Epoch 50/75\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.5458 - accuracy: 0.7545\n",
      "Epoch 64/75\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0069 - accuracy: 1.0000\n",
      " 8/14 [================>.............] - ETA: 0s - loss: 0.1220 - accuracy: 0.9609Epoch 56/75\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.0032 - accuracy: 1.0000\n",
      "Epoch 23/75\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 1.2142 - accuracy: 0.4933\n",
      "Epoch 4/75\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.1621 - accuracy: 0.9241\n",
      "Epoch 63/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.3033 - accuracy: 0.8594\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.1296 - accuracy: 0.9598\n",
      "Epoch 46/75\n",
      "Epoch 51/75\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.5560 - accuracy: 0.7500\n",
      " 4/14 [=======>......................] - ETA: 0s - loss: 0.9794 - accuracy: 0.5547Epoch 65/75\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0169 - accuracy: 1.0000\n",
      "Epoch 57/75\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 9.7609e-04 - accuracy: 1.0000\n",
      "Epoch 24/75\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.8624 - accuracy: 0.5647\n",
      "Epoch 5/75\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.1186 - accuracy: 0.9509\n",
      "Epoch 52/75\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 0.5444 - accuracy: 0.7679- ETA: 0s - loss: 0.2147 - accuracy: 0.\n",
      "Epoch 66/75\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.1335 - accuracy: 0.9375\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.2232 - accuracy: 0.9129\n",
      "Epoch 64/75\n",
      "Epoch 47/75\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.0156 - accuracy: 0.9978 [========================>.....] - ETA: 0s - loss: 0.0177 - accuracy: 0.99\n",
      "Epoch 58/75\n",
      " 6/14 [===========>..................] - ETA: 0s - loss: 0.0933 - accuracy: 0.9688"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:30:39.301592: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 32ms/step - loss: 0.0014 - accuracy: 1.0000- loss: 0.7079 - accuracy: 0.6493 - ETA: 0s - loss: 0.1921 - accuracy: 0.91\n",
      " 6/14 [===========>..................] - ETA: 0s - loss: 0.0220 - accuracy: 1.0000Epoch 25/75\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.5429 - accuracy: 0.7522\n",
      "Epoch 67/75\n",
      "14/14 [==============================] - 0s 37ms/step - loss: 0.6529 - accuracy: 0.6897\n",
      "Epoch 6/75\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.0825 - accuracy: 0.9665\n",
      "Epoch 53/75\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.1657 - accuracy: 0.9219\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 1.5739 - accuracy: 0.3661Epoch 65/75\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.0155 - accuracy: 1.0000\n",
      "Epoch 59/75\n",
      "14/14 [==============================] - 1s 35ms/step - loss: 0.2120 - accuracy: 0.9219- ETA: 0s - loss: 0.0964 - accuracy: 0.9375\n",
      "Epoch 48/75\n",
      "14/14 [==============================] - 2s 38ms/step - loss: 1.5645 - accuracy: 0.3549\n",
      "Epoch 2/75\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 5.9794e-04 - accuracy: 1.0000\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.5839 - accuracy: 0.7452Epoch 26/75\n",
      "14/14 [==============================] - 0s 23ms/step - loss: 0.0093 - accuracy: 1.0000\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.5815 - accuracy: 0.7478\n",
      "Epoch 60/75\n",
      "Epoch 68/75\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.1208 - accuracy: 0.9397\n",
      "Epoch 66/75\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.3942 - accuracy: 0.8460\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.0989 - accuracy: 0.9591Epoch 7/75\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.0946 - accuracy: 0.9598\n",
      "Epoch 54/75\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.2448 - accuracy: 0.9397\n",
      "Epoch 49/75\n",
      "14/14 [==============================] - 0s 23ms/step - loss: 0.0096 - accuracy: 1.0000\n",
      "Epoch 61/75\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 4.7562e-04 - accuracy: 1.0000\n",
      "Epoch 27/75\n",
      "14/14 [==============================] - 0s 24ms/step - loss: 0.5611 - accuracy: 0.7790\n",
      "Epoch 69/75\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 1.4760 - accuracy: 0.3683- loss: 0.1581 - accuracy: 0.9205 - ETA: 0s - loss: 4.5104e-04 - accuracy: 1.00\n",
      "Epoch 3/75\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.1690 - accuracy: 0.9152\n",
      "Epoch 67/75\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.0931 - accuracy: 0.9464\n",
      "12/14 [========================>.....] - ETA: 0s - loss: 0.1867 - accuracy: 0.9818Epoch 55/75\n",
      "14/14 [==============================] - 0s 24ms/step - loss: 0.0489 - accuracy: 0.9911\n",
      "11/14 [======================>.......] - ETA: 0s - loss: 3.3451e-04 - accuracy: 1.0000Epoch 62/75\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.3044 - accuracy: 0.8973\n",
      "Epoch 8/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.1975 - accuracy: 0.9799\n",
      "Epoch 50/75\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.5428 - accuracy: 0.7455\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 3.3967e-04 - accuracy: 1.0000\n",
      "Epoch 70/75\n",
      "Epoch 28/75\n",
      "14/14 [==============================] - 0s 21ms/step - loss: 0.0582 - accuracy: 0.9799A: 0s - loss: 0.5650 - accuracy: 0.77\n",
      "Epoch 63/75\n",
      "14/14 [==============================] - 1s 36ms/step - loss: 1.2981 - accuracy: 0.4420\n",
      "Epoch 4/75\n",
      "14/14 [==============================] - 1s 36ms/step - loss: 0.1254 - accuracy: 0.9375\n",
      "Epoch 68/75\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.0906 - accuracy: 0.9665A: 0s - loss: 0.0393 - accuracy: 0.98\n",
      "Epoch 56/75\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0015 - accuracy: 1.0000 - 0s 32ms/step - loss: 0.2110 - accuracy: 0.9732\n",
      "Epoch 51/75\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.5862 - accuracy: 0.7522\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.0288 - accuracy: 0.9875Epoch 71/75\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 29/75\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.1672 - accuracy: 0.9621A: 0s - loss: 0.1726 - accuracy: 0.96\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 0.1243 - accuracy: 0.9375Epoch 9/75\n",
      "14/14 [==============================] - 0s 21ms/step - loss: 0.0268 - accuracy: 0.9911\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.2973 - accuracy: 0.8750Epoch 64/75\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.1517 - accuracy: 0.9152\n",
      "Epoch 69/75\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.9233 - accuracy: 0.5982A: 0s - loss: 0.0215 - accuracy: 0.99\n",
      "11/14 [======================>.......] - ETA: 0s - loss: 0.1234 - accuracy: 0.9375Epoch 5/75\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 0.5231 - accuracy: 0.7835\n",
      "11/14 [======================>.......] - ETA: 0s - loss: 0.2031 - accuracy: 0.9744Epoch 72/75\n",
      "14/14 [==============================] - 0s 22ms/step - loss: 0.0185 - accuracy: 0.9955A: 0s - loss: 0.0762 - accuracy: 0.9688\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.2011 - accuracy: 0.9688Epoch 65/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.1096 - accuracy: 0.9442\n",
      "Epoch 57/75\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "11/14 [======================>.......] - ETA: 0s - loss: 0.1983 - accuracy: 0.9148Epoch 30/75\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.2062 - accuracy: 0.9688\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.0104 - accuracy: 1.0000Epoch 52/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.1894 - accuracy: 0.9196- loss: 0.3398 - accuracy: 0.9062 - ETA: 0s - loss: 0.6113 - accuracy: 0.76\n",
      "Epoch 10/75\n",
      "10/14 [====================>.........] - 0s 19ms/step - loss: 0.0117 - accuracy: 0.9955A: 0s - loss: 0.0119 - accuracy: 0.990.\n",
      " - ETA: 0s - loss: 0.5639 - accuracy: 0.7937Epoch 66/75\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.1359 - accuracy: 0.9286\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.1011 - accuracy: 0.9514Epoch 70/75\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.5095 - accuracy: 0.7768\n",
      "Epoch 73/75\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.5318 - accuracy: 0.8170A: 0s - loss: 0.1830 - accuracy: 0.93\n",
      "Epoch 6/75\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.0083 - accuracy: 0.9955A: 0s - loss: 0.0083 - accuracy: 0.99\n",
      "Epoch 31/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.2215 - accuracy: 0.9509\n",
      "Epoch 53/75\n",
      "14/14 [==============================] - 0s 36ms/step - loss: 0.1048 - accuracy: 0.9509\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.2158 - accuracy: 0.9688Epoch 58/75\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.1759 - accuracy: 0.9353A: 0s - loss: 0.1493 - accuracy: 0.9286\n",
      "Epoch 11/75\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.0145 - accuracy: 0.9955A: 0s - loss: 0.5690 - accuracy: 0.75TA: 0s - loss: 0.0018 - accuracy: 1.0000  \n",
      "Epoch 67/75\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.5567 - accuracy: 0.7634- loss: 0.0156 - accuracy: 1.0000 - ETA: 0s - loss: 0.1500 - accuracy: 0.92\n",
      "Epoch 74/75\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.1512 - accuracy: 0.9241\n",
      "Epoch 71/75\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.0036 - accuracy: 1.0000\n",
      "Epoch 32/75\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.2730 - accuracy: 0.9263\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 0.4779 - accuracy: 0.8125Epoch 7/75\n",
      "14/14 [==============================] - 0s 21ms/step - loss: 0.0348 - accuracy: 0.9888\n",
      "Epoch 68/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.0849 - accuracy: 0.9598\n",
      "Epoch 59/75\n",
      "14/14 [==============================] - 0s 36ms/step - loss: 0.1979 - accuracy: 0.9621\n",
      "Epoch 54/75\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.1419 - accuracy: 0.9420\n",
      " 6/14 [===========>..................] - ETA: 0s - loss: 0.0068 - accuracy: 1.0000Epoch 12/75\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.5259 - accuracy: 0.7790\n",
      "Epoch 75/75\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.1430 - accuracy: 0.9375- loss: 0.2007 - accuracy: 0.9563 - ETA: 0s - loss: 0.1441 - accuracy: 0.93\n",
      "Epoch 72/75\n",
      "14/14 [==============================] - 0s 22ms/step - loss: 0.0294 - accuracy: 0.9888\n",
      "Epoch 69/75\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.0039 - accuracy: 1.0000\n",
      "Epoch 33/75\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.2119 - accuracy: 0.9219\n",
      "Epoch 8/75\n",
      "13/14 [==========================>...] - 0s 35ms/step - loss: 0.0981 - accuracy: 0.9688\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 0.0051 - accuracy: 1.0000Epoch 60/75\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 0.5500 - accuracy: 0.7634\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.2178 - accuracy: 0.9509\n",
      "14/14 [==============================] - 0s 21ms/step - loss: 0.0120 - accuracy: 0.9911A: 0s - loss: 0.1596 - accuracy: 0.94\n",
      "Epoch 70/75\n",
      "Epoch 55/75\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.0844 - accuracy: 0.9576\n",
      "Epoch 13/75\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.1115 - accuracy: 0.9442\n",
      " 4/14 [=======>......................] - ETA: 0s - loss: 0.0055 - accuracy: 1.0000Epoch 73/75\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.0047 - accuracy: 1.0000\n",
      "Epoch 34/75\n",
      "14/14 [==============================] - 0s 20ms/step - loss: 0.0173 - accuracy: 0.9978\n",
      "Epoch 71/75\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.1162 - accuracy: 0.9732A: 0s - loss: 0.0900 - accuracy: 0.96\n",
      "Epoch 9/75\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.0946 - accuracy: 0.9688\n",
      "Epoch 61/75\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.1191 - accuracy: 0.9464\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.2402 - accuracy: 0.9576\n",
      "Epoch 74/75\n",
      "Epoch 56/75\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.1065 - accuracy: 0.9598\n",
      "Epoch 14/75\n",
      "14/14 [==============================] - 0s 20ms/step - loss: 0.0158 - accuracy: 0.9978\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 7.2103e-04 - accuracy: 1.0000\n",
      "Epoch 72/75\n",
      "Epoch 35/75\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 0.1571 - accuracy: 0.9167"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:30:43.693478: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 29ms/step - loss: 0.2465 - accuracy: 0.9554\n",
      "[CV 3/5] END ...epochs=75, layers=3, neurons=20;, score=0.955 total time=  33.9s\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.1029 - accuracy: 0.9554\n",
      "Epoch 62/75\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.1124 - accuracy: 0.9397- loss: 0.1258 - accuracy: 0.9375 - ETA: 0s - loss: 0.0490 - accuracy: 0.98\n",
      "Epoch 75/75\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.0493 - accuracy: 0.9888\n",
      "Epoch 10/75\n",
      "14/14 [==============================] - 0s 22ms/step - loss: 0.0130 - accuracy: 1.0000\n",
      "Epoch 73/75\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.6264 - accuracy: 0.7790A: 0s - loss: 0.1161 - accuracy: 0.9432\n",
      "Epoch 57/75\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 5.0045e-04 - accuracy: 1.0000\n",
      " 5/14 [=========>....................] - ETA: 0s - loss: 0.0793 - accuracy: 0.9750Epoch 36/75\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.1035 - accuracy: 0.9509\n",
      " 6/14 [===========>..................] - ETA: 0s - loss: 0.1930 - accuracy: 0.9062Epoch 15/75\n",
      "14/14 [==============================] - 0s 19ms/step - loss: 0.0069 - accuracy: 0.9978A: 0s - loss: 0.0069 - accuracy: 0.99\n",
      "Epoch 74/75\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.1758 - accuracy: 0.9174- loss: 0.5407 - accuracy: 0.8047 - ETA: 0s - loss: 8.7188e-04 - accuracy: 1.00\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.0831 - accuracy: 0.9643\n",
      "Epoch 63/75\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 6.9538e-04 - accuracy: 1.0000\n",
      " - ETA: 0s - loss: 0.0802 - accuracy: 0.9688 9/14 [==================>...........] - ETA: 0s - loss: 0.0086 - accuracy: 1.0000Epoch 37/75\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.0345 - accuracy: 0.9888\n",
      "Epoch 11/75\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.4993 - accuracy: 0.8013\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.0791 - accuracy: 0.9712Epoch 58/75\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.0779 - accuracy: 0.9710\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 6.1782e-04 - accuracy: 1.0000Epoch 16/75\n",
      "14/14 [==============================] - 0s 23ms/step - loss: 0.0081 - accuracy: 1.0000\n",
      "Epoch 75/75\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.0891 - accuracy: 0.9531\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.0217 - accuracy: 1.0000Epoch 64/75\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 3.7222e-04 - accuracy: 1.0000\n",
      "Epoch 38/75\n",
      "14/14 [==============================] - 0s 22ms/step - loss: 0.0097 - accuracy: 1.0000\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0194 - accuracy: 1.0000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1969 - accuracy: 0.9792Epoch 12/75\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.3692 - accuracy: 0.8036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:30:44.901878: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/75\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.2266 - accuracy: 0.9732\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.3221 - accuracy: 0.8750[CV 2/5] END ...epochs=75, layers=3, neurons=20;, score=0.973 total time=  38.4s\n",
      " 5/14 [=========>....................] - ETA: 0s - loss: 0.0307 - accuracy: 0.9938Epoch 1/75\n",
      "14/14 [==============================] - 1s 36ms/step - loss: 0.0701 - accuracy: 0.9732\n",
      "Epoch 17/75\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.1004 - accuracy: 0.9487\n",
      "Epoch 65/75\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 2.6230e-04 - accuracy: 1.0000\n",
      "Epoch 39/75\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.3061 - accuracy: 0.8594\n",
      "Epoch 60/75\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.0214 - accuracy: 0.9955\n",
      "Epoch 13/75\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0601 - accuracy: 0.9777\n",
      "Epoch 18/75\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 3.4437e-05 - accuracy: 1.0000\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.0960 - accuracy: 0.9665\n",
      "[CV 1/5] END ...epochs=75, layers=3, neurons=40;, score=1.000 total time=  28.6s\n",
      "Epoch 66/75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:30:45.527627: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 26ms/step - loss: 1.5781e-04 - accuracy: 1.0000\n",
      "Epoch 40/75\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.2927 - accuracy: 0.8571\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 0.0553 - accuracy: 0.9777Epoch 61/75\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.4368 - accuracy: 0.6562"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:30:45.830473: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 32ms/step - loss: 0.0140 - accuracy: 0.9978- loss: 0.0140 - accuracy: 0.9978 - ETA: 0s - loss: 0.0634 - accuracy: 0.97\n",
      "Epoch 14/75\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.0662 - accuracy: 0.9799\n",
      "Epoch 19/75\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.0970 - accuracy: 0.9509\n",
      "Epoch 67/75\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0477 - accuracy: 0.9792 - 0s 33ms/step - loss: 1.4650e-04 - accuracy: 1.0000\n",
      "Epoch 41/75\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 6.6485e-04 - accuracy: 1.0000Epoch 1/75\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.2732 - accuracy: 0.8750\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 1.5599 - accuracy: 0.3250Epoch 62/75\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.0099 - accuracy: 1.0000\n",
      "Epoch 15/75\n",
      "14/14 [==============================] - 1s 35ms/step - loss: 1.5423 - accuracy: 0.3438\n",
      "12/14 [========================>.....] - ETA: 0s - loss: 0.0821 - accuracy: 0.9740Epoch 2/75\n",
      "14/14 [==============================] 7/14 [==============>...............] - 0s 33ms/step - loss: 0.0926 - accuracy: 0.9710\n",
      " - ETA: 0s - loss: 0.3472 - accuracy: 0.8661Epoch 68/75\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.0289 - accuracy: 0.9866\n",
      "Epoch 20/75\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 2.9656e-04 - accuracy: 1.0000\n",
      "Epoch 42/75\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.3145 - accuracy: 0.8846"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:30:46.559871: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 33ms/step - loss: 0.3038 - accuracy: 0.8862\n",
      "Epoch 63/75\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.3211 - accuracy: 0.9062Epoch 1/75\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.0581 - accuracy: 0.9799A: 0s - loss: 3.1317e-04 - accuracy: 1.0000\n",
      "Epoch 16/75\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 1.4448 - accuracy: 0.3862\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.0087 - accuracy: 1.0000 3/14 [=====>........................]Epoch 3/75\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.0972 - accuracy: 0.9598\n",
      "Epoch 69/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.0386 - accuracy: 0.9799\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.2557 - accuracy: 0.8993Epoch 21/75\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 2.9524e-04 - accuracy: 1.0000\n",
      "Epoch 43/75\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 1.6487 - accuracy: 0.2625"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:30:47.116051: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 33ms/step - loss: 0.2734 - accuracy: 0.8839\n",
      "11/14 [======================>.......] - ETA: 0s - loss: 0.1265 - accuracy: 0.9460Epoch 64/75\n",
      "14/14 [==============================] - 0s 24ms/step - loss: 1.3113 - accuracy: 0.3862\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 0.0493 - accuracy: 0.9821Epoch 4/75\n",
      "14/14 [==============================] - 1s 35ms/step - loss: 1.6128 - accuracy: 0.2879\n",
      "Epoch 2/75\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.1272 - accuracy: 0.9442\n",
      "Epoch 17/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.0742 - accuracy: 0.9710\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 9.3574e-05 - accuracy: 1.0000Epoch 70/75\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.0404 - accuracy: 0.9821\n",
      "Epoch 22/75\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 1.3209e-04 - accuracy: 1.0000\n",
      "Epoch 44/75\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 1.0487 - accuracy: 0.3929\n",
      "11/14 [======================>.......] - ETA: 0s - loss: 0.2726 - accuracy: 0.8750Epoch 5/75\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 1.4173 - accuracy: 0.3996 [=========>....................] - ETA: 0s - loss: 0.0179 - accuracy: 0.99\n",
      "11/14 [======================>.......] - ETA: 0s - loss: 0.1125 - accuracy: 0.9517Epoch 3/75\n",
      "14/14 [==============================] - 1s 24ms/step - loss: 1.5582 - accuracy: 0.3125\n",
      "Epoch 2/75\n",
      "14/14 [==============================] 9/14 [==================>...........] - 1s 36ms/step - loss: 0.2642 - accuracy: 0.8862\n",
      " - ETA: 0s - loss: 0.0634 - accuracy: 0.9792Epoch 65/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.1122 - accuracy: 0.9554\n",
      " 6/14 [===========>..................] - ETA: 0s - loss: 0.8364 - accuracy: 0.5573Epoch 18/75\n",
      "14/14 [==============================] - 1s 36ms/step - loss: 0.0841 - accuracy: 0.9665\n",
      "Epoch 71/75\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 1.0861e-04 - accuracy: 1.0000\n",
      "Epoch 45/75\n",
      "14/14 [==============================] - 0s 19ms/step - loss: 1.3787 - accuracy: 0.4308\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 0.2660 - accuracy: 0.8884Epoch 3/75\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.7354 - accuracy: 0.6317 [=>............................] - ETA: 0s - loss: 1.0677 - accuracy: 0.62\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.2565 - accuracy: 0.8993Epoch 6/75\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.0310 - accuracy: 0.9799\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 1.4086e-04 - accuracy: 1.0000Epoch 23/75\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 1.0754 - accuracy: 0.5960\n",
      "Epoch 4/75\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.2485 - accuracy: 0.9107\n",
      "Epoch 66/75\n",
      "14/14 [==============================] - 0s 22ms/step - loss: 1.0530 - accuracy: 0.5580\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 0.6735 - accuracy: 0.7679Epoch 4/75\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.0857 - accuracy: 0.9643\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.2391 - accuracy: 0.9167 - ETA: 0s - loss: 0.9389 - accuracy: 0.5625Epoch 19/75\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 1.3026e-04 - accuracy: 1.0000\n",
      "Epoch 46/75\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.0840 - accuracy: 0.9688\n",
      "Epoch 72/75\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.5129 - accuracy: 0.7969\n",
      "Epoch 7/75\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.5502 - accuracy: 0.8170\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.7293 - accuracy: 0.7188Epoch 5/75\n",
      "14/14 [==============================] - 1s 36ms/step - loss: 0.0523 - accuracy: 0.9799\n",
      "Epoch 24/75\n",
      "14/14 [==============================] - 0s 23ms/step - loss: 0.6344 - accuracy: 0.7679\n",
      "Epoch 5/75\n",
      "14/14 [==============================] - 1s 36ms/step - loss: 0.2599 - accuracy: 0.9040A: 0s - loss: 4.2697e-05 - accuracy: 1.00\n",
      "11/14 [======================>.......]Epoch 67/75- loss: 0.0418 - accuracy: 0.99\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.0389 - accuracy: 0.9911\n",
      "11/14 [======================>.......] - ETA: 0s - loss: 0.0782 - accuracy: 0.9602Epoch 20/75\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 0.3089 - accuracy: 0.8795\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 5.8454e-05 - accuracy: 1.0000\n",
      "Epoch 8/75\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 0.2626 - accuracy: 0.8854Epoch 47/75\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.0813 - accuracy: 0.9576\n",
      "Epoch 73/75\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.2735 - accuracy: 0.9196\n",
      "Epoch 6/75\n",
      "14/14 [==============================] - 0s 22ms/step - loss: 0.3545 - accuracy: 0.9040\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.1678 - accuracy: 0.9688Epoch 6/75\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.0695 - accuracy: 0.9732\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.2711 - accuracy: 0.8889Epoch 25/75\n",
      " - ETA: 0s - loss: 0.0911 - accuracy: 0.956314/14 [==============================] - 0s 35ms/step - loss: 0.2793 - accuracy: 0.8951\n",
      "Epoch 68/75\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.2715 - accuracy: 0.8862\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 6.5914e-05 - accuracy: 1.0000\n",
      "Epoch 48/75\n",
      "Epoch 9/75\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 0.2032 - accuracy: 0.9442\n",
      "Epoch 7/75\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.0313 - accuracy: 0.9933A: 0s - loss: 5.8398e-05 - accuracy: 1.00\n",
      " - ETA: 0s - loss: 0.2590 - accuracy: 0.8750Epoch 21/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.1204 - accuracy: 0.9732\n",
      " 5/14 [=========>....................] - ETA: 0s - loss: 0.2520 - accuracy: 0.9125Epoch 7/75\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.0757 - accuracy: 0.9643\n",
      "Epoch 74/75\n",
      "14/14 [==============================]11/14 [======================>.......] - 1s 37ms/step - loss: 0.0689 - accuracy: 0.9643\n",
      " - ETA: 0s - loss: 1.1672e-04 - accuracy: 1.0000Epoch 26/75\n",
      "14/14 [==============================] - 0s 18ms/step - loss: 0.1702 - accuracy: 0.9330\n",
      " 6/14 [===========>..................] - ETA: 0s - loss: 0.0709 - accuracy: 0.9844Epoch 8/75\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.2533 - accuracy: 0.8884\n",
      "Epoch 10/75\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 9.9911e-05 - accuracy: 1.0000\n",
      "Epoch 49/75\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.2435 - accuracy: 0.9085\n",
      "Epoch 69/75\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.0645 - accuracy: 0.9799\n",
      "Epoch 8/75\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.0092 - accuracy: 1.0000\n",
      "Epoch 22/75\n",
      "14/14 [==============================] - 0s 21ms/step - loss: 0.1112 - accuracy: 0.9665\n",
      "Epoch 9/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.0781 - accuracy: 0.9710\n",
      "Epoch 75/75\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.2598 - accuracy: 0.8996\n",
      "Epoch 11/75\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.0469 - accuracy: 0.9866\n",
      "Epoch 27/75\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 9.8719e-05 - accuracy: 1.0000\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 0.1883 - accuracy: 0.9583Epoch 50/75\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.2404 - accuracy: 0.9085\n",
      "Epoch 70/75\n",
      "14/14 [==============================] - 0s 22ms/step - loss: 0.0812 - accuracy: 0.9710\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.0479 - accuracy: 0.9856Epoch 10/75\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.0562 - accuracy: 0.9821\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 0.0622 - accuracy: 0.9732Epoch 9/75\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.0066 - accuracy: 1.0000\n",
      "Epoch 23/75\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.2192 - accuracy: 0.9464 [==========================>...] - ETA: 0s - loss: 0.2250 - accuracy: 0.94\n",
      " 6/14 [===========>..................] - ETA: 0s - loss: 0.2878 - accuracy: 0.8750Epoch 12/75\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.0844 - accuracy: 0.9665\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 1.7688e-04 - accuracy: 1.0000\n",
      "Epoch 51/75\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.1060 - accuracy: 0.9609 - 1s 39ms/step - loss: 0.0473 - accuracy: 0.9799\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.0359 - accuracy: 0.9965Epoch 28/75\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.0967 - accuracy: 0.9643\n",
      "Epoch 11/75\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0116 - accuracy: 0.9943 - 1s 39ms/step - loss: 0.2605 - accuracy: 0.8862\n",
      "Epoch 71/75\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.0439 - accuracy: 0.9888\n",
      "Epoch 10/75\n",
      "14/14 [==============================] - 1s 34ms/step - loss: 0.0097 - accuracy: 0.9955\n",
      "Epoch 24/75\n",
      "14/14 [==============================] - 1s 35ms/step - loss: 0.2333 - accuracy: 0.9420\n",
      "Epoch 13/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 3.8264e-04 - accuracy: 1.0000ss: 0.2395 - accuracy: 0.9062 - ETA: 0s - loss: 0.0351 - accuracy: 0.98\n",
      "Epoch 52/75\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0435 - accuracy: 0.9844\n",
      "Epoch 12/75\n",
      "14/14 [==============================] - 0s 36ms/step - loss: 0.0352 - accuracy: 0.9821\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 1.1065e-04 - accuracy: 1.0000Epoch 29/75\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.0400 - accuracy: 0.9844\n",
      "Epoch 11/75\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.2344 - accuracy: 0.8951\n",
      " 6/14 [===========>..................] - ETA: 0s - loss: 0.2049 - accuracy: 0.9479Epoch 72/75\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.0216 - accuracy: 0.9911- loss: 0.0228 - accuracy: 0.9904 - ETA: 0s - loss: 0.0460 - accuracy: 0.9955 - ETA: 0s - loss: 0.1898 - accuracy: 0.95\n",
      "Epoch 25/75\n",
      "14/14 [==============================] - 1s 44ms/step - loss: 0.1923 - accuracy: 0.9598 [========================>.....] - ETA: 0s - loss: 0.0472 - accuracy: 0.97\n",
      "Epoch 14/75\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 1.2727e-04 - accuracy: 1.0000\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.1943 - accuracy: 0.9062Epoch 53/75\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.0487 - accuracy: 0.9777\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.0566 - accuracy: 0.9808Epoch 13/75\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.0538 - accuracy: 0.9821\n",
      " 6/14 [===========>..................] - ETA: 0s - loss: 0.0751 - accuracy: 0.9688Epoch 30/75\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.0254 - accuracy: 0.9933\n",
      " 8/14 [================>.............] - ETA: 0s - loss: 0.0740 - accuracy: 0.9727Epoch 12/75\n",
      "14/14 [==============================] - 1s 44ms/step - loss: 0.2054 - accuracy: 0.8996\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.0705 - accuracy: 0.9719Epoch 73/75\n",
      "14/14 [==============================] - 1s 44ms/step - loss: 0.0776 - accuracy: 0.9643\n",
      "Epoch 26/75\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0701 - accuracy: 0.9732\n",
      "Epoch 14/75\n",
      "14/14 [==============================] - 0s 37ms/step - loss: 0.2192 - accuracy: 0.9420\n",
      "Epoch 15/75\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 3.0017e-04 - accuracy: 1.0000\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.0332 - accuracy: 0.9799\n",
      "Epoch 54/75\n",
      "Epoch 31/75\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.0408 - accuracy: 0.98960000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:30:51.970259: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 42ms/step - loss: 0.0127 - accuracy: 1.0000A: 0s - loss: 0.0348 - accuracy: 0.99\n",
      "[CV 4/5] END ...epochs=75, layers=3, neurons=20;, score=1.000 total time=  39.1s\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.0318 - accuracy: 0.9911\n",
      "Epoch 13/75\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.1950 - accuracy: 0.8973\n",
      "Epoch 74/75\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 0.0283 - accuracy: 0.9911\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 1.9771e-04 - accuracy: 1.0000Epoch 15/75\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.1925 - accuracy: 0.9531\n",
      "12/14 [========================>.....] - ETA: 0s - loss: 2.0561e-04 - accuracy: 1.0000Epoch 16/75\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 1.9270e-04 - accuracy: 1.0000\n",
      " 7/14 [==============>...............]13/14 [==========================>...] - ETA: 0s - loss: 0.0133 - accuracy: 1.0000 - ETA: 0s - loss: 0.0319 - accuracy: 0.9904Epoch 55/75\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 0.0318 - accuracy: 0.9911A: 0s - loss: 1.1035e-04 - accuracy: 1.00\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 0.1399 - accuracy: 0.9583Epoch 27/75\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.0223 - accuracy: 0.9911\n",
      "Epoch 32/75\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0134 - accuracy: 1.0000- loss: 0.0029 - accuracy: 1.0000 - ETA: 0s - loss: 0.0017 - accuracy: 1.00\n",
      " 6/14 [===========>..................] - ETA: 0s - loss: 6.3669e-05 - accuracy: 1.0000Epoch 14/75\n",
      "14/14 [==============================] - 0s 23ms/step - loss: 0.0265 - accuracy: 0.9911\n",
      "Epoch 16/75\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.1801 - accuracy: 0.9040\n",
      "Epoch 75/75\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.1672 - accuracy: 0.9732\n",
      "Epoch 17/75\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 8.8573e-05 - accuracy: 1.0000ss: 0.2234 - accuracy: 0.8854 - ETA: 0s - loss: 0.0040 - accuracy: 1.0000\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.0220 - accuracy: 0.9933\n",
      "Epoch 56/75\n",
      "Epoch 33/75\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.0611 - accuracy: 0.9754\n",
      "11/14 [======================>.......] - ETA: 0s - loss: 0.0041 - accuracy: 1.0000Epoch 28/75\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.0034 - accuracy: 1.0000\n",
      "Epoch 15/75\n",
      "14/14 [==============================] - 1s 36ms/step - loss: 0.0426 - accuracy: 0.9821\n",
      "Epoch 17/75\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.1776 - accuracy: 0.9085\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.1609 - accuracy: 0.9665\n",
      "Epoch 18/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.0216 - accuracy: 0.9866A: 0s - loss: 6.5017e-05 - accuracy: 1.0000 - ETA: 0s - loss: 0.0016 - accuracy: 1.\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 6.0657e-05 - accuracy: 1.0000Epoch 34/75\n",
      "14/14 [==============================] - 1s 36ms/step - loss: 5.8633e-05 - accuracy: 1.0000\n",
      "Epoch 57/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.1152 - accuracy: 0.9598\n",
      "Epoch 29/75\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.1770 - accuracy: 0.9621\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.0214 - accuracy: 0.9911\n",
      "Epoch 19/75\n",
      "Epoch 18/75\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 16/75\n",
      " 4/14 [=======>......................] - ETA: 0s - loss: 0.0869 - accuracy: 0.9609Epoch 1/75\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.0231 - accuracy: 0.9821A: 0s - loss: 0.0238 - accuracy: 0.98\n",
      "Epoch 35/75\n",
      "14/14 [==============================] - 0s 37ms/step - loss: 8.0722e-05 - accuracy: 1.0000\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.0533 - accuracy: 0.9792Epoch 58/75\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 2.6953e-05 - accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:30:53.899431: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [============================= - 1s 39ms/step - loss: 0.0396 - accuracy: 0.9866\n",
      " 4/14 [=======>......................] - ETA: 0s - loss: 0.0104 - accuracy: 0.9922Epoch 30/75\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.0200 - accuracy: 0.9911\n",
      "Epoch 17/75\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.0373 - accuracy: 0.9866\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 0.0397 - accuracy: 0.9896Epoch 19/\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.1648 - accuracy: 0.9621\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.0115 - accuracy: 1.0000Epoch 20/75\n",
      "4/4 [==============================] - 1s 57ms/step - loss: 0.2917 - accuracy: 0.8304\n",
      "[CV 5/5] END ...epochs=75, layers=3, neurons=20;, score=0.830 total time=  38.4s\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.0155 - accuracy: 0.9978\n",
      "Epoch 36/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 1.0001e-04 - accuracy: 1.0000\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.0438 - accuracy: 0.9688Epoch 59/75\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.0272 - accuracy: 0.9911- loss: 0.1672 - accuracy: 0.9653 - ETA: 0s - loss: 0.0930 - accuracy: 0.95\n",
      "Epoch 31/75\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.0248 - accuracy: 0.9933\n",
      "Epoch 20/75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:30:54.538881: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 35ms/step - loss: 0.1451 - accuracy: 0.9732\n",
      "Epoch 21/75\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.0779 - accuracy: 0.9621\n",
      "Epoch 18/75\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 6.1241e-05 - accuracy: 1.0000ss: 0.1189 - accuracy: 0.9688 - ETA: 0s - loss: 7.3065e-05 - accuracy: 1.\n",
      "Epoch 60/75\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.0168 - accuracy: 0.9933\n",
      "Epoch 37/75\n",
      "14/14 [==============================] - 0s 22ms/step - loss: 0.0805 - accuracy: 0.9754\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 1.6833 - accuracy: 0.2604Epoch 21/75\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0073 - accuracy: 1.0000\n",
      "Epoch 32/75\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.0433 - accuracy: 0.9866A: 0s - loss: 0.0253 - accuracy: 0.99\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.2695 - accuracy: 0.9263\n",
      "Epoch 19/75\n",
      "Epoch 22/75\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.0199 - accuracy: 0.9978\n",
      "Epoch 22/75\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.0097 - accuracy: 1.0000\n",
      "Epoch 38/75\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 8.2113e-05 - accuracy: 1.0000\n",
      "Epoch 61/75\n",
      "14/14 [==============================] - 2s 47ms/step - loss: 1.5637 - accuracy: 0.3482\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.0061 - accuracy: 0.9978\n",
      "Epoch 33/75\n",
      "Epoch 2/75\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.3905 - accuracy: 0.8795\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 0.0299 - accuracy: 0.9955Epoch 23/75\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0297 - accuracy: 0.9933\n",
      "Epoch 20/75\n",
      " 5/14 [=========>....................] - ETA: 0s - loss: 1.4453 - accuracy: 0.3812Epoch 1/75\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.0287 - accuracy: 0.9911\n",
      "Epoch 23/75\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 5.8642e-05 - accuracy: 1.0000ss: 0.0204 - accuracy: 0.9896 - ETA: 0s - loss: 0.0097 - accuracy: 0.99\n",
      "Epoch 62/75\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.0120 - accuracy: 0.9955- loss: 5.8688e-05 - accuracy: 1.0000 - ETA: 0s - loss: 0.0206 - accuracy: 0.98\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.0168 - accuracy: 0.9906Epoch 39/75\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.0163 - accuracy: 0.9933\n",
      "12/14 [========================>.....] - ETA: 0s - loss: 0.3850 - accuracy: 0.8568Epoch 34/75\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 1.3382 - accuracy: 0.4219\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.0013 - accuracy: 1.0000Epoch 3/75\n",
      "14/14 [==============================] - 0s 24ms/step - loss: 0.3776 - accuracy: 0.8594\n",
      "Epoch 24/75\n",
      " 7/14 [==============>...............] - 0s 28ms/step - loss: 0.0155 - accuracy: 0.9911\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 0.0580 - accuracy: 0.9792Epoch 21/75\n",
      " 3/14 [=====>........................] - 0s 23ms/step - loss: 0.2664 - accuracy: 0.9241\n",
      " - ETA: 0s - loss: 0.3949 - accuracy: 0.8333Epoch 24/75\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 0.0343 - accuracy: 0.986600"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:30:55.979448: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 34ms/step - loss: 7.4193e-05 - accuracy: 1.0000\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.3388 - accuracy: 0.8576Epoch 63/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.0410 - accuracy: 0.9844\n",
      "Epoch 40/75\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.3084 - accuracy: 0.8750\n",
      "Epoch 25/75\n",
      "14/14 [==============================] - 0s 36ms/step - loss: 0.0199 - accuracy: 0.9911\n",
      "Epoch 35/75\n",
      "14/14 [==============================] - 0s 36ms/step - loss: 0.9384 - accuracy: 0.6049\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0087 - accuracy: 0.9978\n",
      " 4/14 [=======>......................]Epoch 4/75\n",
      " - ETA: 0s - loss: 1.6371 - accuracy: 0.2109Epoch 22/75\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 0.3732 - accuracy: 0.8862\n",
      " 5/14 [=========>....................] - ETA: 0s - loss: 1.4218e-04 - accuracy: 1.0000Epoch 25/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 1.0558e-04 - accuracy: 1.0000s - loss: 0.0244 - accuracy: 0.\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.0262 - accuracy: 0.9931Epoch 64/75\n",
      "14/14 [==============================] - 0s 24ms/step - loss: 0.0841 - accuracy: 0.9665\n",
      "Epoch 26/75\n",
      "14/14 [==============================] - ETA: 0s - loss: 1.5548 - accuracy: 0.3210 - 0s 31ms/step - loss: 0.2753 - accuracy: 0.8906\n",
      "Epoch 26/75\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0061 - accuracy: 1.0000\n",
      "Epoch 23/75\n",
      "14/14 [==============================] - 1s 36ms/step - loss: 0.0061 - accuracy: 0.9978\n",
      "Epoch 36/75\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.0232 - accuracy: 0.9955\n",
      "14/14 [==============================]Epoch 41/75\n",
      "14/14 [==============================] - 1s 52ms/step - loss: 1.5446 - accuracy: 0.3304\n",
      "Epoch 2/75\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.4104 - accuracy: 0.8795\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 4.4607e-05 - accuracy: 1.0000Epoch 5/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 5.3731e-05 - accuracy: 1.0000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0348 - accuracy: 0.9933\n",
      "Epoch 65/75\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 0.0154 - accuracy: 0.9955Epoch 27/75\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.0026 - accuracy: 1.0000- loss: 0.0026 - accuracy: 1.0000 - ETA: 0s - loss: 0.1854 - accuracy: 0.94\n",
      "Epoch 24/75\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.2521 - accuracy: 0.8951A: 0s - loss: 2.5806e-04 - accuracy: 1.00\n",
      "Epoch 27/75\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 1.4206 - accuracy: 0.3929\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.1756 - accuracy: 0.9447Epoch 3/75\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.0058 - accuracy: 0.9978\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.0168 - accuracy: 0.9952Epoch 37/75\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.1681 - accuracy: 0.9464\n",
      "Epoch 6/75\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.0157 - accuracy: 0.9955\n",
      "Epoch 42/75\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0390 - accuracy: 0.9866\n",
      "Epoch 28/75\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 7.3183e-04 - accuracy: 1.0000\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.0069 - accuracy: 1.0000Epoch 66/75\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "12/14 [========================>.....] - ETA: 0s - loss: 0.2508 - accuracy: 0.9036Epoch 25/75\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.2423 - accuracy: 0.9040\n",
      "Epoch 28/75\n",
      "14/14 [==============================] - 1s 35ms/step - loss: 1.0910 - accuracy: 0.6071A: 0s - loss: 0.0292 - accuracy: 0.98\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.0013 - accuracy: 1.0000Epoch 4/75\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.0707 - accuracy: 0.9866\n",
      "14/14 [==============================] - 0s 23ms/step - loss: 0.0257 - accuracy: 0.9888\n",
      "Epoch 7/75\n",
      "14/14 [==============================] - 0s 36ms/step - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 38/75\n",
      "Epoch 29/75\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.0371 - accuracy: 0.9911\n",
      "Epoch 43/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 67/75\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 9.0435e-04 - accuracy: 1.0000ss: 9.0435e-04 - accuracy: 1.0000 - ETA: 0s - loss: 0.0024 - accuracy: 1.00\n",
      "Epoch 26/75\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.2365 - accuracy: 0.8996\n",
      "Epoch 29/75\n",
      "14/14 [==============================] - 0s 22ms/step - loss: 0.0127 - accuracy: 0.9978\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.0371 - accuracy: 0.9896Epoch 30/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.0209 - accuracy: 0.9911\n",
      "Epoch 44/75\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.0370 - accuracy: 0.9888\n",
      "Epoch 8/75=====================>.....] - ETA: 0s - loss: 0.6317 - accuracy: 0.77\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 39/75\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.5898 - accuracy: 0.8036A: 0s - loss: 1.8109e-04 - accuracy: 1.00\n",
      "Epoch 5/75\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.0015 - accuracy: 1.0000A: 0s - loss: 0.3375 - accuracy: 0.96\n",
      "Epoch 27/75\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 2.5675e-04 - accuracy: 1.0000\n",
      "Epoch 68/75\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.2179 - accuracy: 0.9063\n",
      "Epoch 30/75\n",
      "14/14 [==============================] - 0s 23ms/step - loss: 0.0387 - accuracy: 0.9911\n",
      "Epoch 31/75\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.1577 - accuracy: 0.9420A: 0s - loss: 0.1577 - accuracy: 0.94\n",
      "Epoch 9/75\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.2296 - accuracy: 0.9420\n",
      "Epoch 6/75\n",
      "14/14 [==============================] - 0s 22ms/step - loss: 0.0466 - accuracy: 0.9799\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.1292 - accuracy: 0.9688\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 4.6338e-04 - accuracy: 1.0000\n",
      "Epoch 69/75\n",
      "Epoch 32/75\n",
      "Epoch 28/75\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.2556 - accuracy: 0.9040\n",
      "Epoch 31/75\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.0021 - accuracy: 1.0000\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.1526 - accuracy: 0.9688Epoch 40/75\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.0659 - accuracy: 0.9754\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.0053 - accuracy: 1.0000Epoch 45/75\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.1688 - accuracy: 0.9420- loss: 0.1130 - accuracy: 0.9688 - ETA: 0s - loss: 0.2307 - accuracy: 0.\n",
      "11/14 [======================>.......] - ETA: 0s - loss: 0.0667 - accuracy: 0.9744Epoch 10/75\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 0.0234 - accuracy: 0.9888\n",
      "Epoch 33/75\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.4681 - accuracy: 0.8772\n",
      "Epoch 70/75\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 2.3025e-04 - accuracy: 1.0000\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.2911 - accuracy: 0.8726Epoch 29/75\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.2829 - accuracy: 0.8728- loss: 5.7828e-05 - accuracy: 1.0000 - ETA: 0s - loss: 0.0958 - accuracy: 0.96\n",
      "Epoch 32/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.1123 - accuracy: 0.9688\n",
      "Epoch 7/75\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.0810 - accuracy: 0.9710\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 0.0419 - accuracy: 1.0000Epoch 46/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 41/75\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0257 - accuracy: 0.9866A: 0s - loss: 0.2712 - accuracy: 0.\n",
      "12/14 [========================>.....] - ETA: 0s - loss: 0.0614 - accuracy: 0.9766Epoch 34/75\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.0297 - accuracy: 0.9955\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.0612 - accuracy: 0.9875Epoch 11/75\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 2.4720e-04 - accuracy: 1.0000\n",
      "Epoch 30/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.0652 - accuracy: 0.9754\n",
      "Epoch 71/75\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.2278 - accuracy: 0.9040\n",
      "Epoch 33/75\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.0632 - accuracy: 0.9777A: 0s - loss: 0.0621 - accuracy: 0.97\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.0638 - accuracy: 0.9799\n",
      "Epoch 8/75\n",
      "Epoch 47/75\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 42/75\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 0.0291 - accuracy: 0.9888- loss: 0.0167 - accuracy: 0.9938 - ETA: 0s - loss: 0.0251 - accuracy: 0.9896\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.2391 - accuracy: 0.9062Epoch 35/75\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 0.2357 - accuracy: 0.9040A: 0s - loss: 0.0588 - accuracy: 0.97\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0029 - accuracy: 1.0000\n",
      "Epoch 31/75\n",
      "Epoch 34/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.0116 - accuracy: 0.9978\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.1998 - accuracy: 0.9375Epoch 12/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.0454 - accuracy: 0.9777\n",
      "Epoch 72/75\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.0655 - accuracy: 0.9821- loss: 0.0566 - accuracy: 0.9792 - ETA: 0s - loss: 0.0048 - accuracy: 1.00\n",
      "Epoch 9/75\n",
      "14/14 [==============================] - 0s 23ms/step - loss: 0.0122 - accuracy: 0.9978\n",
      "14/14 [==============================] - 1s 36ms/step - loss: 0.0602 - accuracy: 0.9799\n",
      "Epoch 36/75\n",
      " 5/14 [=========>....................] - ETA: 0s - loss: 0.0306 - accuracy: 0.9938Epoch 48/75\n",
      "14/14 [==============================] - 0s 36ms/step - loss: 8.3887e-04 - accuracy: 1.0000\n",
      "Epoch 43/75\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 0.2362 - accuracy: 0.8996ETA: 0s - loss: 0.0053 - accuracy: 1.00\n",
      "Epoch 35/75\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.0344 - accuracy: 0.9933\n",
      "Epoch 32/75\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.0279 - accuracy: 0.9911\n",
      "Epoch 73/75\n",
      "14/14 [==============================] - 0s 22ms/step - loss: 0.0309 - accuracy: 0.9866\n",
      "Epoch 37/75\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.0091 - accuracy: 0.9978\n",
      " 5/14 [=========>....................] - ETA: 0s - loss: 0.2532 - accuracy: 0.8562Epoch 13/75\n",
      " 6/14 [===========>..................] - 0s 34ms/step - loss: 0.0395 - accuracy: 0.9844- loss: 0.0415 - accuracy: 0.9818 - ETA: 0s - loss: 0.0042 - accuracy: 1.00\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.0855 - accuracy: 0.9710\n",
      "Epoch 49/75\n",
      "Epoch 10/75\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 7.1067e-04 - accuracy: 1.0000\n",
      "Epoch 44/75\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 0.0114 - accuracy: 0.9911 - 0s 28ms/step - loss: 0.2192 - accuracy: 0.9063\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 4.3212e-04 - accuracy: 1.0000Epoch 36/75\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.1394 - accuracy: 0.9442\n",
      "Epoch 33/75\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 0.0215 - accuracy: 0.9911\n",
      "Epoch 38/75\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0100 - accuracy: 0.9978\n",
      "Epoch 74/75\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.0100 - accuracy: 0.9955\n",
      " 4/14 [=======>......................] - ETA: 0s - loss: 0.1000 - accuracy: 0.9531Epoch 14/75\n",
      "14/14 [==============================] - 0s 24ms/step - loss: 0.2534 - accuracy: 0.8750\n",
      "Epoch 37/75\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.0176 - accuracy: 0.9978\n",
      "Epoch 11/75\n",
      "14/14 [==============================] - 0s 20ms/step - loss: 0.0414 - accuracy: 0.9821A: 0s - loss: 0.0414 - accuracy: 0.98\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.0398 - accuracy: 0.9844\n",
      "Epoch 39/75\n",
      "Epoch 50/75\n",
      "14/14 [==============================] - 1s 36ms/step - loss: 0.0014 - accuracy: 1.0000- loss: 0.1055 - accuracy: 0.9469 - ETA: 0s - loss: 0.0497 - accuracy: 0.\n",
      "Epoch 45/75\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0970 - accuracy: 0.9554\n",
      "Epoch 34/75\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.0075 - accuracy: 1.0000- ETA: 0s - loss: 0.0113 - accuracy: 0.9938 - ETA: 0s - loss: 0.0179 - accuracy: 0.9938\n",
      "Epoch 75/75\n",
      "14/14 [==============================] - 0s 21ms/step - loss: 0.0228 - accuracy: 0.9911\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.0150 - accuracy: 0.9911\n",
      "Epoch 40/75\n",
      "Epoch 15/75\n",
      "14/14 [==============================] - 0s 24ms/step - loss: 0.2070 - accuracy: 0.9129\n",
      "Epoch 38/75\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.0186 - accuracy: 0.9955- loss: 0.0035 - accuracy: 1.0000 - ETA: 0s - loss: 0.0039 - accuracy: 1.00\n",
      "Epoch 12/75\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.0623 - accuracy: 0.9688\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.0046 - accuracy: 1.0000Epoch 35/75\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.0199 - accuracy: 0.9955\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 0.0035 - accuracy: 1.0000Epoch 51/75\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.0010 - accuracy: 1.0000\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 0.0229 - accuracy: 0.9896Epoch 46/75\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.0033 - accuracy: 1.0000\n",
      "14/14 [==============================] - 0s 24ms/step - loss: 0.0194 - accuracy: 0.9933\n",
      "Epoch 41/75\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0058 - accuracy: 1.0000\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.1999 - accuracy: 0.9152\n",
      "Epoch 16/75\n",
      " 4/14 [=======>......................] - ETA: 0s - loss: 0.0459 - accuracy: 0.9766Epoch 39/75\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 0.0733 - accuracy: 0.9688- loss: 0.2165 - accuracy: 0.8958 - ETA: 0s - loss: 0.0164 - accuracy: 0.98\n",
      "Epoch 36/75\n",
      " 5/14 [=========>....................] - ETA: 0s - loss: 0.0101 - accuracy: 0.9938"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:31:02.093868: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0176 - accuracy: 0.9955\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.0284 - accuracy: 1.0000Epoch 13/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.0147 - accuracy: 0.9933- loss: 0.0821 - accuracy: 0.9792 - ETA: 0s - loss: 0.0088 - accuracy: 0.99\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 0.0278 - accuracy: 0.9888\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 0.0125 - accuracy: 1.0000Epoch 52/75\n",
      "Epoch 42/75\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0117 - accuracy: 0.9911\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 2.5540e-04 - accuracy: 1.0000\n",
      "Epoch 47/75\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.0086 - accuracy: 0.9955- ETA: 0s - loss: 0.0102 - accuracy: 1.00\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.2540 - accuracy: 0.8929\n",
      " 4/14 [=======>......................] - ETA: 0s - loss: 8.2683e-04 - accuracy: 1.0000Epoch 17/75\n",
      "Epoch 40/75\n",
      " 6/14 [===========>..................] - ETA: 0s - loss: 5.7529e-04 - accuracy: 1.0000[CV 2/5] END ...epochs=75, layers=3, neurons=40;, score=0.991 total time=  34.1s\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.0400 - accuracy: 0.9911\n",
      "Epoch 37/75\n",
      "14/14 [==============================] - 0s 20ms/step - loss: 0.0315 - accuracy: 0.9844\n",
      "Epoch 43/75\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.0102 - accuracy: 0.9978\n",
      " 8/14 [================>.............] - ETA: 0s - loss: 0.0030 - accuracy: 1.0000Epoch 14/75\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.0023 - accuracy: 1.0000- loss: 0.3535 - accuracy: 0.8568 - ETA: 0s - loss: 0.0428 - accuracy: 0.98\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 2.6232e-04 - accuracy: 1.0000Epoch 53/75\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 3.0588e-04 - accuracy: 1.0000\n",
      "Epoch 48/75\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.3481 - accuracy: 0.8571\n",
      "Epoch 41/75\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0031 - accuracy: 1.0000A: 0s - loss: 0.3723 - accuracy: 0.81\n",
      "Epoch 18/75\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.0817 - accuracy: 0.9665\n",
      "Epoch 38/75\n",
      "14/14 [==============================] - 0s 24ms/step - loss: 0.0291 - accuracy: 0.9911\n",
      "Epoch 44/75\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.0260 - accuracy: 0.9911\n",
      " 6/14 [===========>..................] - ETA: 0s - loss: 0.1145 - accuracy: 0.9583Epoch 15/75\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.2620 - accuracy: 0.8772\n",
      "Epoch 42/75\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.0095 - accuracy: 0.9955\n",
      "11/14 [======================>.......] - ETA: 0s - loss: 0.0853 - accuracy: 0.9659Epoch 54/75\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 3.5278e-04 - accuracy: 1.0000ss: 0.0119 - accuracy: 0.9952 - ETA: 0s - loss: 3.5278e-04 - accuracy: 1.00\n",
      "Epoch 49/75\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0141 - accuracy: 0.9955\n",
      "Epoch 19/75\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.0915 - accuracy: 0.9688\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.0053 - accuracy: 1.0000Epoch 39/75\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 0.0323 - accuracy: 0.9933\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 0.0014 - accuracy: 1.0000    Epoch 45/75\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.0250 - accuracy: 0.9933- loss: 0.0066 - accuracy: 0.9965 - ETA: 0s - loss: 0.2357 - accuracy: 0.90\n",
      "Epoch 16/75\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.2294 - accuracy: 0.9085\n",
      "Epoch 43/75\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.0238 - accuracy: 0.9931Epoch 1/75\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.0064 - accuracy: 0.9978\n",
      "12/14 [========================>.....] - ETA: 0s - loss: 0.0786 - accuracy: 0.9818Epoch 55/75\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0176 - accuracy: 0.9933\n",
      "Epoch 20/75\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0799 - accuracy: 0.9821\n",
      "Epoch 40/75\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 2.3944e-04 - accuracy: 1.0000\n",
      "Epoch 50/75\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0246 - accuracy: 0.9933\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.5623 - accuracy: 0.9375Epoch 46/75\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.0253 - accuracy: 0.9933A: 0s - loss: 0.1993 - accuracy: 0.\n",
      "14/14 [==============================] - 0s 23ms/step - loss: 0.2075 - accuracy: 0.9129\n",
      "Epoch 17/75\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.0293 - accuracy: 0.9931Epoch 44/75\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.0092 - accuracy: 0.9978\n",
      " 4/14 [=======>......................] - ETA: 0s - loss: 0.2747 - accuracy: 0.8906Epoch 56/75\n",
      "14/14 [==============================] - 0s 21ms/step - loss: 0.0296 - accuracy: 0.9911\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.0136 - accuracy: 0.9978\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 0.0333 - accuracy: 0.9896Epoch 21/75\n",
      "Epoch 47/75\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.0029 - accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:31:03.932175: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 26ms/step - loss: 0.1353 - accuracy: 0.9643\n",
      "12/14 [========================>.....] - ETA: 0s - loss: 5.2185e-04 - accuracy: 1.0000Epoch 41/75\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 4.5681e-04 - accuracy: 1.0000\n",
      "Epoch 51/75\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.1950 - accuracy: 0.9241A: 0s - loss: 0.0336 - accuracy: 0.98\n",
      " 4/14 [=======>......................] - ETA: 0s - loss: 7.6685e-05 - accuracy: 1.0000Epoch 45/75\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.0185 - accuracy: 0.9955\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 0.0274 - accuracy: 0.9866\n",
      "Epoch 18/75\n",
      "Epoch 48/75\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.0127 - accuracy: 0.9933A: 0s - loss: 0.1323 - accuracy: 0.9688 - ETA: 0s - loss: 1.6501 - accuracy: 0.35\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 0.0030 - accuracy: 1.0000Epoch 22/75\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.0822 - accuracy: 0.9643\n",
      " 5/14 [=========>....................] - ETA: 0s - loss: 0.1200 - accuracy: 0.9688Epoch 42/75\n",
      "14/14 [==============================] - 0s 36ms/step - loss: 0.0057 - accuracy: 0.9978\n",
      " 5/14 [=========>....................] - ETA: 0s - loss: 0.0791 - accuracy: 0.9750 - ETA: 0s - loss: 1.6168 - accuracy: 0.3594Epoch 57/75\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.1726 - accuracy: 0.9330A: 0s - loss: 1.5776e-04 - accuracy: 1.\n",
      "Epoch 46/75\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 1.8979e-04 - accuracy: 1.0000\n",
      "Epoch 52/75\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0382 - accuracy: 0.9866\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.0294 - accuracy: 0.9938Epoch 49/75\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 1.5886 - accuracy: 0.3460\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 1.0228e-04 - accuracy: 1.0000Epoch 2/75\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.0234 - accuracy: 0.9911\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.0011 - accuracy: 1.0000Epoch 19/75\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.0636 - accuracy: 0.9732\n",
      "Epoch 43/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.0270 - accuracy: 0.9933\n",
      "Epoch 23/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.0092 - accuracy: 0.9978A: 0s - loss: 2.7676e-04 - accuracy: 1.00\n",
      "Epoch 58/75\n",
      "14/14 [==============================] - 0s 24ms/step - loss: 0.2003 - accuracy: 0.9241\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 0.0184 - accuracy: 0.9911Epoch 47/75\n",
      "14/14 [==============================] - 0s 21ms/step - loss: 0.0181 - accuracy: 0.9933\n",
      "Epoch 50/75\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 1.3870 - accuracy: 0.3996\n",
      "Epoch 3/75\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.0588 - accuracy: 0.9732\n",
      "Epoch 44/75\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 2.8984e-04 - accuracy: 1.0000\n",
      "Epoch 53/75\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.0152 - accuracy: 0.9955A: 0s - loss: 1.1868 - accuracy: 0.52\n",
      "Epoch 20/75\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0219 - accuracy: 0.9933\n",
      "Epoch 24/75\n",
      "14/14 [==============================] - 0s 20ms/step - loss: 0.0179 - accuracy: 0.9911\n",
      "Epoch 51/75\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.2136 - accuracy: 0.9063\n",
      "11/14 [======================>.......] - ETA: 0s - loss: 1.1131 - accuracy: 0.5369Epoch 48/75\n",
      "14/14 [==============================] - 0s 24ms/step - loss: 1.0619 - accuracy: 0.5737\n",
      " 5/14 [=========>....................] - ETA: 0s - loss: 0.0173 - accuracy: 0.9938Epoch 4/75\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.0052 - accuracy: 0.9978\n",
      "Epoch 59/75\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.0270 - accuracy: 0.9911\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.0324 - accuracy: 0.9844Epoch 45/75\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.0333 - accuracy: 0.9844\n",
      "Epoch 52/75\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.0209 - accuracy: 0.9955\n",
      "Epoch 21/75\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 2.2951e-04 - accuracy: 1.0000\n",
      "Epoch 54/75\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 0.1916 - accuracy: 0.9196A: 0s - loss: 0.0025 - accuracy: 1.00\n",
      "Epoch 49/75\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.0357 - accuracy: 0.9866\n",
      "11/14 [======================>.......] - ETA: 0s - loss: 0.6183 - accuracy: 0.7585Epoch 25/75\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.5692 - accuracy: 0.7879\n",
      " 6/14 [===========>..................] - ETA: 0s - loss: 0.0458 - accuracy: 0.9844Epoch 5/75\n",
      "14/14 [==============================] - 0s 20ms/step - loss: 0.0193 - accuracy: 0.9933\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 0.0340 - accuracy: 0.9933\n",
      "Epoch 53/75\n",
      "Epoch 46/75\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 60/75\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0451 - accuracy: 0.9844- ETA: 0s - loss: 0.0218 - accuracy: 0.\n",
      "Epoch 22/75\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.1625 - accuracy: 0.9330\n",
      "Epoch 50/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 2.0965e-04 - accuracy: 1.0000ss: 0.0492 - accuracy: 0.9875 - ETA: 0s - loss: 0.2165 - accuracy: 0.90\n",
      "Epoch 55/75\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 0.2476 - accuracy: 0.9241\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.2244 - accuracy: 0.9286\n",
      "Epoch 6/75\n",
      "Epoch 26/75\n",
      "14/14 [==============================] - 0s 20ms/step - loss: 0.0378 - accuracy: 0.9911\n",
      "Epoch 54/75\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.0571 - accuracy: 0.9844A: 0s - loss: 0.0526 - accuracy: 0.\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 0.0465 - accuracy: 0.9792Epoch 47/75\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 61/75\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.4499 - accuracy: 0.8750\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 0.0884 - accuracy: 0.9732Epoch 23/75\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.1384 - accuracy: 0.9464\n",
      "14/14 [==============================] - 0s 24ms/step - loss: 0.0381 - accuracy: 0.9911\n",
      " 5/14 [=========>....................] - ETA: 0s - loss: 0.0093 - accuracy: 0.9938Epoch 51/75\n",
      "Epoch 55/75\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 5.7021e-04 - accuracy: 1.0000ss: 0.0971 - accuracy: 0.9688 - ETA: 0s - loss: 5.7021e-04 - accuracy: 1.00\n",
      "Epoch 56/75\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.0867 - accuracy: 0.9799\n",
      "Epoch 7/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.3762 - accuracy: 0.8549\n",
      "Epoch 27/75\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.0913 - accuracy: 0.9665\n",
      "Epoch 48/75\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.0040 - accuracy: 0.9978- loss: 0.0900 - accuracy: 0.9688 - ETA: 0s - loss: 0.0467 - accuracy: 0.99\n",
      "Epoch 62/75\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.0223 - accuracy: 0.9888\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.1491 - accuracy: 0.9495Epoch 56/75\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.1447 - accuracy: 0.9554\n",
      " 1/14 [=>............................]Epoch 24/75\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.1561 - accuracy: 0.9464\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.0657 - accuracy: 0.9826Epoch 52/75\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.0482 - accuracy: 0.9911\n",
      "Epoch 8/75\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0691 - accuracy: 0.9661 - 0s 35ms/step - loss: 6.6805e-04 - accuracy: 1.0000\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 0.0924 - accuracy: 0.9792Epoch 57/75\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0633 - accuracy: 0.9688\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.0783 - accuracy: 0.9710\n",
      "Epoch 49/75\n",
      " 5/14 [=========>....................] - ETA: 0s - loss: 0.0623 - accuracy: 0.9875Epoch 28/75\n",
      "14/14 [==============================] - 0s 22ms/step - loss: 0.0168 - accuracy: 0.9955- loss: 0.0458 - accuracy: 0.9948 - ETA: 0s - loss: 0.0223 - accuracy: 0.98\n",
      "Epoch 57/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.0060 - accuracy: 0.9978A: 0s - loss: 0.0576 - accuracy: 0.\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 0.0311 - accuracy: 0.9866Epoch 63/75\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.1401 - accuracy: 0.9442A: 0s - loss: 0.1275 - accuracy: 0.96\n",
      "Epoch 53/75\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 0.0298 - accuracy: 0.9978\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.0469 - accuracy: 0.9866\n",
      "Epoch 25/75\n",
      "Epoch 9/75\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.1163 - accuracy: 0.9665\n",
      "14/14 [==============================] - 1s 35ms/step - loss: 3.4219e-04 - accuracy: 1.0000\n",
      "Epoch 50/75\n",
      "Epoch 58/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.0294 - accuracy: 0.9888\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 9.1138e-04 - accuracy: 1.0000Epoch 29/75\n",
      "14/14 [==============================] - 0s 24ms/step - loss: 0.0186 - accuracy: 0.9955\n",
      "Epoch 58/75\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.1735 - accuracy: 0.9330A: 0s - loss: 1.8048e-04 - accuracy: 1.00\n",
      "Epoch 54/75\n",
      "14/14 [==============================] - 1s 36ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.0070 - accuracy: 1.0000\n",
      "Epoch 64/75\n",
      "Epoch 10/75\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.0123 - accuracy: 0.9955\n",
      "Epoch 26/75\n",
      "14/14 [==============================] - 0s 23ms/step - loss: 0.0225 - accuracy: 0.9955\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.0035 - accuracy: 1.0000Epoch 59/75\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.0526 - accuracy: 0.9844\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.0425 - accuracy: 0.9904Epoch 51/75\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.0409 - accuracy: 0.9911\n",
      "Epoch 30/75\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 2.2549e-04 - accuracy: 1.0000\n",
      "Epoch 59/75\n",
      "14/14 [==============================] - 0s 24ms/step - loss: 0.1893 - accuracy: 0.9152\n",
      "Epoch 55/75\n",
      "14/14 [==============================] - 0s 20ms/step - loss: 0.0108 - accuracy: 0.9933\n",
      "13/14 [==========================>...]Epoch 60/75- loss: 0.0022 - accuracy: 1.00\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.0244 - accuracy: 0.9888\n",
      " 5/14 [=========>....................] - ETA: 0s - loss: 1.1371e-04 - accuracy: 1.0000Epoch 11/75\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.0018 - accuracy: 1.0000\n",
      " 6/14 [===========>..................] - ETA: 0s - loss: 0.1404 - accuracy: 0.9479Epoch 27/75\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 0.0327 - accuracy: 0.9888\n",
      "Epoch 52/75\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.0027 - accuracy: 1.0000\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 1.8685e-04 - accuracy: 1.0000Epoch 65/75\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.0130 - accuracy: 0.9978\n",
      "Epoch 31/75\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.1408 - accuracy: 0.9464\n",
      "Epoch 56/75\n",
      "14/14 [==============================] - 0s 23ms/step - loss: 0.0174 - accuracy: 0.9911\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 0.0011 - accuracy: 1.0000    Epoch 61/75\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 1.5186e-04 - accuracy: 1.0000\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.1079 - accuracy: 0.9688Epoch 60/75\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0312 - accuracy: 0.9888\n",
      "Epoch 12/75\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.0434 - accuracy: 0.9799\n",
      "Epoch 53/75\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 28/75\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.0151 - accuracy: 0.9933\n",
      "Epoch 32/75\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.0031 - accuracy: 1.0000\n",
      "Epoch 66/75\n",
      "14/14 [==============================] - 0s 24ms/step - loss: 0.1796 - accuracy: 0.9353\n",
      "14/14 [==============================] - 0s 23ms/step - loss: 0.0081 - accuracy: 1.0000\n",
      "Epoch 57/75\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 3.0907e-04 - accuracy: 1.0000Epoch 62/75\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 4.4625e-04 - accuracy: 1.0000s - loss: 0.0233 - accuracy: 0.99\n",
      "Epoch 61/75\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.0101 - accuracy: 1.0000\n",
      "Epoch 13/75\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0258 - accuracy: 0.9978\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 5.5206e-05 - accuracy: 1.0000Epoch 54/75\n",
      "14/14 [==============================] - 0s 22ms/step - loss: 0.0082 - accuracy: 0.9978\n",
      "Epoch 63/75\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 29/75\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 0.1460 - accuracy: 0.9375\n",
      "Epoch 58/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.0043 - accuracy: 1.0000\n",
      " 6/14 [===========>..................] - ETA: 0s - loss: 0.0287 - accuracy: 1.0000Epoch 33/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.0110 - accuracy: 0.9911\n",
      "Epoch 67/75\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.0151 - accuracy: 0.9955A: 0s - loss: 0.0040 - accuracy: 1.00\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 3.5327e-04 - accuracy: 1.0000Epoch 14/75\n",
      "14/14 [==============================] - 0s 24ms/step - loss: 0.0095 - accuracy: 0.9978\n",
      "Epoch 64/75\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0046 - accuracy: 1.0000 - 0s 26ms/step - loss: 0.0248 - accuracy: 0.9978\n",
      "Epoch 55/75\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 3.3608e-04 - accuracy: 1.0000\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.0422 - accuracy: 1.0000Epoch 62/75\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.1697 - accuracy: 0.9263\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.0070 - accuracy: 1.0000Epoch 59/75\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 4.5136e-04 - accuracy: 1.0000\n",
      "Epoch 30/75\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.0070 - accuracy: 0.9978\n",
      " 6/14 [===========>..................] - ETA: 0s - loss: 0.1954 - accuracy: 0.9271Epoch 34/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.0046 - accuracy: 1.0000\n",
      "Epoch 68/75\n",
      " - 0s 24ms/step - loss: 0.0198 - accuracy: 0.9933- loss: 0.0198 - accuracy: 0.990000\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 3.6256e-04 - accuracy: 1.0000Epoch 65/75\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.0043 - accuracy: 1.0000\n",
      "Epoch 15/75\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0284 - accuracy: 0.9911- loss: 8.9416e-04 - accuracy: 1.0000 - ETA: 0s - loss: 0.0038 - accuracy: 1.00\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 0.0197 - accuracy: 0.9896Epoch 56/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 2.5960e-04 - accuracy: 1.0000\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.1505 - accuracy: 0.9420\n",
      "Epoch 63/75\n",
      "Epoch 60/75\n",
      "14/14 [==============================] - 0s 36ms/step - loss: 4.4559e-04 - accuracy: 1.0000\n",
      " 5/14 [=========>....................] - ETA: 0s - loss: 8.0484e-05 - accuracy: 1.0000Epoch 31/75\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.0021 - accuracy: 1.0000\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 0.0194 - accuracy: 0.9933\n",
      "Epoch 35/75\n",
      "Epoch 66/75\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.0099 - accuracy: 0.9955A: 0s - loss: 0.0014 - accuracy: 1.00\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 5.8496e-04 - accuracy: 1.0000Epoch 69/75\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.0116 - accuracy: 0.9978\n",
      "Epoch 16/75\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.1577 - accuracy: 0.9308\n",
      "Epoch 61/75\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.0192 - accuracy: 0.9911\n",
      "Epoch 57/75\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 1.3075e-04 - accuracy: 1.0000ss: 0.0077 - accuracy: 1.0000 - ETA: 0s - loss: 0.0029 - accuracy: 1.00\n",
      "Epoch 64/75\n",
      "14/14 [==============================] - 0s 24ms/step - loss: 0.0524 - accuracy: 0.9844\n",
      "Epoch 67/75\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0054 - accuracy: 1.0000\n",
      "Epoch 36/75\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.0029 - accuracy: 1.0000\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.0012 - accuracy: 1.0000Epoch 32/75\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.0039 - accuracy: 1.0000\n",
      "Epoch 17/75\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.1361 - accuracy: 0.9464\n",
      "Epoch 62/75\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.0043 - accuracy: 1.0000\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.0265 - accuracy: 0.9904Epoch 70/75\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.0247 - accuracy: 0.9911\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.0141 - accuracy: 1.0000Epoch 58/75\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0196 - accuracy: 1.0000- ETA: 0s - loss: 1.3937e-04 - accuracy: 1.00\n",
      "Epoch 68/75\n",
      "14/14 [==============================] - 1s 36ms/step - loss: 8.2107e-05 - accuracy: 1.0000\n",
      "11/14 [======================>.......] - ETA: 0s - loss: 0.0043 - accuracy: 1.0000Epoch 65/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.0040 - accuracy: 1.0000\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 3.1828e-04 - accuracy: 1.0000Epoch 37/75\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 7.8664e-04 - accuracy: 1.0000\n",
      "Epoch 18/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 3.1556e-04 - accuracy: 1.0000\n",
      "Epoch 33/75\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.1379 - accuracy: 0.9442- ETA: 0s - loss: 1.5945e-04 - accuracy: 1.00\n",
      "Epoch 63/75\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.0156 - accuracy: 0.9933\n",
      "Epoch 59/75\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 71/75\n",
      "14/14 [==============================] - 0s 22ms/step - loss: 0.0249 - accuracy: 0.9933\n",
      " 5/14 [=========>....................] - ETA: 0s - loss: 5.9061e-04 - accuracy: 1.0000Epoch 69/75\n",
      "14/14 [==============================] - 0s 36ms/step - loss: 9.8244e-05 - accuracy: 1.0000ss: 0.0033 - accuracy: 1.0000 - ETA: 0s - loss: 5.2270e-04 - accuracy: 1.\n",
      "Epoch 66/75\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0026 - accuracy: 1.0000\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 0.0050 - accuracy: 0.9955Epoch 38/75\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 19/75\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 6.5620e-04 - accuracy: 1.0000\n",
      "Epoch 34/75\n",
      "14/14 [==============================] - 0s 20ms/step - loss: 0.0213 - accuracy: 0.9933\n",
      " - 0s 30ms/step - loss: 0.1328 - accuracy: 0.9464\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 8.3568e-05 - accuracy: 1.0000Epoch 70/75\n",
      "Epoch 64/75\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.0236 - accuracy: 0.9955\n",
      " 6/14 [===========>..................] - ETA: 0s - loss: 0.0049 - accuracy: 1.0000Epoch 60/75\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.0048 - accuracy: 0.9955\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.0042 - accuracy: 1.0000Epoch 72/75\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0032 - accuracy: 1.0000\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.0067 - accuracy: 0.9976Epoch 39/75\n",
      "14/14 [==============================] - 0s 22ms/step - loss: 0.0062 - accuracy: 0.9978\n",
      "Epoch 71/75\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0059 - accuracy: 1.0000\n",
      "Epoch 20/75\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 8.5361e-05 - accuracy: 1.0000\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.1297 - accuracy: 0.9420\n",
      "Epoch 67/75\n",
      "Epoch 65/75\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 5.3623e-04 - accuracy: 1.0000A: 0s - loss: 0.0429 - accuracy: 0.9792\n",
      "Epoch 35/75\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.0395 - accuracy: 0.9821- ETA: 0s - loss: 0.2135 - accuracy: 0.\n",
      "Epoch 61/75\n",
      "14/14 [==============================] - 0s 22ms/step - loss: 0.0067 - accuracy: 1.0000\n",
      "Epoch 72/75\n",
      "14/14 [==============================] - 0s 36ms/step - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 73/75\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.0063 - accuracy: 1.0000\n",
      " 5/14 [=========>....................] - ETA: 0s - loss: 0.0395 - accuracy: 0.9938Epoch 21/75\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.0035 - accuracy: 0.9978\n",
      "Epoch 40/75\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.1552 - accuracy: 0.9375\n",
      " 6/14 [===========>..................] - ETA: 0s - loss: 0.0081 - accuracy: 1.0000Epoch 66/75\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 2.3201e-04 - accuracy: 1.0000\n",
      "Epoch 68/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 1.1069e-04 - accuracy: 1.0000\n",
      "Epoch 36/75\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 0.0085 - accuracy: 1.0000\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.0333 - accuracy: 0.9955\n",
      "Epoch 73/75\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.0035 - accuracy: 1.0000Epoch 62/75\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.0040 - accuracy: 1.0000\n",
      " - ETA: 0s - loss: 2.0096e-04 - accuracy: 1.0000 7/14 [==============>...............] - ETA: 0s - loss: 6.6741e-05 - accuracy: 1.0000Epoch 22/75\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 4.6272e-04 - accuracy: 1.0000\n",
      "Epoch 74/75\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.1490 - accuracy: 0.9397\n",
      "Epoch 67/75\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 41/75\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 7.3914e-05 - accuracy: 1.0000\n",
      " - ETA: 0s - loss: 1.7639e-04 - accuracy: 1.0000 5/14 [=========>....................] - 0s 26ms/step - loss: 0.0048 - accuracy: 1.0000\n",
      " - ETA: 0s - loss: 2.9397e-04 - accuracy: 1.0000Epoch 69/75\n",
      " 5/14 [=========>....................]Epoch 74/75- loss: 0.0016 - accuracy: 1.00\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 2.6403e-04 - accuracy: 1.0000\n",
      "Epoch 37/75\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0197 - accuracy: 0.9933\n",
      "Epoch 63/75\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      " 2/14 [===>..........................] - ETA: 0s - loss: 5.1927e-04 - accuracy: 1.0000Epoch 23/75\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.1655 - accuracy: 0.9308\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.0025 - accuracy: 1.0000Epoch 68/75\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 42/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 75/75\n",
      "14/14 [==============================] - 0s 22ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 75/75\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 9.1168e-05 - accuracy: 1.0000ss: 2.9699e-04 - accuracy: 1.0000 - ETA: 0s - loss: 0.0030 - accuracy: 1.\n",
      "Epoch 70/75\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0152 - accuracy: 0.9933\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 0.0071 - accuracy: 0.9955Epoch 64/75\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 3.7783e-04 - accuracy: 1.0000\n",
      "Epoch 24/75\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 2.3395e-04 - accuracy: 1.0000\n",
      " 8/14 [================>.............] - ETA: 0s - loss: 6.6043e-04 - accuracy: 1.0000Epoch 38/75\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.1410 - accuracy: 0.9375\n",
      " 3/14 [=====>........................] - ETA: 0s - loss: 9.3829e-05 - accuracy: 1.0000Epoch 69/75\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 0.0053 - accuracy: 1.0000\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.0058 - accuracy: 0.9955\n",
      "Epoch 43/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 7.1273e-04 - accuracy: 1.0000==============>.............] - ETA: 0s - loss: 1.2365e-04 - accuracy: 1.00\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0316 - accuracy: 0.9888- loss: 9.3231e-05 - accuracy: 1.0000 - ETA: 0s - loss: 0.0340 - accuracy: 0.98\n",
      "Epoch 65/75\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 2.9949e-04 - accuracy: 1.0000\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 0.0025 - accuracy: 1.0000Epoch 25/75\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 1.2600e-04 - accuracy: 1.0000\n",
      "Epoch 71/75\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 0.1421 - accuracy: 0.9464A: 0s - loss: 0.0293 - accuracy: 0.9792  \n",
      "Epoch 70/75\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 1.5478e-04 - accuracy: 1.0000\n",
      "Epoch 39/75\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 1.2073e-04 - accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:31:13.880502: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-01-09 14:31:13.937851: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 30ms/step - loss: 0.0030 - accuracy: 1.0000\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 3.0477e-04 - accuracy: 1.0000Epoch 44/75\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.0285 - accuracy: 0.9911- ETA: 0s - loss: 4.2032e-04 - accuracy: 1.00\n",
      "Epoch 66/75\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.0247 - accuracy: 0.9911  - ETA: 0s - loss: 0.1672 - accuracy: 0.92\n",
      "[CV 2/5] END ...epochs=75, layers=3, neurons=60;, score=0.991 total time=  27.9s\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 3.1955e-04 - accuracy: 1.0000\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 6.5075e-04 - accuracy: 1.0000Epoch 26/75\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 2.8404e-06 - accuracy: 1.0000\n",
      "[CV 3/5] END ...epochs=75, layers=3, neurons=40;, score=1.000 total time=  38.8s\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.1463 - accuracy: 0.9397\n",
      "Epoch 71/75\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 1.9135e-04 - accuracy: 1.0000\n",
      " 5/14 [=========>....................] - ETA: 0s - loss: 0.0074 - accuracy: 1.0000    Epoch 72/75\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 2.3859e-04 - accuracy: 1.0000A: 0s - loss: 1.1008e-04 - accuracy: 1.00\n",
      "Epoch 40/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 45/75\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0170 - accuracy: 0.9933- ETA: 0s - loss: 0.0537 - accuracy: 0.96\n",
      "Epoch 67/75\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 2.6743e-04 - accuracy: 1.0000\n",
      "Epoch 27/75\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.1575 - accuracy: 0.9308\n",
      "Epoch 72/75\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 9.4336e-05 - accuracy: 1.0000\n",
      "Epoch 73/75\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 1.7729e-04 - accuracy: 1.0000\n",
      "Epoch 41/75\n",
      "14/14 [==============================] - 0s 24ms/step - loss: 0.0324 - accuracy: 0.9821\n",
      "Epoch 68/75\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0081 - accuracy: 0.9978\n",
      "Epoch 46/75\n",
      "14/14 [==============================] - 0s 23ms/step - loss: 1.5511e-04 - accuracy: 1.0000\n",
      "Epoch 28/75\n",
      "14/14 [==============================] - 0s 21ms/step - loss: 0.1373 - accuracy: 0.9397\n",
      "Epoch 73/75\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 1.7765e-04 - accuracy: 1.0000\n",
      "Epoch 42/75\n",
      "14/14 [==============================] - 0s 20ms/step - loss: 0.0442 - accuracy: 0.9911\n",
      "Epoch 69/75\n",
      "14/14 [==============================] - 0s 19ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 29/75\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 1.2636e-04 - accuracy: 1.0000\n",
      "Epoch 74/75\n",
      "14/14 [==============================] - 0s 19ms/step - loss: 0.1607 - accuracy: 0.9420\n",
      "Epoch 74/75\n",
      "14/14 [==============================] 4/14 [=======>......................] - 0s 26ms/step - loss: 0.0154 - accuracy: 0.9978\n",
      " - ETA: 0s - loss: 0.0366 - accuracy: 0.9844Epoch 47/75\n",
      "14/14 [==============================] - 0s 21ms/step - loss: 0.0253 - accuracy: 0.9911- ETA: 0s - loss: 8.1309e-05 - accuracy: 1.\n",
      "Epoch 70/75\n",
      "14/14 [==============================] - 0s 22ms/step - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 30/75\n",
      "14/14 [==============================] - 0s 20ms/step - loss: 0.1002 - accuracy: 0.9621\n",
      "11/14 [======================>.......] - ETA: 0s - loss: 5.7225e-05 - accuracy: 1.0000Epoch 75/75\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 2.9475e-04 - accuracy: 1.0000\n",
      "Epoch 43/75\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.0118 - accuracy: 0.9955- loss: 0.1691 - accuracy: 0.9219 - ETA: 0s - loss: 0.0219 - accuracy: 0.99\n",
      "Epoch 48/75\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 5.5139e-05 - accuracy: 1.0000\n",
      "Epoch 75/75\n",
      "14/14 [==============================] - 0s 17ms/step - loss: 9.1970e-04 - accuracy: 1.0000\n",
      "Epoch 31/75\n",
      "14/14 [==============================] - 0s 20ms/step - loss: 0.0253 - accuracy: 0.9933\n",
      "Epoch 71/75\n",
      "14/14 [==============================] - 0s 22ms/step - loss: 0.1491 - accuracy: 0.9375\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 2.2982e-04 - accuracy: 1.0000\n",
      "Epoch 44/75\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 0.0140 - accuracy: 0.9978\n",
      "Epoch 49/75\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 8.1560e-05 - accuracy: 1.0000\n",
      "14/14 [==============================] - 0s 20ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 32/75\n",
      "14/14 [==============================] - 0s 24ms/step - loss: 0.1143 - accuracy: 0.9598\n",
      "Epoch 72/75\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.2464 - accuracy: 0.96430\n",
      "[CV 5/5] END ...epochs=75, layers=3, neurons=40;, score=0.964 total time=  31.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:31:16.038408: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 24ms/step - loss: 1.4880e-04 - accuracy: 1.0000\n",
      "Epoch 45/75\n",
      "14/14 [==============================] - 0s 22ms/step - loss: 0.0040 - accuracy: 1.0000\n",
      "Epoch 50/75\n",
      "14/14 [==============================] - 0s 22ms/step - loss: 3.8619e-04 - accuracy: 1.0000A: 0s - loss: 0.2149 - accuracy: 0.9410\n",
      "12/14 [========================>.....] - ETA: 0s - loss: 0.2127 - accuracy: 0.9375Epoch 33/75\n",
      "14/14 [==============================] - 0s 21ms/step - loss: 0.1914 - accuracy: 0.9420\n",
      "Epoch 73/75\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 1.0334e-04 - accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:31:16.255446: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 41ms/step - loss: 0.0264 - accuracy: 0.9911\n",
      "[CV 4/5] END ...epochs=75, layers=3, neurons=40;, score=0.991 total time=  39.0s\n",
      "14/14 [==============================] - 0s 24ms/step - loss: 1.0573e-04 - accuracy: 1.0000\n",
      "14/14 [==============================] - 0s 24ms/step - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 46/75\n",
      "Epoch 51/75\n",
      "14/14 [==============================] - 0s 19ms/step - loss: 0.1206 - accuracy: 0.9509\n",
      "14/14 [==============================] - 0s 23ms/step - loss: 6.4371e-05 - accuracy: 1.0000\n",
      "Epoch 74/75\n",
      "Epoch 34/75\n",
      "14/14 [==============================] - 0s 20ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 52/75\n",
      "14/14 [==============================] - 0s 21ms/step - loss: 1.0970e-04 - accuracy: 1.0000\n",
      "Epoch 47/75\n",
      "14/14 [==============================] - 0s 17ms/step - loss: 8.1610e-05 - accuracy: 1.0000\n",
      "Epoch 35/75\n",
      "14/14 [==============================] - 0s 18ms/step - loss: 0.1099 - accuracy: 0.9531\n",
      "Epoch 75/75\n",
      "14/14 [==============================] - 0s 15ms/step - loss: 5.2615e-05 - accuracy: 1.0000A: 0s - loss: 0.1854 - accuracy: 0.\n",
      "Epoch 36/75\n",
      "14/14 [==============================] - 0s 19ms/step - loss: 5.0835e-04 - accuracy: 1.0000\n",
      "Epoch 53/75\n",
      "14/14 [==============================] - 0s 17ms/step - loss: 0.1669 - accuracy: 0.9375\n",
      "14/14 [==============================] - 0s 22ms/step - loss: 1.0728e-04 - accuracy: 1.0000\n",
      "Epoch 48/75\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 4.6325e-05 - accuracy: 1.0000\n",
      "Epoch 37/75\n",
      "14/14 [==============================] - 0s 15ms/step - loss: 4.9798e-04 - accuracy: 1.0000\n",
      "Epoch 54/75\n",
      "14/14 [==============================] - 0s 17ms/step - loss: 1.0436e-04 - accuracy: 1.0000\n",
      "Epoch 49/75\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.0426 - accuracy: 0.9911\n",
      "[CV 1/5] END ...epochs=75, layers=3, neurons=60;, score=0.991 total time=  31.6s\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 2.6954e-04 - accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:31:17.310070: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 16ms/step - loss: 1.2638e-04 - accuracy: 1.0000\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 3.6589e-04 - accuracy: 1.0000Epoch 38/75\n",
      "14/14 [==============================] - 0s 19ms/step - loss: 3.7153e-04 - accuracy: 1.0000\n",
      "Epoch 55/75\n",
      "14/14 [==============================] - 0s 19ms/step - loss: 1.0533e-04 - accuracy: 1.0000\n",
      "Epoch 50/75\n",
      "14/14 [==============================] - 0s 15ms/step - loss: 7.3043e-05 - accuracy: 1.0000\n",
      "Epoch 39/75\n",
      "14/14 [==============================] - 0s 19ms/step - loss: 2.4231e-04 - accuracy: 1.0000\n",
      "Epoch 56/75\n",
      "14/14 [==============================] - 0s 18ms/step - loss: 2.1563e-04 - accuracy: 1.0000\n",
      "Epoch 51/75\n",
      "14/14 [==============================] - 0s 15ms/step - loss: 5.0990e-05 - accuracy: 1.0000\n",
      "Epoch 40/75\n",
      "14/14 [==============================] - 0s 16ms/step - loss: 6.3077e-04 - accuracy: 1.0000\n",
      " 8/14 [================>.............] - ETA: 0s - loss: 3.8915e-05 - accuracy: 1.0000Epoch 57/75\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 1.0109e-04 - accuracy: 1.0000\n",
      "Epoch 41/75\n",
      "14/14 [==============================] - 0s 16ms/step - loss: 6.0980e-05 - accuracy: 1.0000\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 1.7099e-05 - accuracy: 1.0000Epoch 52/75\n",
      "14/14 [==============================] - 0s 15ms/step - loss: 3.7088e-04 - accuracy: 1.0000\n",
      "Epoch 58/75\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 8.7605e-05 - accuracy: 1.0000\n",
      "Epoch 42/75\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 7.4822e-05 - accuracy: 1.0000\n",
      "Epoch 53/75\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 1.9247e-04 - accuracy: 1.0000\n",
      "Epoch 59/75\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 3.5930e-05 - accuracy: 1.0000\n",
      "Epoch 43/75\n",
      "14/14 [==============================] - 0s 16ms/step - loss: 0.0012 - accuracy: 1.0000- loss: 3.4131e-05 - accuracy: 1.0000 - ETA: 0s - loss: 5.9000e-05 - accuracy: 1.00\n",
      "Epoch 54/75\n",
      "14/14 [==============================] - 0s 15ms/step - loss: 2.5374e-04 - accuracy: 1.0000\n",
      "Epoch 60/75\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 3.6194e-05 - accuracy: 1.0000\n",
      "Epoch 44/75\n",
      "14/14 [==============================] - 0s 15ms/step - loss: 2.2799e-04 - accuracy: 1.0000\n",
      "Epoch 55/75\n",
      "14/14 [==============================] - 0s 15ms/step - loss: 2.8929e-04 - accuracy: 1.0000\n",
      "Epoch 61/75\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 4.8141e-05 - accuracy: 1.0000\n",
      "Epoch 45/75\n",
      "14/14 [==============================] - 0s 16ms/step - loss: 6.0777e-04 - accuracy: 1.0000\n",
      "Epoch 56/75\n",
      "14/14 [==============================] - 0s 15ms/step - loss: 3.4749e-04 - accuracy: 1.0000\n",
      "Epoch 62/75\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 3.9225e-05 - accuracy: 1.0000\n",
      "Epoch 46/75\n",
      "14/14 [==============================] - 0s 17ms/step - loss: 1.0060e-04 - accuracy: 1.0000\n",
      "Epoch 57/75\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 4.6622e-05 - accuracy: 1.0000\n",
      "Epoch 47/75\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 1.4773e-04 - accuracy: 1.0000\n",
      "Epoch 63/75\n",
      "14/14 [==============================] - 0s 15ms/step - loss: 1.1630e-04 - accuracy: 1.0000\n",
      "Epoch 58/75\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 5.3586e-05 - accuracy: 1.0000\n",
      "Epoch 48/75\n",
      "14/14 [==============================] - 0s 16ms/step - loss: 2.1202e-04 - accuracy: 1.0000\n",
      "Epoch 64/75\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 2.4110e-05 - accuracy: 1.0000\n",
      "Epoch 49/75\n",
      "14/14 [==============================] - 0s 17ms/step - loss: 1.5915e-04 - accuracy: 1.0000ss: 1.7925e-05 - accuracy: 1.0000 - ETA: 0s - loss: 1.5915e-04 - accuracy: 1.00\n",
      "Epoch 59/75\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 1.7793e-04 - accuracy: 1.0000\n",
      "Epoch 65/75\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 5.4259e-05 - accuracy: 1.0000\n",
      "Epoch 50/75\n",
      "14/14 [==============================] - 0s 15ms/step - loss: 1.6081e-04 - accuracy: 1.0000\n",
      "Epoch 66/75\n",
      "14/14 [==============================] - 0s 17ms/step - loss: 6.5350e-05 - accuracy: 1.0000\n",
      "Epoch 60/75\n",
      "14/14 [==============================] - 0s 15ms/step - loss: 3.0611e-05 - accuracy: 1.0000\n",
      "Epoch 51/75\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 8.4866e-05 - accuracy: 1.0000\n",
      "Epoch 67/75\n",
      "14/14 [==============================] - 0s 16ms/step - loss: 4.9056e-05 - accuracy: 1.0000\n",
      "Epoch 61/75\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 2.3694e-05 - accuracy: 1.0000\n",
      "Epoch 52/75\n",
      "14/14 [==============================] - 0s 15ms/step - loss: 1.0224e-04 - accuracy: 1.0000\n",
      "Epoch 68/75\n",
      "14/14 [==============================] - 0s 15ms/step - loss: 6.3259e-05 - accuracy: 1.0000\n",
      "Epoch 62/75\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 3.1480e-05 - accuracy: 1.0000\n",
      "Epoch 53/75\n",
      "14/14 [==============================] - 0s 15ms/step - loss: 2.0301e-04 - accuracy: 1.0000\n",
      "Epoch 69/75\n",
      "14/14 [==============================] - 0s 15ms/step - loss: 6.0707e-05 - accuracy: 1.0000\n",
      "Epoch 63/75\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 2.1343e-05 - accuracy: 1.0000\n",
      "Epoch 54/75\n",
      "14/14 [==============================] - 0s 15ms/step - loss: 7.0747e-05 - accuracy: 1.0000\n",
      "Epoch 70/75\n",
      "14/14 [==============================] - 0s 15ms/step - loss: 4.0838e-05 - accuracy: 1.0000\n",
      "Epoch 64/75\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 1.7726e-05 - accuracy: 1.0000\n",
      "Epoch 55/75\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 7.3065e-05 - accuracy: 1.0000\n",
      "Epoch 71/75\n",
      "14/14 [==============================] - 0s 16ms/step - loss: 7.2580e-05 - accuracy: 1.0000\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 3.2210e-05 - accuracy: 1.0000Epoch 65/75\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 2.9972e-05 - accuracy: 1.0000\n",
      "Epoch 56/75\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 1.4368e-04 - accuracy: 1.0000\n",
      "Epoch 72/75\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 5.1516e-05 - accuracy: 1.0000A: 0s - loss: 1.0110e-04 - accuracy: 1.00\n",
      "Epoch 57/75\n",
      "14/14 [==============================] - 0s 16ms/step - loss: 1.0460e-04 - accuracy: 1.0000\n",
      "Epoch 66/75\n",
      "14/14 [==============================] - 0s 16ms/step - loss: 1.0691e-04 - accuracy: 1.0000\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 3.5073e-05 - accuracy: 1.0000Epoch 73/75\n",
      "14/14 [==============================] - 0s 17ms/step - loss: 3.2395e-05 - accuracy: 1.0000\n",
      "Epoch 58/75\n",
      "14/14 [==============================] - 0s 18ms/step - loss: 4.8125e-05 - accuracy: 1.0000\n",
      "Epoch 67/75\n",
      "14/14 [==============================] - 0s 19ms/step - loss: 7.6313e-05 - accuracy: 1.0000\n",
      "Epoch 74/75\n",
      "14/14 [==============================] - 0s 19ms/step - loss: 3.6854e-05 - accuracy: 1.0000\n",
      "12/14 [========================>.....] - ETA: 0s - loss: 8.4095e-05 - accuracy: 1.0000Epoch 59/75\n",
      "14/14 [==============================] - 0s 19ms/step - loss: 7.6048e-05 - accuracy: 1.0000\n",
      "Epoch 68/75\n",
      "14/14 [==============================] - 0s 18ms/step - loss: 1.1757e-04 - accuracy: 1.0000\n",
      "Epoch 75/75\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 2.0195e-05 - accuracy: 1.0000\n",
      "Epoch 60/75\n",
      "14/14 [==============================] - 0s 15ms/step - loss: 5.1028e-05 - accuracy: 1.0000\n",
      "Epoch 69/75\n",
      "14/14 [==============================] - 0s 17ms/step - loss: 6.5848e-05 - accuracy: 1.0000\n",
      "14/14 [==============================] - 0s 17ms/step - loss: 1.9752e-05 - accuracy: 1.0000\n",
      "Epoch 61/75\n",
      "14/14 [==============================] - 0s 17ms/step - loss: 2.2367e-04 - accuracy: 1.0000\n",
      "Epoch 70/75\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 2.1487e-05 - accuracy: 1.0000\n",
      "Epoch 62/75\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 5.0389e-05 - accuracy: 1.0000\n",
      "Epoch 71/75\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 4.5682e-06 - accuracy: 1.0000\n",
      "[CV 3/5] END ...epochs=75, layers=3, neurons=60;, score=1.000 total time=  29.7s\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 3.7980e-05 - accuracy: 1.0000\n",
      "Epoch 63/75\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 6.2902e-06 - accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:31:22.412332: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 14ms/step - loss: 6.6483e-05 - accuracy: 1.0000\n",
      "Epoch 72/75\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 4.4152e-05 - accuracy: 1.0000\n",
      "Epoch 64/75\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 5.7067e-05 - accuracy: 1.0000\n",
      "Epoch 73/75\n",
      "14/14 [==============================] - 0s 16ms/step - loss: 1.3384e-05 - accuracy: 1.0000\n",
      "Epoch 65/75\n",
      "14/14 [==============================] - 0s 16ms/step - loss: 5.1451e-05 - accuracy: 1.0000\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 1.6547e-05 - accuracy: 1.0000Epoch 74/75\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 1.3645e-05 - accuracy: 1.0000\n",
      " 5/14 [=========>....................] - ETA: 0s - loss: 9.9130e-05 - accuracy: 1.0000Epoch 66/75\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 5.8448e-05 - accuracy: 1.0000\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 2.6425e-05 - accuracy: 1.0000Epoch 75/75\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 2.3392e-05 - accuracy: 1.0000\n",
      " 5/14 [=========>....................] - ETA: 0s - loss: 3.8093e-05 - accuracy: 1.0000Epoch 67/75\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 3.4391e-05 - accuracy: 1.0000\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 4.2810e-05 - accuracy: 1.0000\n",
      "Epoch 68/75\n",
      "11/14 [======================>.......] - ETA: 0s - loss: 1.8048e-05 - accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:31:23.595097: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 11ms/step - loss: 2.0908e-05 - accuracy: 1.0000\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 5.4613e-06 - accuracy: 1.0000Epoch 69/75\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.0181 - accuracy: 0.9911\n",
      "[CV 4/5] END ...epochs=75, layers=3, neurons=60;, score=0.991 total time=  28.7s\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 1.9797e-05 - accuracy: 1.0000\n",
      "Epoch 70/75\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 1.8219e-05 - accuracy: 1.0000\n",
      "Epoch 71/75\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 9.0564e-05 - accuracy: 1.0000\n",
      "Epoch 72/75\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 1.7863e-04 - accuracy: 1.0000\n",
      "Epoch 73/75\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 7.1961e-04 - accuracy: 1.0000\n",
      "Epoch 74/75\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 4.2984e-04 - accuracy: 1.0000\n",
      "Epoch 75/75\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 9.5408e-04 - accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:31:24.789098: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 11ms/step - loss: 2.2408e-05 - accuracy: 1.0000\n",
      "[CV 5/5] END ...epochs=75, layers=3, neurons=60;, score=1.000 total time=  22.0s\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:31:25.581101: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 1s 15ms/step - loss: 1.5463 - accuracy: 0.3429\n",
      "Epoch 2/50\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 1.3643 - accuracy: 0.4643\n",
      "Epoch 3/50\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.9538 - accuracy: 0.5679\n",
      "Epoch 4/50\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.5942 - accuracy: 0.7500\n",
      "Epoch 5/50\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.4243 - accuracy: 0.8571\n",
      "Epoch 6/50\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.3261 - accuracy: 0.8750\n",
      "Epoch 7/50\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.2916 - accuracy: 0.8821\n",
      "Epoch 8/50\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.3360 - accuracy: 0.8893\n",
      "Epoch 9/50\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.3026 - accuracy: 0.8929\n",
      "Epoch 10/50\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.2548 - accuracy: 0.8982\n",
      "Epoch 11/50\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.2744 - accuracy: 0.9000\n",
      "Epoch 12/50\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.2804 - accuracy: 0.8857\n",
      "Epoch 13/50\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.2654 - accuracy: 0.9143\n",
      "Epoch 14/50\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.2758 - accuracy: 0.8696\n",
      "Epoch 15/50\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.2629 - accuracy: 0.8768\n",
      "Epoch 16/50\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.3371 - accuracy: 0.8821\n",
      "Epoch 17/50\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.2982 - accuracy: 0.9000\n",
      "Epoch 18/50\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.2431 - accuracy: 0.9268\n",
      "Epoch 19/50\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.2375 - accuracy: 0.9250\n",
      "Epoch 20/50\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.2379 - accuracy: 0.9232\n",
      "Epoch 21/50\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.2223 - accuracy: 0.9250\n",
      "Epoch 22/50\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.2233 - accuracy: 0.9250\n",
      "Epoch 23/50\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.2309 - accuracy: 0.9143\n",
      "Epoch 24/50\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.2235 - accuracy: 0.9179\n",
      "Epoch 25/50\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.1989 - accuracy: 0.9304\n",
      "Epoch 26/50\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.2023 - accuracy: 0.9232\n",
      "Epoch 27/50\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.2257 - accuracy: 0.9089\n",
      "Epoch 28/50\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.3191 - accuracy: 0.8857\n",
      "Epoch 29/50\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.2384 - accuracy: 0.9089\n",
      "Epoch 30/50\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.1968 - accuracy: 0.9250\n",
      "Epoch 31/50\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.2590 - accuracy: 0.9000\n",
      "Epoch 32/50\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.2086 - accuracy: 0.9071\n",
      "Epoch 33/50\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.1879 - accuracy: 0.9179\n",
      "Epoch 34/50\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.1775 - accuracy: 0.9161\n",
      "Epoch 35/50\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.1609 - accuracy: 0.9268\n",
      "Epoch 36/50\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.1882 - accuracy: 0.9125\n",
      "Epoch 37/50\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.1766 - accuracy: 0.9179\n",
      "Epoch 38/50\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.1841 - accuracy: 0.9107\n",
      "Epoch 39/50\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.1535 - accuracy: 0.9321\n",
      "Epoch 40/50\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.1729 - accuracy: 0.9161\n",
      "Epoch 41/50\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.1519 - accuracy: 0.9286\n",
      "Epoch 42/50\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.1497 - accuracy: 0.9286\n",
      "Epoch 43/50\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.1834 - accuracy: 0.9089\n",
      "Epoch 44/50\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.1699 - accuracy: 0.9143\n",
      "Epoch 45/50\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.1690 - accuracy: 0.9125\n",
      "Epoch 46/50\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.1827 - accuracy: 0.9054\n",
      "Epoch 47/50\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.1903 - accuracy: 0.9018\n",
      "Epoch 48/50\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.1463 - accuracy: 0.9339\n",
      "Epoch 49/50\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.1911 - accuracy: 0.9143\n",
      "Epoch 50/50\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 2.0640 - accuracy: 0.5750\n"
     ]
    }
   ],
   "source": [
    "# model = Model(input_layer,output_layer)\n",
    "# model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=5, verbose=3)\n",
    "grid_result = grid.fit(X_train, Y_train, use_multiprocessing=True, workers=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.998214 using {'epochs': 50, 'layers': 3, 'neurons': 60}\n",
      "0.942857 (0.050697) with: {'epochs': 25, 'layers': 2, 'neurons': 20}\n",
      "0.971429 (0.048379) with: {'epochs': 25, 'layers': 2, 'neurons': 40}\n",
      "0.994643 (0.004374) with: {'epochs': 25, 'layers': 2, 'neurons': 60}\n",
      "0.942857 (0.100952) with: {'epochs': 25, 'layers': 3, 'neurons': 20}\n",
      "0.980357 (0.021429) with: {'epochs': 25, 'layers': 3, 'neurons': 40}\n",
      "0.994643 (0.004374) with: {'epochs': 25, 'layers': 3, 'neurons': 60}\n",
      "0.894643 (0.108091) with: {'epochs': 50, 'layers': 2, 'neurons': 20}\n",
      "0.805357 (0.310550) with: {'epochs': 50, 'layers': 2, 'neurons': 40}\n",
      "0.994643 (0.004374) with: {'epochs': 50, 'layers': 2, 'neurons': 60}\n",
      "0.992857 (0.010412) with: {'epochs': 50, 'layers': 3, 'neurons': 20}\n",
      "0.991071 (0.009781) with: {'epochs': 50, 'layers': 3, 'neurons': 40}\n",
      "0.998214 (0.003571) with: {'epochs': 50, 'layers': 3, 'neurons': 60}\n",
      "0.860714 (0.243054) with: {'epochs': 75, 'layers': 2, 'neurons': 20}\n",
      "0.962500 (0.061962) with: {'epochs': 75, 'layers': 2, 'neurons': 40}\n",
      "0.998214 (0.003571) with: {'epochs': 75, 'layers': 2, 'neurons': 60}\n",
      "0.951786 (0.063033) with: {'epochs': 75, 'layers': 3, 'neurons': 20}\n",
      "0.989286 (0.013122) with: {'epochs': 75, 'layers': 3, 'neurons': 40}\n",
      "0.994643 (0.004374) with: {'epochs': 75, 'layers': 3, 'neurons': 60}\n"
     ]
    }
   ],
   "source": [
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(layers=3, neurons=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_34 (Dense)            (None, 60)                1215900   \n",
      "                                                                 \n",
      " dropout_23 (Dropout)        (None, 60)                0         \n",
      "                                                                 \n",
      " dense_35 (Dense)            (None, 60)                3660      \n",
      "                                                                 \n",
      " dropout_24 (Dropout)        (None, 60)                0         \n",
      "                                                                 \n",
      " dense_36 (Dense)            (None, 60)                3660      \n",
      "                                                                 \n",
      " dropout_25 (Dropout)        (None, 60)                0         \n",
      "                                                                 \n",
      " dense_37 (Dense)            (None, 5)                 305       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,223,525\n",
      "Trainable params: 1,223,525\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(model, to_file=\"output/model.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:31:39.105138: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/18 [=========================>....] - ETA: 0s - loss: 1.5594 - accuracy: 0.3281"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:31:39.662925: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 1s 35ms/step - loss: 1.5474 - accuracy: 0.3357 - val_loss: 1.3814 - val_accuracy: 0.3734\n",
      "Epoch 2/25\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 1.2130 - accuracy: 0.4839 - val_loss: 0.7797 - val_accuracy: 0.9834\n",
      "Epoch 3/25\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.4969 - accuracy: 0.8518 - val_loss: 0.1673 - val_accuracy: 0.9751\n",
      "Epoch 4/25\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.1442 - accuracy: 0.9661 - val_loss: 0.0433 - val_accuracy: 0.9959\n",
      "Epoch 5/25\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0507 - accuracy: 0.9911 - val_loss: 0.0346 - val_accuracy: 0.9876\n",
      "Epoch 6/25\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0529 - accuracy: 0.9893 - val_loss: 0.0301 - val_accuracy: 0.9876\n",
      "Epoch 7/25\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0569 - accuracy: 0.9857 - val_loss: 0.0170 - val_accuracy: 0.9959\n",
      "Epoch 8/25\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 0.0121 - accuracy: 1.0000 - val_loss: 0.0121 - val_accuracy: 0.9917\n",
      "Epoch 9/25\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0157 - accuracy: 0.9982 - val_loss: 0.0363 - val_accuracy: 0.9917\n",
      "Epoch 10/25\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0538 - accuracy: 0.9875 - val_loss: 0.0640 - val_accuracy: 0.9834\n",
      "Epoch 11/25\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0159 - accuracy: 0.9964 - val_loss: 0.0230 - val_accuracy: 0.9959\n",
      "Epoch 12/25\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0165 - val_accuracy: 0.9959\n",
      "Epoch 13/25\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 8.9784e-04 - accuracy: 1.0000 - val_loss: 0.0189 - val_accuracy: 0.9959\n",
      "Epoch 14/25\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0025 - accuracy: 0.9982 - val_loss: 0.0329 - val_accuracy: 0.9959\n",
      "Epoch 15/25\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0690 - accuracy: 0.9821 - val_loss: 0.1471 - val_accuracy: 0.9585\n",
      "Epoch 16/25\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0376 - accuracy: 0.9893 - val_loss: 0.0216 - val_accuracy: 0.9917\n",
      "Epoch 17/25\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.0182 - accuracy: 0.9946 - val_loss: 0.0117 - val_accuracy: 0.9959\n",
      "Epoch 18/25\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0109 - accuracy: 0.9964 - val_loss: 0.0370 - val_accuracy: 0.9917\n",
      "Epoch 19/25\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0084 - accuracy: 0.9964 - val_loss: 0.0207 - val_accuracy: 0.9959\n",
      "Epoch 20/25\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.0112 - accuracy: 0.9964 - val_loss: 0.0406 - val_accuracy: 0.9917\n",
      "Epoch 21/25\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.0328 - accuracy: 0.9893 - val_loss: 0.0359 - val_accuracy: 0.9917\n",
      "Epoch 22/25\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0174 - accuracy: 0.9964 - val_loss: 0.0321 - val_accuracy: 0.9959\n",
      "Epoch 23/25\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0057 - accuracy: 0.9982 - val_loss: 0.0147 - val_accuracy: 0.9959\n",
      "Epoch 24/25\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0122 - val_accuracy: 0.9959\n",
      "Epoch 25/25\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 6.3550e-04 - accuracy: 1.0000 - val_loss: 0.0191 - val_accuracy: 0.9959\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2f69dd100>"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "model.fit(\n",
    "          x=X_train, \n",
    "          y=Y_train, \n",
    "          epochs=25,\n",
    "          batch_size=32,\n",
    "          validation_data=(X_test, Y_test),\n",
    "          use_multiprocessing=True, \n",
    "          workers=-1, \n",
    "          callbacks=[tensorboard_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 44828), started 1 day, 3:56:38 ago. (Use '!kill 44828' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-9f4ba3e4e732b234\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-9f4ba3e4e732b234\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:31:49.758202: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "Z = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.995850622406639"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(np.argmax(Z, axis = 1),np.argmax(Y_test, axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0   0   1   2   3   4\n",
       "row_0                    \n",
       "0      41   0   0   0   0\n",
       "1       0  41   0   0   0\n",
       "2       0   1  90   0   0\n",
       "3       0   0   0  44   0\n",
       "4       0   0   0   0  24"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(np.argmax(Z, axis = 1),np.argmax(Y_test, axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'output/finalized_model_ANN.sav'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://24c6a67f-d01a-418e-bef6-b0192d87d0b8/assets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['output/finalized_model_ANN.sav']"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create file model\n",
    "joblib.dump(model, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model from disk\n",
    "loaded_model = joblib.load(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 14:31:50.739195: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "result = loaded_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.995850622406639"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(np.argmax(result, axis = 1),np.argmax(Y_test, axis = 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formatting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 3, 4, 4, 0, 4, 2, 4, 0, 4, 0, 2, 4, 0, 0, 0, 3, 2, 2, 4, 0, 2,\n",
       "       3, 0, 2, 3, 1, 0, 0, 0, 0, 0, 2, 0, 4, 0, 2, 3, 0, 0, 2, 4, 4, 2,\n",
       "       2, 0, 4, 1, 0, 3, 0, 3, 0, 4, 1, 0, 0, 1, 2, 0, 3, 2, 0, 3, 4, 1,\n",
       "       0, 4, 2, 0, 2, 0, 0, 3, 0, 3, 0, 2, 4, 1, 0, 4, 0, 0, 4, 4, 0, 0,\n",
       "       2, 0, 4, 4, 0, 0, 0, 4, 1, 0, 4, 0, 0, 2, 0, 2, 3, 2, 3, 1, 3, 3,\n",
       "       4, 0, 3, 4, 0, 2, 2, 2, 0, 0, 3, 2, 3, 0, 4, 4, 4, 0, 2, 3, 1, 0,\n",
       "       1, 0, 0, 2, 3, 0, 2, 1, 0, 4, 0, 2, 3, 1, 4, 0, 3, 3, 3, 3, 0, 0,\n",
       "       3, 0, 0, 4, 4, 3, 4, 3, 2, 0, 4, 3, 1, 2, 3, 0, 2, 3, 0, 3, 0, 0,\n",
       "       0, 4, 0, 2, 1, 2, 0, 4, 4, 4, 3, 3, 0, 3, 3, 2, 3, 4, 3, 0, 0, 0,\n",
       "       3, 3, 0, 2, 2, 2, 2, 4, 0, 4, 0, 3, 3, 0, 4, 0, 4, 0, 0, 0, 3, 0,\n",
       "       2, 3, 2, 2, 3, 0, 2, 4, 0, 3, 3, 4, 1, 0, 2, 4, 2, 1, 0, 2, 2, 3,\n",
       "       4, 4, 3, 3, 2, 0, 0, 1, 0, 4, 1, 0, 4, 2, 4, 4, 4, 0, 1, 1, 3, 1,\n",
       "       1, 4, 3, 0, 0, 2, 2, 0, 1, 4, 2, 4, 0, 0, 2, 0, 0, 0, 0, 3, 3, 0,\n",
       "       0, 0, 2, 2, 2, 2, 0, 0, 0, 2, 0, 0, 3, 4, 0, 0, 1, 3, 4, 0, 0, 0,\n",
       "       1, 0, 4, 0, 1, 3, 3, 4, 2, 0, 2, 2, 3, 1, 2, 0, 0, 0, 0, 2, 0, 0,\n",
       "       4, 0, 2, 0, 3, 4, 2, 0, 4, 1, 0, 0, 0, 3, 3, 3, 0, 0, 4, 3, 0, 2,\n",
       "       0, 1, 1, 3, 0, 2, 0, 0, 0, 1, 3, 1, 2, 4, 2, 0, 0, 2, 0, 1, 4, 3,\n",
       "       4, 0, 2, 4, 0, 1, 2, 2, 1, 1, 4, 0, 0, 1, 2, 0, 4, 0, 0, 0, 3, 3,\n",
       "       2, 3, 0, 2, 1, 4, 0, 3, 4, 0, 0, 0, 3, 0, 0, 4, 0, 4, 1, 0, 3, 0,\n",
       "       0, 3, 0, 0, 0, 2, 3, 4, 0, 4, 2, 0, 2, 1, 0, 4, 3, 2, 0, 0, 2, 0,\n",
       "       3, 0, 0, 4, 1, 0, 2, 3, 4, 0, 4, 0, 0, 0, 0, 2, 3, 0, 2, 0, 0, 3,\n",
       "       3, 2, 1, 4, 1, 0, 2, 2, 0, 4, 2, 1, 3, 3, 0, 4, 4, 0, 4, 3, 2, 4,\n",
       "       0, 3, 4, 3, 0, 0, 1, 3, 2, 1, 3, 0, 4, 0, 0, 4, 0, 1, 0, 1, 2, 0,\n",
       "       0, 3, 3, 3, 1, 2, 3, 3, 0, 0, 2, 4, 3, 4, 0, 2, 0, 2, 2, 4, 4, 3,\n",
       "       0, 2, 1, 1, 0, 2, 2, 0, 0, 4, 2, 1, 0, 0, 1, 3, 0, 0, 0, 2, 4, 3,\n",
       "       3, 0, 2, 1, 2, 2, 0, 4, 3, 2, 0, 1, 3, 3, 3, 4, 3, 2, 0, 0, 1, 4,\n",
       "       0, 0, 0, 2, 3, 3, 0, 4, 3, 3, 0, 2, 4, 1, 3, 4, 1, 3, 1, 2, 2, 0,\n",
       "       0, 2, 2, 1, 0, 3, 4, 4, 2, 0, 3, 0, 0, 1, 0, 4, 4, 0, 0, 1, 0, 2,\n",
       "       0, 0, 1, 0, 4, 0, 0, 2, 4, 3, 0, 0, 2, 0, 0, 0, 0, 0, 1, 3, 3, 0,\n",
       "       0, 0, 4, 0, 0, 2, 3, 3, 2, 2, 3, 2, 1, 0, 1, 2, 0, 0, 4, 4, 4, 3,\n",
       "       4, 4, 1, 0, 0, 1, 3, 2, 0, 2, 1, 0, 0, 0, 4, 3, 2, 0, 4, 2, 4, 0,\n",
       "       3, 2, 4, 3, 4, 4, 0, 2, 4, 3, 1, 1, 0, 0, 0, 3, 2, 2, 2, 0, 3, 2,\n",
       "       4, 0, 3, 4, 0, 4, 0, 2, 0, 1, 4, 4, 2, 4, 2, 0, 3, 3, 0, 0, 2, 0,\n",
       "       0, 0, 0, 2, 2, 4, 1, 2, 0, 0, 2, 0, 3, 0, 0, 4, 0, 4, 0, 1, 0, 0,\n",
       "       2, 3, 0, 0, 4, 0, 4, 1, 0, 0, 0, 3, 0, 3, 0, 3, 2, 2, 1, 1, 0, 0,\n",
       "       0, 3, 0, 3, 2, 0, 3, 2, 3, 3, 3, 2, 0, 4, 0, 0, 2, 0, 4, 2, 0, 0,\n",
       "       0, 0, 4, 3, 0, 3, 1, 4, 4])"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = LabelEncoder()\n",
    "Y_bis = y.fit_transform(Y)\n",
    "Y_bis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y_bis, test_size=0.3, random_state=42, stratify=Y_bis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = xgb.XGBClassifier(objective='multi:softprob', random_state = 0, nthread = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a dictionary of hyperparameter values to search\n",
    "search_space = {\n",
    "    \"n_estimators\" : [100, 200, 500],\n",
    "    \"max_depth\" : [3, 6, 9],\n",
    "    \"learning_rate\" : [0.001, 0.01, 0.1]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a GridSearchCV object\n",
    "GS = GridSearchCV(estimator = xgb_model,\n",
    "                  param_grid = search_space,\n",
    "                  scoring = \"accuracy\", #sklearn.metrics.SCORERS.keys()\n",
    "                  cv = 3,\n",
    "                  n_jobs=-1,\n",
    "                  verbose = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 27 candidates, totalling 81 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:49:14] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1637426411619/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:49:14] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1637426411619/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:49:14] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1637426411619/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:49:15] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1637426411619/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:49:15] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1637426411619/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:49:15] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1637426411619/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:49:15] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1637426411619/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:49:15] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1637426411619/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 3/3] END learning_rate=0.001, max_depth=3, n_estimators=100;, score=0.989 total time= 4.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:13] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1637426411619/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 1/3] END learning_rate=0.001, max_depth=3, n_estimators=100;, score=0.984 total time= 4.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END learning_rate=0.001, max_depth=3, n_estimators=100;, score=0.995 total time= 4.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:18] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1637426411619/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:53:19] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1637426411619/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 3/3] END learning_rate=0.001, max_depth=3, n_estimators=200;, score=0.984 total time= 8.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:57:14] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1637426411619/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 2/3] END learning_rate=0.001, max_depth=3, n_estimators=200;, score=0.995 total time= 8.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END learning_rate=0.001, max_depth=3, n_estimators=200;, score=0.989 total time= 8.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END learning_rate=0.001, max_depth=6, n_estimators=100;, score=0.984 total time= 4.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END learning_rate=0.001, max_depth=6, n_estimators=100;, score=0.995 total time= 4.2min\n",
      "[14:57:26] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1637426411619/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:57:27] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1637426411619/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:57:29] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1637426411619/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:57:30] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1637426411619/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 3/3] END learning_rate=0.001, max_depth=6, n_estimators=100;, score=0.989 total time= 4.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:01:34] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1637426411619/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 3/3] END learning_rate=0.001, max_depth=6, n_estimators=200;, score=0.984 total time= 8.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:05:46] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1637426411619/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 1/3] END learning_rate=0.001, max_depth=6, n_estimators=200;, score=0.989 total time= 8.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END learning_rate=0.001, max_depth=6, n_estimators=200;, score=0.995 total time= 8.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:05:58] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1637426411619/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:05:59] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1637426411619/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 2/3] END learning_rate=0.001, max_depth=3, n_estimators=500;, score=0.989 total time=20.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:09:48] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1637426411619/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 1/3] END learning_rate=0.001, max_depth=3, n_estimators=500;, score=0.989 total time=20.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:09:53] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1637426411619/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 1/3] END learning_rate=0.001, max_depth=9, n_estimators=100;, score=0.984 total time= 4.0min\n",
      "[CV 2/3] END learning_rate=0.001, max_depth=9, n_estimators=100;, score=0.995 total time= 4.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:10:00] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1637426411619/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:10:00] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1637426411619/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 3/3] END learning_rate=0.001, max_depth=3, n_estimators=500;, score=0.984 total time=20.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:13:16] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1637426411619/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 3/3] END learning_rate=0.001, max_depth=9, n_estimators=100;, score=0.989 total time= 3.9min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:13:43] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1637426411619/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 3/3] END learning_rate=0.001, max_depth=9, n_estimators=200;, score=0.984 total time= 7.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:17:51] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1637426411619/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 1/3] END learning_rate=0.001, max_depth=9, n_estimators=200;, score=0.989 total time= 8.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END learning_rate=0.001, max_depth=6, n_estimators=500;, score=0.989 total time=20.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:17:57] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1637426411619/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 2/3] END learning_rate=0.001, max_depth=9, n_estimators=200;, score=0.995 total time= 8.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:17:59] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1637426411619/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:18:02] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1637426411619/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 2/3] END learning_rate=0.001, max_depth=6, n_estimators=500;, score=0.989 total time=20.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:21:44] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1637426411619/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 1/3] END learning_rate=0.01, max_depth=3, n_estimators=100;, score=0.989 total time= 4.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:21:56] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1637426411619/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 3/3] END learning_rate=0.01, max_depth=3, n_estimators=100;, score=0.984 total time= 4.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END learning_rate=0.01, max_depth=3, n_estimators=100;, score=0.989 total time= 4.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:22:00] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1637426411619/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:22:02] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1637426411619/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 3/3] END learning_rate=0.001, max_depth=6, n_estimators=500;, score=0.984 total time=19.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:25:12] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1637426411619/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 1/3] END learning_rate=0.01, max_depth=3, n_estimators=200;, score=0.995 total time= 7.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:34] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1637426411619/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 3/3] END learning_rate=0.01, max_depth=3, n_estimators=200;, score=0.984 total time= 7.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:45] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1637426411619/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 2/3] END learning_rate=0.01, max_depth=3, n_estimators=200;, score=0.989 total time= 8.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:56] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1637426411619/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 1/3] END learning_rate=0.001, max_depth=9, n_estimators=500;, score=0.989 total time=20.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:33:39] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1637426411619/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 1/3] END learning_rate=0.01, max_depth=6, n_estimators=100;, score=0.989 total time= 4.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:33:43] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1637426411619/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 2/3] END learning_rate=0.001, max_depth=9, n_estimators=500;, score=0.989 total time=20.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END learning_rate=0.01, max_depth=6, n_estimators=100;, score=0.989 total time= 4.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:33:57] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1637426411619/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:33:59] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1637426411619/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 3/3] END learning_rate=0.01, max_depth=6, n_estimators=100;, score=0.984 total time= 4.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END learning_rate=0.001, max_depth=9, n_estimators=500;, score=0.984 total time=19.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:37:38] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1637426411619/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:37:40] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1637426411619/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 1/3] END learning_rate=0.01, max_depth=3, n_estimators=500;, score=0.984 total time=17.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:39:36] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1637426411619/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 1/3] END learning_rate=0.01, max_depth=6, n_estimators=200;, score=0.995 total time= 7.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:41:14] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1637426411619/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 3/3] END learning_rate=0.01, max_depth=6, n_estimators=200;, score=0.984 total time= 7.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:41:23] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1637426411619/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 2/3] END learning_rate=0.01, max_depth=6, n_estimators=200;, score=0.989 total time= 7.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:41:37] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1637426411619/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 2/3] END learning_rate=0.01, max_depth=3, n_estimators=500;, score=0.989 total time=17.9min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:43:04] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1637426411619/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 1/3] END learning_rate=0.01, max_depth=9, n_estimators=100;, score=0.989 total time= 3.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:45:01] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1637426411619/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 2/3] END learning_rate=0.01, max_depth=9, n_estimators=100;, score=0.989 total time= 3.9min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:45:15] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1637426411619/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 3/3] END learning_rate=0.01, max_depth=9, n_estimators=100;, score=0.984 total time= 3.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:45:25] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1637426411619/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 3/3] END learning_rate=0.01, max_depth=3, n_estimators=500;, score=0.984 total time=17.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:46:38] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1637426411619/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 1/3] END learning_rate=0.01, max_depth=9, n_estimators=200;, score=0.995 total time= 7.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:50:30] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1637426411619/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 3/3] END learning_rate=0.01, max_depth=9, n_estimators=200;, score=0.984 total time= 7.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:52:25] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1637426411619/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 2/3] END learning_rate=0.01, max_depth=9, n_estimators=200;, score=0.989 total time= 7.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:52:30] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1637426411619/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 1/3] END learning_rate=0.01, max_depth=6, n_estimators=500;, score=0.984 total time=16.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:53:59] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1637426411619/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 2/3] END learning_rate=0.01, max_depth=6, n_estimators=500;, score=0.989 total time=16.9min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:54:30] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1637426411619/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 1/3] END learning_rate=0.1, max_depth=3, n_estimators=100;, score=0.989 total time= 2.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:54:37] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1637426411619/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 2/3] END learning_rate=0.1, max_depth=3, n_estimators=100;, score=0.995 total time= 2.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:54:45] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1637426411619/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 3/3] END learning_rate=0.01, max_depth=6, n_estimators=500;, score=0.984 total time=16.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:55:52] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1637426411619/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 3/3] END learning_rate=0.1, max_depth=3, n_estimators=100;, score=0.989 total time= 2.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:56:09] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1637426411619/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 1/3] END learning_rate=0.1, max_depth=3, n_estimators=200;, score=0.989 total time= 3.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:57:40] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1637426411619/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 2/3] END learning_rate=0.1, max_depth=3, n_estimators=200;, score=0.995 total time= 3.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:57:48] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1637426411619/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 3/3] END learning_rate=0.1, max_depth=3, n_estimators=200;, score=0.989 total time= 3.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:57:55] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1637426411619/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 1/3] END learning_rate=0.1, max_depth=6, n_estimators=100;, score=0.989 total time= 2.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:59:56] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1637426411619/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 2/3] END learning_rate=0.1, max_depth=6, n_estimators=100;, score=0.995 total time= 2.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:00:04] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1637426411619/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 1/3] END learning_rate=0.01, max_depth=9, n_estimators=500;, score=0.984 total time=15.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:00:41] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1637426411619/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 1/3] END learning_rate=0.1, max_depth=3, n_estimators=500;, score=0.989 total time= 5.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:01:40] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1637426411619/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 3/3] END learning_rate=0.1, max_depth=6, n_estimators=100;, score=0.989 total time= 1.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:01:43] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1637426411619/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 2/3] END learning_rate=0.01, max_depth=9, n_estimators=500;, score=0.989 total time=15.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END learning_rate=0.1, max_depth=3, n_estimators=500;, score=0.995 total time= 5.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:01:58] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1637426411619/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:01:59] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1637426411619/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 1/3] END learning_rate=0.1, max_depth=6, n_estimators=200;, score=0.989 total time= 2.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:02:45] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1637426411619/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 3/3] END learning_rate=0.1, max_depth=3, n_estimators=500;, score=0.989 total time= 5.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END learning_rate=0.1, max_depth=6, n_estimators=200;, score=0.995 total time= 2.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:03:21] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1637426411619/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:03:23] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1637426411619/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 3/3] END learning_rate=0.1, max_depth=6, n_estimators=200;, score=0.989 total time= 2.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END learning_rate=0.01, max_depth=9, n_estimators=500;, score=0.984 total time=13.9min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:04:20] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1637426411619/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:04:20] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1637426411619/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 1/3] END learning_rate=0.1, max_depth=9, n_estimators=100;, score=0.989 total time= 1.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:04:30] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1637426411619/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 3/3] END learning_rate=0.1, max_depth=9, n_estimators=100;, score=0.989 total time= 1.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END learning_rate=0.1, max_depth=9, n_estimators=100;, score=0.995 total time= 1.7min\n",
      "[16:05:05] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1637426411619/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:05:06] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1637426411619/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 1/3] END learning_rate=0.1, max_depth=9, n_estimators=200;, score=0.989 total time= 2.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END learning_rate=0.1, max_depth=6, n_estimators=500;, score=0.989 total time= 5.0min\n",
      "[16:06:41] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1637426411619/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 2/3] END learning_rate=0.1, max_depth=9, n_estimators=200;, score=0.995 total time= 2.4min\n",
      "[CV 3/3] END learning_rate=0.1, max_depth=9, n_estimators=200;, score=0.989 total time= 2.3min\n",
      "[CV 3/3] END learning_rate=0.1, max_depth=6, n_estimators=500;, score=0.989 total time= 4.9min\n",
      "[CV 2/3] END learning_rate=0.1, max_depth=6, n_estimators=500;, score=0.995 total time= 4.9min\n",
      "[CV 1/3] END learning_rate=0.1, max_depth=9, n_estimators=500;, score=0.989 total time= 2.7min\n",
      "[CV 2/3] END learning_rate=0.1, max_depth=9, n_estimators=500;, score=0.995 total time= 2.7min\n",
      "[CV 3/3] END learning_rate=0.1, max_depth=9, n_estimators=500;, score=0.989 total time= 1.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:07:58] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1637426411619/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None,\n",
       "                                     enable_categorical=False, gamma=None,\n",
       "                                     gpu_id=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None, max_delta_step=None,\n",
       "                                     max_depth=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     n_estimators=100, n_jobs=None, nthread=-1,\n",
       "                                     num_parallel_tree=None,\n",
       "                                     objective='multi:softprob', predictor=None,\n",
       "                                     random_state=0, reg_alpha=None,\n",
       "                                     reg_lambda=None, scale_pos_weight=None,\n",
       "                                     subsample=None, tree_method=None,\n",
       "                                     validate_parameters=None, verbosity=None),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'learning_rate': [0.001, 0.01, 0.1],\n",
       "                         'max_depth': [3, 6, 9],\n",
       "                         'n_estimators': [100, 200, 500]},\n",
       "             scoring='accuracy', verbose=4)"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GS.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "              gamma=0, gpu_id=-1, importance_type=None,\n",
       "              interaction_constraints='', learning_rate=0.1, max_delta_step=0,\n",
       "              max_depth=3, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=100, n_jobs=8, nthread=-1,\n",
       "              num_parallel_tree=1, objective='multi:softprob', predictor='auto',\n",
       "              random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=None,\n",
       "              subsample=1, tree_method='exact', validate_parameters=1,\n",
       "              verbosity=None)"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GS.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100}"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GS.best_params_ # to get only the best hyperparameter values that we searched for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9910681770264312\n"
     ]
    }
   ],
   "source": [
    "print(GS.best_score_) # score according to the metric we passed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 10800x7200 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_tree(GS.best_estimator_)\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(150, 100)\n",
    "fig.savefig('output/tree.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'output/finalized_model_XGB.sav'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['output/finalized_model_XGB.sav']"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create file model\n",
    "joblib.dump(GS.best_estimator_, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model from disk\n",
    "loaded_model = joblib.load(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.991701244813278\n"
     ]
    }
   ],
   "source": [
    "result = loaded_model.score(X_test, Y_test)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_model():\n",
    "#     init = 'random_uniform'\n",
    "#     model = Sequential()\n",
    "#     model.add(Input(shape=(20264,)))\n",
    "#     model.add(Dense(100, activation = 'relu', kernel_initializer = init))\n",
    "#     model.add(Dense(50, activation = 'relu', kernel_initializer = init))\n",
    "#     model.add(Dense(5, activation = 'softmax', kernel_initializer = init))\n",
    "    \n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = create_model()\n",
    "# model.compile(optimizer='sgd',loss='categorical_crossentropy',metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "11/18 [=================>............] - ETA: 0s - loss: 2.3251 - accuracy: 0.3409"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-06 00:48:53.326721: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/18 [=========================>....] - ETA: 0s - loss: 2.0553 - accuracy: 0.3633"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-06 00:48:53.677873: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 1s 30ms/step - loss: 2.0288 - accuracy: 0.3554 - val_loss: 1.5462 - val_accuracy: 0.2573\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 1.4255 - accuracy: 0.3536 - val_loss: 1.6999 - val_accuracy: 0.3734\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 1.4833 - accuracy: 0.3357 - val_loss: 1.4330 - val_accuracy: 0.3734\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 1.4398 - accuracy: 0.3571 - val_loss: 1.6927 - val_accuracy: 0.1743\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 1.4249 - accuracy: 0.3839 - val_loss: 1.3695 - val_accuracy: 0.3734\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 1.4909 - accuracy: 0.3571 - val_loss: 1.5681 - val_accuracy: 0.5353\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 1.4973 - accuracy: 0.4232 - val_loss: 1.4512 - val_accuracy: 0.4440\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 1.5098 - accuracy: 0.3446 - val_loss: 1.5566 - val_accuracy: 0.1120\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 1.5504 - accuracy: 0.3429 - val_loss: 1.5901 - val_accuracy: 0.0996\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 1.5595 - accuracy: 0.3679 - val_loss: 1.5361 - val_accuracy: 0.4689\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 1.5460 - accuracy: 0.3732 - val_loss: 1.4922 - val_accuracy: 0.3983\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 1.5475 - accuracy: 0.3643 - val_loss: 1.5735 - val_accuracy: 0.3734\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 1.5708 - accuracy: 0.3750 - val_loss: 1.5687 - val_accuracy: 0.3734\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 1.5660 - accuracy: 0.3750 - val_loss: 1.5639 - val_accuracy: 0.3734\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 1.5614 - accuracy: 0.3750 - val_loss: 1.5599 - val_accuracy: 0.3734\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 1.5574 - accuracy: 0.3750 - val_loss: 1.5558 - val_accuracy: 0.3734\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 1.5534 - accuracy: 0.3750 - val_loss: 1.5521 - val_accuracy: 0.3734\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 1.5498 - accuracy: 0.3750 - val_loss: 1.5488 - val_accuracy: 0.3734\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 1.5465 - accuracy: 0.3750 - val_loss: 1.5459 - val_accuracy: 0.3734\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 1.5437 - accuracy: 0.3750 - val_loss: 1.5432 - val_accuracy: 0.3734\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 1.5410 - accuracy: 0.3750 - val_loss: 1.5405 - val_accuracy: 0.3734\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 1.5384 - accuracy: 0.3750 - val_loss: 1.5382 - val_accuracy: 0.3734\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 1.5361 - accuracy: 0.3750 - val_loss: 1.5361 - val_accuracy: 0.3734\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 1.5339 - accuracy: 0.3750 - val_loss: 1.5341 - val_accuracy: 0.3734\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 1.5321 - accuracy: 0.3750 - val_loss: 1.5324 - val_accuracy: 0.3734\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 1.5303 - accuracy: 0.3750 - val_loss: 1.5307 - val_accuracy: 0.3734\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 1.5286 - accuracy: 0.3750 - val_loss: 1.5292 - val_accuracy: 0.3734\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 1.5271 - accuracy: 0.3750 - val_loss: 1.5279 - val_accuracy: 0.3734\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 1.5259 - accuracy: 0.3750 - val_loss: 1.5266 - val_accuracy: 0.3734\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 1.5246 - accuracy: 0.3750 - val_loss: 1.5255 - val_accuracy: 0.3734\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 1.5235 - accuracy: 0.3750 - val_loss: 1.5245 - val_accuracy: 0.3734\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 1.5225 - accuracy: 0.3750 - val_loss: 1.5236 - val_accuracy: 0.3734\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 1.5216 - accuracy: 0.3750 - val_loss: 1.5227 - val_accuracy: 0.3734\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 1.5207 - accuracy: 0.3750 - val_loss: 1.5220 - val_accuracy: 0.3734\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 1.5199 - accuracy: 0.3750 - val_loss: 1.5213 - val_accuracy: 0.3734\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 1.5192 - accuracy: 0.3750 - val_loss: 1.5207 - val_accuracy: 0.3734\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 1.5186 - accuracy: 0.3750 - val_loss: 1.5200 - val_accuracy: 0.3734\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 1.5180 - accuracy: 0.3750 - val_loss: 1.5195 - val_accuracy: 0.3734\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 1.5175 - accuracy: 0.3750 - val_loss: 1.5190 - val_accuracy: 0.3734\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 1.5170 - accuracy: 0.3750 - val_loss: 1.5186 - val_accuracy: 0.3734\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 1.5165 - accuracy: 0.3750 - val_loss: 1.5182 - val_accuracy: 0.3734\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 1.5161 - accuracy: 0.3750 - val_loss: 1.5178 - val_accuracy: 0.3734\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 1.5157 - accuracy: 0.3750 - val_loss: 1.5175 - val_accuracy: 0.3734\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 1.5153 - accuracy: 0.3750 - val_loss: 1.5172 - val_accuracy: 0.3734\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 1.5150 - accuracy: 0.3750 - val_loss: 1.5169 - val_accuracy: 0.3734\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 1.5148 - accuracy: 0.3750 - val_loss: 1.5167 - val_accuracy: 0.3734\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 1.5146 - accuracy: 0.3750 - val_loss: 1.5165 - val_accuracy: 0.3734\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 1.5144 - accuracy: 0.3750 - val_loss: 1.5163 - val_accuracy: 0.3734\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 1.5141 - accuracy: 0.3750 - val_loss: 1.5161 - val_accuracy: 0.3734\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 1.5139 - accuracy: 0.3750 - val_loss: 1.5159 - val_accuracy: 0.3734\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 1.5137 - accuracy: 0.3750 - val_loss: 1.5157 - val_accuracy: 0.3734\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 1.5135 - accuracy: 0.3750 - val_loss: 1.5156 - val_accuracy: 0.3734\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 1.5133 - accuracy: 0.3750 - val_loss: 1.5154 - val_accuracy: 0.3734\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 1.5132 - accuracy: 0.3750 - val_loss: 1.5153 - val_accuracy: 0.3734\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 1.5130 - accuracy: 0.3750 - val_loss: 1.5152 - val_accuracy: 0.3734\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 1.5130 - accuracy: 0.3750 - val_loss: 1.5151 - val_accuracy: 0.3734\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 1.5128 - accuracy: 0.3750 - val_loss: 1.5150 - val_accuracy: 0.3734\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 1.5127 - accuracy: 0.3750 - val_loss: 1.5149 - val_accuracy: 0.3734\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 1.5126 - accuracy: 0.3750 - val_loss: 1.5148 - val_accuracy: 0.3734\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 1.5125 - accuracy: 0.3750 - val_loss: 1.5148 - val_accuracy: 0.3734\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 1.5124 - accuracy: 0.3750 - val_loss: 1.5147 - val_accuracy: 0.3734\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 1.5123 - accuracy: 0.3750 - val_loss: 1.5146 - val_accuracy: 0.3734\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 1.5123 - accuracy: 0.3750 - val_loss: 1.5146 - val_accuracy: 0.3734\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 1.5122 - accuracy: 0.3750 - val_loss: 1.5145 - val_accuracy: 0.3734\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 1.5121 - accuracy: 0.3750 - val_loss: 1.5144 - val_accuracy: 0.3734\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 1.5120 - accuracy: 0.3750 - val_loss: 1.5144 - val_accuracy: 0.3734\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 1.5120 - accuracy: 0.3750 - val_loss: 1.5144 - val_accuracy: 0.3734\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 1.5120 - accuracy: 0.3750 - val_loss: 1.5143 - val_accuracy: 0.3734\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 1.5119 - accuracy: 0.3750 - val_loss: 1.5143 - val_accuracy: 0.3734\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 1.5118 - accuracy: 0.3750 - val_loss: 1.5142 - val_accuracy: 0.3734\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 1.5118 - accuracy: 0.3750 - val_loss: 1.5142 - val_accuracy: 0.3734\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 1.5117 - accuracy: 0.3750 - val_loss: 1.5142 - val_accuracy: 0.3734\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 1.5117 - accuracy: 0.3750 - val_loss: 1.5141 - val_accuracy: 0.3734\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 1.5116 - accuracy: 0.3750 - val_loss: 1.5141 - val_accuracy: 0.3734\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 1.5116 - accuracy: 0.3750 - val_loss: 1.5141 - val_accuracy: 0.3734\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 1.5116 - accuracy: 0.3750 - val_loss: 1.5141 - val_accuracy: 0.3734\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 28ms/step - loss: 1.5115 - accuracy: 0.3750 - val_loss: 1.5140 - val_accuracy: 0.3734\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 1.5115 - accuracy: 0.3750 - val_loss: 1.5140 - val_accuracy: 0.3734\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 1.5115 - accuracy: 0.3750 - val_loss: 1.5140 - val_accuracy: 0.3734\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 1.5114 - accuracy: 0.3750 - val_loss: 1.5140 - val_accuracy: 0.3734\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 1.5114 - accuracy: 0.3750 - val_loss: 1.5140 - val_accuracy: 0.3734\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 1.5114 - accuracy: 0.3750 - val_loss: 1.5139 - val_accuracy: 0.3734\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 1.5114 - accuracy: 0.3750 - val_loss: 1.5139 - val_accuracy: 0.3734\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 1.5114 - accuracy: 0.3750 - val_loss: 1.5139 - val_accuracy: 0.3734\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 1.5113 - accuracy: 0.3750 - val_loss: 1.5139 - val_accuracy: 0.3734\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 1.5113 - accuracy: 0.3750 - val_loss: 1.5139 - val_accuracy: 0.3734\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 1.5113 - accuracy: 0.3750 - val_loss: 1.5139 - val_accuracy: 0.3734\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 1.5113 - accuracy: 0.3750 - val_loss: 1.5139 - val_accuracy: 0.3734\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 1.5113 - accuracy: 0.3750 - val_loss: 1.5139 - val_accuracy: 0.3734\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 1.5112 - accuracy: 0.3750 - val_loss: 1.5139 - val_accuracy: 0.3734\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 1.5112 - accuracy: 0.3750 - val_loss: 1.5139 - val_accuracy: 0.3734\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 1.5112 - accuracy: 0.3750 - val_loss: 1.5138 - val_accuracy: 0.3734\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 1.5112 - accuracy: 0.3750 - val_loss: 1.5138 - val_accuracy: 0.3734\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 1.5112 - accuracy: 0.3750 - val_loss: 1.5138 - val_accuracy: 0.3734\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 1.5112 - accuracy: 0.3750 - val_loss: 1.5138 - val_accuracy: 0.3734\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 1.5112 - accuracy: 0.3750 - val_loss: 1.5138 - val_accuracy: 0.3734\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 1.5112 - accuracy: 0.3750 - val_loss: 1.5138 - val_accuracy: 0.3734\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 1.5111 - accuracy: 0.3750 - val_loss: 1.5138 - val_accuracy: 0.3734\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 1.5111 - accuracy: 0.3750 - val_loss: 1.5138 - val_accuracy: 0.3734\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 1.5112 - accuracy: 0.3750 - val_loss: 1.5138 - val_accuracy: 0.3734\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17ecc27c0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "# tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "# model.fit(x=X_train, \n",
    "#           y=Y_train, \n",
    "#           epochs=100,\n",
    "#           batch_size=32,\n",
    "#           validation_data=(X_test, Y_test),\n",
    "#           use_multiprocessing=True, \n",
    "#           workers=-1, \n",
    "#           callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-51412be9ea491121\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-51412be9ea491121\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# %tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-06 00:49:35.476672: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "# Z = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>42</td>\n",
       "      <td>90</td>\n",
       "      <td>44</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0   0   1   2   3   4\n",
       "row_0                    \n",
       "2      41  42  90  44  24"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pd.crosstab(np.argmax(Z, axis = 1),np.argmax(Y_test, axis = 1))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4976e0179d97dd6d59b1329a76e601e17b789c2571b41c8b57f5fd69821c0dd3"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
